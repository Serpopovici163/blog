<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-02-11T23:42:30-05:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Ludicrous Tech</title><subtitle>This website keeps track of whichever projects I am most proud of and serves to share some of the knowledge I accumulate from tinkering on whatever comes to my mind. Enjoy!</subtitle><author><name>Serban Popovici</name></author><entry><title type="html">Two G-class Stage Rocket w/ Basic Telemetry</title><link href="http://localhost:4000/two-stage-rocket/" rel="alternate" type="text/html" title="Two G-class Stage Rocket w/ Basic Telemetry" /><published>2022-11-08T00:00:00-05:00</published><updated>2022-11-08T00:00:00-05:00</updated><id>http://localhost:4000/two-stage-rocket</id><content type="html" xml:base="http://localhost:4000/two-stage-rocket/"><![CDATA[<h2 id="experimenting-with-rocketry-electronics">Experimenting with rocketry electronics</h2>

<p>While I doubt I will ever get a high power rocketry license, I do thoroughly enjoy developing and flying model rockets. None of my past rockets have incorporated any amount of electronics so the purpose of this project is to get a feel for rocketry electronics without any risk by developing only non-terribly-flight-critical components. For this project, I purchased the two biggest rocket engines I can legally get my hands on without any license: AeroTech G80-7T motors.</p>

<h1 id="design">Design</h1>
<h2 id="motor-mounts">Motor mounts</h2>

<p>I watched a <a href="https://www.youtube.com/watch?v=4fhoCt9vXA8">video</a> by ProjectAir on YouTube about a rocket he built using similarly powerful motors and I based my rocket motor mounts on his design. The motor mounts consist of a small tube for the motor and a larger tube that fits snugly into the rocket body. These two are connected by 8 perpendicular supports between the two cylindrical extrusions. The holes on the bottom of this motor mount also work to hold the first stage onto the main stage by using 8 pegs protruding from the first stage which fit snugly into the 8 holes of the motor mount above.</p>

<h2 id="avionics">Avionics</h2>

<p>I intend to have live data logging and telemetry at the very least. This rocket will include a GPS, barometer, and accelerometer as well as an ignition system for the main stage engine. I would also like to include some system that can delay the deployment of the main chute since it will significantly increase the rocket’s drift during recovery however I’m unsure of how reliably I can integrate such a feature. All the electronics will be housed near/in the nose cone and the rocket will separate close to the main stage motor for recovery such that the body tube/nose cone section containing the electronics remains intact.</p>

<h1 id="update-nov-2022">UPDATE Nov 2022</h1>

<p>Project is not on track, too many things going on in school however the avionics bay had been printed and mostly assembled. The nose cone is being redesigned to house status LEDs, the GPS, and two cameras for in-flight footage. Pictures coming soon.</p>

<h1 id="update-oct-2022">UPDATE Oct 2022</h1>

<p><img src="/assets/img/habibi-express/recovery_layout_update.jpg" alt="Recovery layout update" style="float: right; width:10%; height:20%; margin-left: 10px;" /> 
Progress is being made on flight controller firmware, the I2C issue has been fixed, and the IMU data is now being read as well. Turns out the Adafruit BMP280 library was looking for the wrong address and I had to force it to read data from the true address. Engine mounts and fins have been attached to the rocket, currently focused on recovery charge and how to protect the rocket’s internals from the motor’s ejection charge as well as the true ejection charge. The motor mounts have plenty of space around them to allow the motor’s ejection charge gases to escape however I need to add a component following the motor to shield the parachute from the motor’s charge and contain the true ejection charge as well. The planned layout is pictured to the right where the green block represents the blast shield, red represents the true ejection charge, yellow represents the drogue chute, and cyan represents the final chute. The rocket splits between the cyan and yellow blocks when the ejection charge detonates.</p>

<p>The avionics bay has been expanded to include relays for the second stage and ejection charge igniters as well as an SD card reader for data logging, servo to retain the primary parachute, and two DVRs (scrapped the camera inside the body tube). The second stage will be ignited based on the following criteria:</p>
<ul>
  <li>Rocket attitude is within 30 degrees of launch attitude (makes sure the rocket is vertical)</li>
  <li>Rocket altitude is greater than 250 meters (should be 500 meters or so based on simulation)</li>
  <li>Rocket acceleration drops noticeably (simulation suggests peak of 13 Gs however the software will just look for a drop of ~5Gs)</li>
  <li>Launch was detected less than 10 seconds ago (makes sure the conditions cannot be met unless the rocket just took off)</li>
</ul>

<p>Once these conditions are met, the rocket will begin a 3-second timer before igniting the second stage, otherwise the flight controller will do nothing. Apogee will be detected when vertical acceleration drops below -5m/s^2 after which the ejection charge will be ignited. The final chute will be deployed 250 meters above ground level based on barometric data. Launch window has been slightly pushed back however it should be achievable by end of November :)</p>

<h1 id="update-sep-2022">UPDATE Sep 2022</h1>

<p><img src="/assets/img/habibi-express/fin_laser_cutting.jpg" alt="Laser cutting fins" style="float: right; width:30%; height:50%; margin-left: 10px;" />
Finally got around to laser cutting the fins and I have worked slightly on the firmware for the flight controller. Unfortunately I’m having issues with the barometer since it communicates using 3.3V so the Arduino Mega is not able to interpret the I2C data coming from it. The current solution is to replace the barometer with a proven chip that I can find online as working with the Arduino Mega. I will also attempt to read the I2C data using another 5V Arduino to verify that this is indeed the issue. Finally, I have decided to add a few <a href="https://www.aliexpress.com/item/1005002457700952.html">video recorders</a> and a few analog cameras to capture a few angles of the flight. I’m hoping to add a downward facing camera, a side facing camera, and one looking down the body tube towards the main stage engine to capture the ejection from inside the rocket. I intend model camera mounts and redo the avionics bay by the end of October such that the rocket can be flown early November at the latest.</p>

<h1 id="update-jun-2022">UPDATE Jun 2022</h1>

<p><img src="/assets/img/habibi-express/avionicsFront.jpg" alt="Assembled avionics bay" style="float: right; width:30%; height:50%; margin-left: 10px;" />
The avionics bay has been assembled though it is missing a couple key elements. Firstly, there is no voltage regulator to step down the LiPo’s voltage for the Arduino and related electronics; furthermore, I need to integrate a relay, so the Arduino can ignite the second stage motor once the initial one burns out. Finally, the antenna installed on the design right now can not be used and is solely there to ensure that I don’t accidentally burn the LoRa transceiver by powering it on without an antenna. Everything on the module at the moment is completely wired and ready to go. I have noted the I2C addresses of the MPU6050 and BMP280 and the wire with the white connector sticking out the top of the avionics bay goes to the GPS sensor in the nose cone of the aircraft.</p>

<p>The software for this design won’t be too involved as the Arduino only needs to ignite the second stage 3 seconds after the MPU6050 detects a decrease in vertical acceleration all while broadcasting GPS, altitude, and attitude data at regular intervals. The main concern now is developing viable fins for the rocket body. I am hoping to have them laser-cut at the university but I have yet to inquire about using the equipment.</p>

<h1 id="update-mar-2022">UPDATE Mar 2022</h1>

<p><img src="/assets/img/habibi-express/avionics-CAD-V2-back.PNG" alt="Avionics bay V2 back" style="float: right; width:30%; height:50%; margin-left: 10px;" />
The avionics bay is mostly finalized, and I will attempt to print this soon; I’ve done without the 18650 battery and kept the 3s LiPo which is now housed in a casing at the top of the avionics bay. The LoRa module is now positioned such that an antenna can be directly attached to the module and have space in the rocket fuselage. The only thing lacking from the model to the right is a relay holder to ignite the second stage. I still need to remodel the nose cone since the current GPS holder may not have clearance, so it must be shifted upwards after which I will begin 3D printing these components and assembling the rocket!</p>

<h1 id="update-feb-2022">UPDATE Feb 2022</h1>

<p><img src="/assets/img/habibi-express/rocket-CAD.PNG" alt="Rocket model" style="float: right; width:50%; height:50%; margin-left: 10px;" />
CAD model is now mostly finished, lots of small things still need to be figured out however most of the grunt work is done. I don’t have a concrete plan for how to wire the main stage motor’s igniter in a way that won’t risk tangling the parachute during recovery. Furthermore, I purchased two G80-7T motors however the rocket will need at least 10 seconds after the main stage burns out to reach its apogee meaning that I most likely need to source a G80-13T motor to avoid using any complex recovery mechanisms. Unfortunately, <a href="https://www.greathobbies.com/">Great Hobbies</a> does not carry G80 motors anymore, so I can only source these for unreasonably high prices from <a href="https://www.allrockets.ca/G80-13">AllRockets</a>.</p>

<p><img src="/assets/img/habibi-express/avionics-CAD.PNG" alt="Avionics model" style="float: right; width:30%; height:50%; margin-left: 10px;" />
Main focus now is the avionics bay. The model pictured here has space for an Arduino Mega 2560 (embed), a BMP280, an MPU6050, a LoRa SX1278 transceiver, and two batteries. The nose cone contains a GPS antenna bracket for positioning as well. This is the second iteration of the avionics bay, and it contains space for both an 18650 Li-Ion cell (in green) and a small 3S 700mAh LiPo next to the Li-Ion cell. I’m concerned that the ~3V from the 18650 will not be enough to ignite the main stage of the rocket even with a boost converter which is why I included the LiPo. I originally considered using the 18650 in light of its higher energy density however it only has roughly 1.5 times the energy stored by the LiPo so it will likely be discarded in the next iteration.</p>

<h1 id="update-dec-2021">UPDATE Dec 2021</h1>
<p>Rocket design was finalized in <a href="https://openrocket.info/">OpenRocket</a> and basic simulation was done; maximum altitude estimated at roughly 1.1km with a max speed of Mach 0.52. I made some faster designs and others with higher apogees, but this model seems the most predictable based on how much tech I want to fly with the rocket and how lightly I can manufacture things.</p>

<p><img src="/assets/img/habibi-express/open-rocket-sim.PNG" alt="OpenRocket Model" />
<img src="/assets/img/habibi-express/open-rocket-sim-graph.PNG" alt="OpenRocket Simulation" /></p>]]></content><author><name>Serban Popovici</name></author><summary type="html"><![CDATA[Experimenting with rocketry electronics]]></summary></entry><entry><title type="html">LoRa Sensor Suite</title><link href="http://localhost:4000/lora-sensor-suite/" rel="alternate" type="text/html" title="LoRa Sensor Suite" /><published>2022-10-16T00:00:00-04:00</published><updated>2022-10-16T00:00:00-04:00</updated><id>http://localhost:4000/lora-sensor-suite</id><content type="html" xml:base="http://localhost:4000/lora-sensor-suite/"><![CDATA[<h2 id="a-scalable-dynamic-solution-for-monitoring-activity-in-unknown-environments">A scalable dynamic solution for monitoring activity in unknown environments</h2>

<p>At some point in 2021, a friend and I had just finished exploring a construction site and as we were preparing to leave on the first floor, a security guard haphazardly walked in. Luckily we were out of sight and managed to get away undetected, but this presented a need for a system capable of monitoring activity within an uncontrolled environment. So far I have only built PIR sensors for this purpose though I intend to build tripwires and possibly audio sensors.</p>

<h1 id="update-november-2022">UPDATE November 2022</h1>

<p><img src="/assets/img/lora-sensor-suite/PIR-V3-front.jpg" alt="Second generation sensor" style="float: right; width:50%; height:50%" />
Forgot about this project for a while however I have decided to redesign the sensors to incorporate more functionality. I purchased a few ESP-CAM modules off of AliExpress and redesigned the sensors to fit these modules. The new iteration can now detect Bluetooth devices (the last generation was supposed to do this, but I only had ESP-12E modules on hand) and can now send pictures alongside motion and Bluetooth alerts. Further improvements will include adding a buzzer and possibly LEDs such that the sensors can generate distractions. The new design has two external antennas, one for the LoRa transceiver and another for WiFi, which I chose to keep exposed solely for the aesthetic. Future versions may internalize the WiFi antenna since I see no benefit in having it exposed.</p>

<h1 id="update-feb-2022">UPDATE Feb 2022</h1>

<p><img src="/assets/img/lora-sensor-suite/PIR-V2-front.PNG" alt="Front" style="float: right; width:50%; height:50%" />
I’ve decided to migrate from an Arduino to an ESP32 module; this CAD design has space for an ESP32-WROVER module. The reasoning behind this change is that an ESP32 module can be used to pick up bluetooth devices nearby which would allow the attacker to configure the device with their cell phone 
<img src="/assets/img/lora-sensor-suite/PIR-V2-back.PNG" alt="Back" style="float: right; width:50%; height:50%" /> 
and can be used to pick up unknown devices and send alerts even if the sensor itself fails to trip.</p>

<p>The current design does not have space for a battery management circuit and will need to be reiterated, but it does successfully house the LoRa SX1278, 18650, and PIR sensor. The general shape of the sensor allows for it to be placed on the floor with the PIR facing 45 degrees upwards, or it can be flipped and placed on top of a cabinet, for example, with the PIR facing 45 degrees downwards. The next iteration will likely also include magnets such that the sensor can attach to metallic cabinets, metal handrails on stairs, light fixtures, etc. I also took apart one of the 433MHz antennas and noticed that at least 10mm of the rubber housing is left empty meaning that I could omit the rubber housing in future designs to save space.</p>

<h1 id="basic-idea">Basic Idea</h1>

<p>Each sensor runs off of an 18650 Li-Ion cell with a battery protection circuit that enables USB charging and maintains the cell voltage within its acceptable range. Each sensor has an Arduino Nano with a LoRa SX1278 transceiver in addition to its sensing equipment. LoRa modules are ideal since they act as a mesh network and these sensors are intended for use within concrete buildings thus signals will have difficulty traveling far. An additional LoRa module with a high gain antenna connects the LoRa mesh network to the attacker’s phone or some other notification method. Due to the RF challenges faced by these sensors, they should transmit repeatedly once triggered until the attacker’s device is able to acknowledge the signal. Based on experimentation, the LoRa modules I own do not natively do this.</p>

<h2 id="sensor-construction">Sensor Construction</h2>

<p><img src="/assets/img/lora-sensor-suite/PIR-V1-front.png" alt="Front" style="float: right; width:50%; height:50%" />
Pins 0 and 1 of the Arduino are used for serial communication with the LoRa module (the RX pin of the LoRa module must be disconnected when code is uploaded to Arduino). Pin A0 is for the pair button and other pins are used as required for the relevant sensor. 
<img src="/assets/img/lora-sensor-suite/PIR-V1-back.png" alt="Back" style="float: right; width:50%; height:50%" /> 
Pins M0 and M1 on the module are shorted to ground in order for the module to transmit. The whole assembly is currently zip tied together in a rather minimalist form factor for software development, but future versions will be housed in 3D printed casings.</p>

<h2 id="communication-protocol">Communication Protocol</h2>

<p>Each sensor broadcasts an ‘alive’ packet once the pair button has been pressed; this packet contains a unique ID based on the microcontroller’s serial number to differentiate its ‘alive’ packet from that of other sensors. Alive packets are repeated up until the sensor receives an acknowledgment packet from the head unit in which the head unit will assign a numerical value to the sensor between 0 and 9998. The user is then able to assign a more descriptive identifying string to the sensor so that its location can be more apparent. Upon being triggered, the sensor will begin broadcasting a packed in the form of “SENSOR_ID:PACKET_ID:TRIG_VAL” where</p>
<ul>
  <li>PACKET_ID is a unique integer identifying the packet to ensure the head unit doesn’t register the same alert twice</li>
  <li>TRIG_VAL is an integer representative of the sensor’s states</li>
</ul>

<p>This packet is repeated every 0.5 seconds up until the sensor receives a packet from the head unit in the form of “9999;SENSOR_ID;PACKET_ID” where</p>
<ul>
  <li>9999 is the equivalent SENSOR_ID for the head unit</li>
  <li>SENSOR_ID is the id of whichever sensor tripped</li>
  <li>PACKET_ID is the packet id</li>
</ul>]]></content><author><name>Serban Popovici</name></author><summary type="html"><![CDATA[A scalable dynamic solution for monitoring activity in unknown environments]]></summary></entry><entry><title type="html">BRZ VIM4</title><link href="http://localhost:4000/brz-VIM4/" rel="alternate" type="text/html" title="BRZ VIM4" /><published>2022-10-01T00:00:00-04:00</published><updated>2022-10-01T00:00:00-04:00</updated><id>http://localhost:4000/brz-VIM4</id><content type="html" xml:base="http://localhost:4000/brz-VIM4/"><![CDATA[]]></content><author><name>Serban Popovici</name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Modernizing my 2013 Subaru BRZ</title><link href="http://localhost:4000/brz/" rel="alternate" type="text/html" title="Modernizing my 2013 Subaru BRZ" /><published>2022-10-01T00:00:00-04:00</published><updated>2022-10-01T00:00:00-04:00</updated><id>http://localhost:4000/brz</id><content type="html" xml:base="http://localhost:4000/brz/"><![CDATA[<p>I recently acquired a car for recreational purposes since I had saved up a decent amount of money and didn’t feel like investing it. I purchased a BRZ because they are built in conjunction with Toyota and this should theoretically imply that they are relatively reliable and I won’t need to worry about the mechanical aspects of the vehicle. Furthermore, the BRZ’s interior is driver-centered while maintaining a relatively simple geometry that should facilitate the design of custom dash components to fit my upgraded electronics.</p>

<p>This project began as a way to disguise speed enforcement countermeasures within the car’s UI seeing as radar/lidar countermeasures are illegal in Ontario. As such, I figured that the best way to hide illegal features would be to program the UI myself. Seeing as the current head unit is only capable of playing back bluetooth audio, it’s very unlikely that anything I do will result in less overall functionality so there really is nothing to lose here.</p>

<p>A lot of work has gone into the project so I have split up this post to include a variety of sub-pages detailing individual subsystems in greater detail. This page serves to provide a general overview of the project and a set of links to sub-pages is included below:</p>
<ul>
  <li><a href="/brz-head-unit">Head Unit</a></li>
  <li><a href="/brz-user-interface">User Interface (Software)</a></li>
  <li><a href="/brz-steering-wheel">Steering Wheel</a></li>
  <li><a href="/brz-light-link">LightLink Module</a></li>
</ul>

<h1 id="idea">Idea</h1>

<h2 id="ui-enhancements">UI Enhancements</h2>

<p><img src="/assets/img/brz/planned_display_layout.jpg" alt="Picture of plan" style="float: right; width:50%; height:80%; margin-left: 10px;" /></p>

<p>The plan is to replace the head unit of the BRZ with a <a href="https://www.aliexpress.com/item/1005003546521274.html">12.3” touch-screen</a>, replace the small button cluster on the center console with a <a href="https://www.aliexpress.com/item/4000393713339.html">7” touch screen</a>, and convert the analog gauge cluster to a display. The 12.3” display will be used for most vehicle functionality such as navigation and media whereas the 7” display will provide diagnostic information about the vehicle as well as any subsystems I add.</p>

<p>The car will have an LTE modem in it to provide WiFi connectivity for passengers and allow its internal computers to access Google Maps, media streaming services, and other resources such as the Waze database to protect against police encounters. Finally, I hope to add cameras all around the car and experiment with computer vision though, aside from collision warnings and enhanced cruise control I’m not sure what I’ll be able to code. The cameras will however provide a 360-degree dash cam and I will be able to use them for a Tesla-like sentry mode when the car is locked. Furthermore, it may be interesting to experiment with augmented reality headsets in the future to provide the driver with enhanced situational awareness but this is not in the works as of this writing.</p>

<h2 id="speed-enforcement-countermeasures">Speed Enforcement Countermeasures</h2>

<p>I’m hoping to, at the very least, add passive sensors for radar/lidar and aircraft but I may not be able to add active countermeasures such as radar/lidar jamming. Based on some brief research, there is a significant risk that a radar/lidar device would detect my jamming attempts seeing as many of them have jamming detection built in. Proper commercial jammers are designed to identify the specific make/model of a lidar gun and behave accordingly however they are rather cost-prohibitive so I may not be able to reasonably source a commercial system.</p>

<p>Aircraft countermeasures are more reasonably achievable since aircraft speed detection works using lines painted on the pavement at a known distance interval such that an aircraft flying above can time a vehicle crossing a set of these lines. My plan for countering this is to use a front facing camera on the car to pick up the lines at which point an onboard computer will use a software defined radio to look for any aircraft transponders within a certain radius of the vehicle. Should there be an aircraft nearby, the onboard computer will begin calling out speeds for the user to match in hopes that the average speed across the two lines does not exceed the posted limit.</p>

<p>An even more complex countermeasure I’m hoping to integrate is cellular sniffing where a computer would once again use a software defined radio to look for nearby cellular devices and fingerprint them to single out the specific make and model of cellular modem present in a Ford Interceptor. I’m unsure if this is even theoretically possible since newer cellular devices may encrypt everything including metadata but I intend to research this in depth.</p>

<p>In addition to passive countermeasures and radar/lidar jammers, the vehicle will hopefully have cellular and VHF/UHF jammers. The purpose of these is to prevent a Ford Interceptor’s cellular modem and radio from working when in close proximity to the BRZ meaning that the officer will <em>hopefully</em> be unable to run driver’s licenses or issue tickets.</p>

<h1 id="build">Build</h1>

<h2 id="software">Software</h2>

<p>I initially intended to build a custom image of Android Automotive for the BRZ and develop mobile applications that would mostly run as background services and overlay themselves on top of Android to display relevant information. Unfortunately this turned out to be a rather lucrative task and as of this writing I have elected to build a simple Android application running on a mobile image. The advantages of Android Automotive are as follows:</p>
<ul>
  <li>Better navigation with fully functional Google Maps (Android applications cannot have integrated navigation activities and can only display 2D maps as far as I am aware)</li>
  <li>Better media controls with proper Bluetooth integration (the Android Mobile OS cannot be used as a A2DP sink without modifying the source code)</li>
  <li>Better boot times</li>
</ul>

<p>Overall, I did not feel these advantages were enough to justify the increased complexity of building a custom Android Automotive image especially considering how many custom UI screens and functions I intend to incorporate as well as my lack of affinity for hardware-level programming.</p>

<p>The purpose of rebuilding the vehicle’s UI is not only to provide a seamless means of interacting with the additional functionality but also to fully hide any illegal functions on demand. As such, a ‘legal mode’ will be integrated in the software which will be activated on boot and will hide all illegal functionality from the vehicle’s UI. The driver can disable legal mode using an arbitrary set of seemingly random keystrokes using buttons throughout the car’s interior which will be intricate such that they cannot be haphazardly entered.</p>

<h2 id="hardware">Hardware</h2>

<h3 id="computers">Computers</h3>

<p>The UI of the car is handled by two primary computers (a Raspberry Pi 4B and a <a href="https://www.khadas.com/vim4">Khadas VIM4</a>) whereas the hardware modifications are handled by a varity of Arduinos integrated throughout the vehicle. The Khadas VIM4 was not my first choice, I wanted a nVidia Jetson, however I purchased this during the height of the pandemic meaning that the chip shortage was in full stride and I could not find a reasonably-priced Jetson powerful enough for my application.</p>

<p>The Raspberry Pi runs Android and controls the head unit and center console displays which function in tandem to deliver the interactive component of the vehicle’s UI whereas the VIM4 runs Linux and does most of the heavy lifting. The RPi does not handle any logic and interacts with the VIM4 using a series of web services. The VIM4 handles a variety of tasks including Bluetooth media playback, camera feed management, and CANBUS communication. More information can be found <a href="/brz-VIM4">here</a>.</p>

<p>Most of the hardware modifications are executed by Arduinos integrated throughout the vehicle that share its CANBUS. The list of integrated Arduinos as well as the model used is as follows:</p>
<ul>
  <li>LightLink (2xMEGA_EMBED) –&gt; Used to control all exterior vehicle lights, more info <a href="/brz-light-link">here</a>.</li>
  <li>Mirror manager (NANO) –&gt; Keeps track of mirror position and allows them to automatically tilt when backing up. One per mirror.</li>
  <li>Diagnostic display button manager (NANO) –&gt; Controls MOSFETs that simulate button presses to maintain functionality of old center console buttons.</li>
  <li>Steering wheel button manager (NANO) –&gt; Converts steering wheel button presses into CAN messages for head unit.</li>
</ul>

<h3 id="cameras">Cameras</h3>

<p>The planned camera layout is included below. The green semicircles are <a href="https://www.aliexpress.com/item/1005004337827464.html">136-degree FOV cameras</a> installed in the front windshield and above the rear license plate whereas the gray circles represent <a href="https://www.aliexpress.com/item/1005004335144138.html">210-degree cameras</a> (the listing says 180 degrees but they are actually 210) installed beneath the side view mirrors of the car (PIC). I planned on including a second front-facing camera on the right wing mirror to provide the driver with insight about any vehicles in the right lane ahead of the car however this camera is not included at this time since the 210-degree FOV camera installed beneath the mirror should theoretically capture all vehicles in the right lane.</p>

<p><img src="/assets/img/brz/camera_layout.png" alt="Camera layout" /></p>

<p>Beyond the cameras used for 360 degree coverage, both fog lights of the vehicle contain camera modules with the driver side being a thermal camera and the passenger side being a Sony Starvis low light camera with optical zoom. These are meant to be used in conjunction with AI to detect threats on the road ahead as well as to provide increased visibility in low light conditions. A final camera is installed inside the vehicle and faces the driver for eye tracking such that the touch screen functionality of the center console display is disabled unless the driver is looking at the display to prevent accidental inputs (might not be included after all, depends on whether accidental input truly is an issue).</p>]]></content><author><name>Serban Popovici</name></author><summary type="html"><![CDATA[I recently acquired a car for recreational purposes since I had saved up a decent amount of money and didn’t feel like investing it. I purchased a BRZ because they are built in conjunction with Toyota and this should theoretically imply that they are relatively reliable and I won’t need to worry about the mechanical aspects of the vehicle. Furthermore, the BRZ’s interior is driver-centered while maintaining a relatively simple geometry that should facilitate the design of custom dash components to fit my upgraded electronics.]]></summary></entry><entry><title type="html">BRZ Steering Wheel</title><link href="http://localhost:4000/brz-steering-wheel/" rel="alternate" type="text/html" title="BRZ Steering Wheel" /><published>2022-10-01T00:00:00-04:00</published><updated>2022-10-01T00:00:00-04:00</updated><id>http://localhost:4000/brz-steering-wheel</id><content type="html" xml:base="http://localhost:4000/brz-steering-wheel/"><![CDATA[<h3 id="steering-wheel-button-integration">Steering Wheel Button Integration</h3>

<p>Steering wheel buttons were added to BRZs in 2017 and mine is a 2013 so I purchased a salvage steering wheel in order to integrate its buttons into my systems. Should anybody else contemplate to do the same, be aware that even though steering wheels are cheap the airbag most certainly is not: a brand new OEM airbag for my car is $CAD 1100 from the dealer while a used one is ~$CAD 600.</p>

<p>The steering wheel uses an Arduino Pro Micro to convert button presses into keyboard output for the Khadas VIM4 to understand. Furthermore, it connects to the CANBUS to forward hardware-related commands to decrease latency as opposed to transferring commands from the VIM4 to other devices. In order to interface the Arduino with the steering wheel, I took apart the button clusters on each side of the 
<img src="/assets/img/brz/steering_wheel_button_connector.jpg" alt="Steering wheel button connector" style="float: right; width:50%; height:80%; margin-left: 10px;" />
steering wheel and followed traces to figure out the function of each wire. My findings are listed below for anybody else intending to reverse engineer the steering wheel buttons on a BRZ (wires are listed from left to right, top to bottom, looking at the connector from behind as depicted to the right):</p>
<ul>
  <li>Light green –&gt; Volume and arrow keys of left side cluster</li>
  <li>Red –&gt; Common of left side cluster</li>
  <li>Green –&gt; Arrow keys of right side cluster</li>
  <li>Purple –&gt; Enter and back key of right side cluster</li>
  <li>Yellow –&gt; Common of right side cluster</li>
  <li>Black –&gt; Call buttons, source button, left enter button, and voice button</li>
  <li>Blue –&gt; Steering wheel ground</li>
  <li>Brown –&gt; Cruise control pin 1</li>
  <li>Grey –&gt; Cruise control pin 2</li>
  <li>Black + White –&gt; LED ground</li>
  <li>White –&gt; LED VCC (5V works but dim. Not sure I’m willing to go higher so I’ll suck it up)</li>
</ul>

<p>The ‘voice’ button on the right side of the steering wheel is wired to the left button cluster and its state is transmitted through the (light green or black) wire. Button states are transmitted by varying the resistance between the common pin of each button cluster and one of the two output pins of each button cluster. The Arduino interprets these using an analog pin using the INPUT_PULLUP pin mode with the common pins being connected to ground. The resulting resistance and output wire for any button press is listed below in hopes of saving someone else the effort required to decode these circuit boards though I ended up using analogRead values in my code so these are useless to me.</p>

<table>
  <thead>
    <tr>
      <th>Left Side Cluster</th>
      <th>Right Side Cluster</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Source –&gt; 115 Ohm BLACK</td>
      <td>Up –&gt; 330 Ohm GREEN</td>
    </tr>
    <tr>
      <td>Call pickup –&gt; 425 Ohm BLACK</td>
      <td>Right –&gt; 3.1 kOhm GREEN</td>
    </tr>
    <tr>
      <td>Call hangup –&gt; 225 Ohm BLACK</td>
      <td>Down –&gt; 1 kOhm GREEN</td>
    </tr>
    <tr>
      <td>Volume up –&gt; short LIGHT GREEN</td>
      <td>Left –&gt; short GREEN</td>
    </tr>
    <tr>
      <td>Volume down –&gt; 50 Ohm LIGHT GREEN</td>
      <td>Enter –&gt; 100 kOhm PURPLE</td>
    </tr>
    <tr>
      <td>Right –&gt; 115 Ohm LIGHT GREEN</td>
      <td>Back –&gt; 101 kOhm PURPLE</td>
    </tr>
    <tr>
      <td>Left –&gt; 245 Ohm LIGHT GREEN</td>
      <td>Voice –&gt; 50 Ohm BLACK</td>
    </tr>
    <tr>
      <td>Enter –&gt; short BLACK</td>
      <td> </td>
    </tr>
  </tbody>
</table>]]></content><author><name>Serban Popovici</name></author><summary type="html"><![CDATA[Steering Wheel Button Integration]]></summary></entry><entry><title type="html">BRZ LightLink</title><link href="http://localhost:4000/brz-light-link/" rel="alternate" type="text/html" title="BRZ LightLink" /><published>2022-10-01T00:00:00-04:00</published><updated>2022-10-01T00:00:00-04:00</updated><id>http://localhost:4000/brz-light-link</id><content type="html" xml:base="http://localhost:4000/brz-light-link/"><![CDATA[<h2 id="rgb-ftw">RGB ftw</h2>

<h2 id="lightlink-overview">LightLink Overview</h2>

<p>Control of a vehicle’s external lighting is safety critical and I did not feel comfortable half-assing a solution to handle this considering the hardware upgrades to the vehicle. As a result, I’ve settled on designing a custom circuit board with 12 MOSFET channels to handle ‘dumb’ lights and 8 addressable channels to handle a set of addressable LED arrays retrofitted throughout the vehicle.</p>

<h3 id="redundancy-considerations">Redundancy Considerations</h3>

<p>Given its safety critical function, this board was built with redundancy in mind and includes two of each component required for nominal operation. The MOSFET channels are designed as per the schematic below:</p>

<p>MOSFET SCHEMATIC</p>

<p>Two MOSFETs are included in parallel, both of which are immediately followed by a Schottky diode to prevent backflow from the other MOSFET. This is necessary because a diagnostic pin is included prior to the Schottky. The diagnostic connections use a summing amplifier with a op-amp IC as pictured below such that the output signal ranges between 0V and 3V with the Qx MOSFET contributing 80% of the output voltage and Qx only contributing the other 20%. This allows the microcontroller to detect the functionality of each individual MOSFET regardless of their parallel arrangement.</p>

<p>MOSFETS SCHEMATIC</p>

<p>For control, two Arduino Mega EMBEDs are inclded. These were chosen because I have about a dozen on hand right now and they have been reliable in my experience. Regardless, two Arduinos with separate CAN transceivers are included on the board as depicted in the schematic below:</p>

<p>OVERALL SCHEMATIC</p>

<p>At any given moment, one of the Arduinos is considered the ‘master’. The master is in charge of outputting signals to the MOSFET and addressable channels while simoultaneously communicating its state over to the slave Arduino over a UART connection. The master updates the slave at regular intervals such that the updates themselves function as ‘heartbeat’ signals assuring the slave that the master is operating optimally. Should the master miss a heartbeat for whatever reason, the slave sends a hardware reset pin to the current master after which it assumes the master role and resumes signal outputs based on the last state update it received over UART. This system also allows the Arduinos to swap roles ever 30 days since my asynchronous code uses the millis() function to keep track of time and its value will exceed the maximum possible variable size in approximately 50 days.</p>

<h3 id="lighting-modifications">Lighting Modifications</h3>

<p>Some modifications require extensive control of the vehicle’s lights however I am not willing to alter anything about the car’s computers so my solution consists of placing relays along the wiring harnesses controlling the vehicle’s lights with two separate computers on each end of the car. Each computer has a combination of mechanical and solid state relays depending on how frequently a light is expected to toggle on/off. Mechanical relays are used for lights that rarely toggle and because they provide a normally closed and normally open set of contacts. This is important because the lighting computers receive constant power regardless of the vehicle’s state and therefore power draw must be minimized when the vehicle is not running.</p>

<p><img src="/assets/img/brz/rear_light_manager.jpg" alt="Rear light manager computer" style="float: right; width:50%; height:80%; margin-left: 10px;" /> The rear lighting computer is pictured to the right and I expect the front computer to be highly similar. It uses four solid state relays (top left) to drive the brake lights and turn signals of the car by connecting them to the car’s battery. The third and fourth brake light of the car (third is in the windshield and fourth is F1 style in bumper) are converted to addressable LEDs and do not require relays. Addressable LEDs have also been integrated into the reverse lights (two lights adjoined to the fourth brake light) and the two rear quarter panel windows of the car. Excluding the solid state relays, the computer contains two mechanical relays (bottom left) for running lights, a CANBUS module (bottom right), an Arduino (top right), and a 5V regulator on the backside. Currently, this computer turns lights on based on whether or not live data is being sent across the CANBUS since it is always powered and I have not yet figured out what value represents the stte of the vehicle’s running lights. This is not ideal since a side effect of my current solution is that running lights turn on when doors open or the car is unlocked etc.</p>]]></content><author><name>Serban Popovici</name></author><summary type="html"><![CDATA[RGB ftw]]></summary></entry><entry><title type="html">BRZ Head Unit</title><link href="http://localhost:4000/brz-head-unit/" rel="alternate" type="text/html" title="BRZ Head Unit" /><published>2022-10-01T00:00:00-04:00</published><updated>2022-10-01T00:00:00-04:00</updated><id>http://localhost:4000/brz-head-unit</id><content type="html" xml:base="http://localhost:4000/brz-head-unit/"><![CDATA[<h3 id="cad">CAD</h3>

<p>The retrofit brackets for this vehicle were designed by first measuring and modelling the mount points to the vehicle before extruding a general shape to house all the required components. The components are then arranged on the aforementioned general shape such that their screw holes/mount points can be cut after which the bulk of the material is removed leaving a barebones structure which can be further broken down into smaller pieces to facilitate manufacturing.</p>

<p>The head unit bracket is a perfect example of this technique. The design was built symmetrically, and as such, I began by modelling the left side before mirroring it to generate the entire assembly. I knew I would need two ‘platforms’ to house all the required components so I began by measuring the mount hole positions from the old head unit and generating two basic mount ‘ears’ before extruding an arbitrary platform attached to each ear. The platforms were extended an arbitrary amount in both directions based on how much space I estimated to be available inside the vehicle’s cavity and how far the head unit display would be mounted. The head unit bracket holds the following hardware as can be seen in the <em>PIC</em> to the right:</p>

<ol>
  <li>Head unit display</li>
  <li>Head unit display driver</li>
  <li>Khadas VIM4</li>
  <li>Voltage regulator</li>
  <li>Driver-facing camera</li>
</ol>

<p>No amp needed up front since it’s in the trunk from factory. That being said it only drives the front speakers and I can’t figure out how the rear side speakers are powered so there may be more amplifiers throughout the vehicle. I also need to include an amplifier for a loudspeaker up front which may end up in the head unit if there is space.</p>]]></content><author><name>Serban Popovici</name></author><summary type="html"><![CDATA[CAD]]></summary></entry><entry><title type="html">LTE Mavic Pro</title><link href="http://localhost:4000/lte-mavic-pro/" rel="alternate" type="text/html" title="LTE Mavic Pro" /><published>2022-09-03T00:00:00-04:00</published><updated>2022-09-03T00:00:00-04:00</updated><id>http://localhost:4000/lte-mavic-pro</id><content type="html" xml:base="http://localhost:4000/lte-mavic-pro/"><![CDATA[<p>Cellular-based drone control has been a longstanding goal with the purpose of creating UAVs requiring minimal user input to function. I have found the need for constant input to significantly reduce the useability of drones for recon during my adventures because neither myself nor the people with me can dedicate significant attention to piloting them. This project aims to achieve basic autonomous control through an Android application that allows the user to place the drone at specific coordinates or land it. The first rendition was built to be submitted as an electronics project for a university course and is solely capable of navigation; takeoff and landing must be manually with a separate remote controller. This is because a F1 flight controller was used which is only capable of managing stability.</p>

<h1 id="basic-idea">Basic Idea</h1>

<p>The drone will be centered around a Raspberry Pi Zero and a LTE modem for internet access. A Raspberry Pi CM4 could fit and would be beneficial but I am not currently capable of developing carrier boards and a full size Raspberry Pi will not fit. The Pi’s serial port is dedicated to communicating with the flight controller through iBus since iBus operates at 115200 baud and bit bashing on the Pi becomes unreliable past 19200 baud. The GPS data will be received using a GPIO pin and bit bashing and another bit bashing serial connection will be used to communicate with an Arduino. The Arduino serves as an IO expander for the Pi to manage the LEDs on the drone as well as an ultrasonic sensor and sense voltage and current throughout the drone. Using an Arduino as such is advantageous since it has an ADC whereas the Pi does not. Additionally, offloading time-sensitive operations such as reading the ultrasonic sensor and running the drone’s LED patterns decreases the complexity of the Pi’s code.</p>

<h2 id="data-link">Data Link</h2>

<p>My current LTE modem filters all ports no matter what settings I chose within its menu. For this reason, I’ve elected to use a P2P UDP protocol which is able to punch through firewalls. A second Raspberry Pi will serve as an intermediary P2P server to connect the cell phone and drone given that neither has a static IP. The P2P code was largely copied from https://github.com/grakshith/p2p-chat-python.git and modified to better fit my protocol. Both the drone and cell phone should identify themselves during their initial UDP broadcast in order to identify what function they serve; this future proofs the server’s code since I can selectively connect devices based on functionality as opposed to the time at which they contact the server. Once two compatible hosts have broadcast their address/port to the P2P server, they will each receive the address/port of the other client and the server logs the connection before discarding all saved host data.</p>

<h2 id="flight-algorithm">Flight Algorithm</h2>

<p>The version submitted for my course uses a rather primal flight algorithm in which the Pi has a barometer and compass connected to it through I2C. Using GPS, compass, and altitude data the Pi is able to compute a vector from its current coordinates to the target coordinates using the haversine libary for Python and a bearing function I stole from StackExchange. It then points the drone in the target direction and goes forward; the drone’s speed varies based on distance to target and it progressively slows down as the distance decreases. The current version offloaded all navigation to the flight controller running iNav thereby reserving the Pi’s looptime for more useful functions such as WiFi, cellular, and UHF sniffing. OpenCV can also be used on the Pi to provide some level of active tracking and increase the effective autonomy of this platform. For this, I may need to choose a UAV platform with surround cameras such as the Mavic 2 or Skydio 2 and upgrade to an nVidia Jetson computer since having the drone actively follow subjects would require some level of obstacle avoidance.</p>

<h1 id="update-feb-2022">UPDATE Feb 2022</h1>

<p>Obtained a SucceX-D Mini F7 Twin G stack and redesigned the 3D printed bracket which holds all the electronics inside the Mavic. 
<img src="/assets/img/hacked-mavic/board-mount-V3.PNG" alt="Bracket V2" style="float: right" />
The new design no longer requires tape and glue but rather relies on three pre-existing screwholes used by the original DJI flight control board. It took a few revisions to finalize the fit of the board such that the components comfortably fit within the restricted space originally occupied by DJI’s proprietary electronics. This is the fifth revision of the bracket and it includes mount points for a 4-in-1 ESC board, flight controller, the Raspberry Pi, and a Flysky receiver. I’m sticking with the Flysky receiver over a Crossfire system since it is able to take advantage of the 2.4 GHz antennas already integrated in the Mavic leading to a more ‘stock’ look. The 4-in-1 ESC board is on the bottom such that it can be in contact with the bottom heatsink of the Mavic and hopefully take advantage of it. Realistically, this ESC board is rated for 45A per motor which is likely over double what the motors should be drawing. Finally, I have decided to remove the Arduino since I should be able to accomplish its tasks with threaded processes on the RPi. In doing so, I am now once again able to install the OEM gimbal on the drone and, since the DJI Mavic’s camera seems to use MIPI, I should be able to interface it with the RPi (I haven’t yet tested the camera’s protocol but its connector looks identical to that of the Caddx Polar camera I own).</p>

<p>Unfortunately I still do not have a compact cellular modem and I am not sure where I will be able to fit it. I also need to create a custom target to flash the F7 board with iNav since I don’t believe Betaflight is capable of executing waypoint missions through telemetry but I will see if that’s a possibility. I also need to figure out if the flight controller is able to arm and takeoff without any contribution from the receiver since I only intend to keep it for debugging/testing purposes and it is not intended to be used during regular operation.</p>

<h1 id="update-dec-2021">UPDATE Dec 2021</h1>

<p>Initial bracket designs relied on double sided adhesive and a small bracket to effectively hold down all the internals. 
<img src="/assets/img/hacked-mavic/board-mount-V1.PNG" alt="Bracket V1" style="float: right" />
This design makes maintenance virtually impossible without considerably disassembling the drone so current versions use existing screwholes to ensure a more secure fit. The varying boards within the Mavic are installed as follows:</p>
<ul>
  <li>The flight controller is installed sideways on the front of the bracket immediately following the pre-existing fan</li>
  <li>A 20x20mm 20A ESC board is installed immediately following the flight controller on the underside of the bracket. This allows for thermal pads to be placed between the ESCs and the Mavic’s pre-existing heatsink thereby providing some cooling.</li>
  <li>Following the ESC, the LTE modem and an Arduino Nano are installed on the bottom of the board.</li>
  <li>The top of the bracket is exclusively reserved for the Raspberry Pi Zero. Ideally, the Pi would be on the bottom so that the heatsink could cool it but unfortunately the ultrasonic sensors make this difficult so I had to place it on top. Fortunately, the Pi Zero does not need any cooling so I will keep it like this for future designs.</li>
  <li>Finally, a FlySky i6X receiver is shoved within the wiring towards the end of the drone body for debugging purposes.</li>
</ul>

<p><img src="/assets/img/hacked-mavic/build-V1.jpg" alt="Mavic Build V1" /></p>

<h1 id="code">Code</h1>

<h2 id="raspberry-pi">Raspberry Pi</h2>

<p>The Raspberry Pi runs off of a Python program split into four key files:</p>
<ul>
  <li><strong>main.py</strong> –&gt; this file is what runs upon startup. It calls upon the other three and synchronizes data between files (takes updated target coordinates from network.py and sends them to flight.py)</li>
  <li><strong>network.py</strong> –&gt; this file handles all P2P communication and is responsible for maintaining a link with the cell phone. It receives target coordinates and saves them in a local variable which is then queried by main.py</li>
  <li><strong>flight.py</strong> –&gt; handled flight algorithm in implementation for my course however <strong>TODO</strong> current version dispatches target coords to the flight controller and monitors telemetry data so it can be passed on to the Android application</li>
  <li><strong>misc.py</strong> –&gt; contains random functions used by all files such as logging</li>
</ul>

<h2 id="arduino">Arduino</h2>

<p>Pins A0 and A1 are used for detecting voltage from the battery and the 5V rail. Pins 2 and 13 are used as digital outputs for controlling the LEDs on the left and right front arms of the Mavic, respectively. Pin 8 is used for the LEDs throughout the drone which are single WS2812b pixels while pins 5 and 6 are used to monitoring the ultrasonic sensor. The LED patterns were done by keeping track of loop time: every time an LED pattern begins the value of millis() is saved in cycleStartTime, and for every time the code runs the current output is compared to cycleStartTime. Each cycle has an arbitrary time step, for example a cycle may have 8 time steps all of which last 800ms. These time steps are encoded in if statements that compare millis() to cycleStartTime and figure out which time step the cycle should be running. Once all 8 time steps have finished, cycleStartTime is updated to represent the current time and the cycle restarts.</p>

<h2 id="android-studio">Android Studio</h2>

<p>Not sure where exactly to go with the application. Probably gonna open to a full screen map but also have another activity for the drone camera feed/more complex controls. The user will be able to have either activity open full screen or split the screen so both can be viewed at the same time.</p>]]></content><author><name>Serban Popovici</name></author><summary type="html"><![CDATA[Cellular-based drone control has been a longstanding goal with the purpose of creating UAVs requiring minimal user input to function. I have found the need for constant input to significantly reduce the useability of drones for recon during my adventures because neither myself nor the people with me can dedicate significant attention to piloting them. This project aims to achieve basic autonomous control through an Android application that allows the user to place the drone at specific coordinates or land it. The first rendition was built to be submitted as an electronics project for a university course and is solely capable of navigation; takeoff and landing must be manually with a separate remote controller. This is because a F1 flight controller was used which is only capable of managing stability.]]></summary></entry><entry><title type="html">Security Camera Privacy Hack</title><link href="http://localhost:4000/camera-privacy-hack/" rel="alternate" type="text/html" title="Security Camera Privacy Hack" /><published>2022-08-07T00:00:00-04:00</published><updated>2022-08-07T00:00:00-04:00</updated><id>http://localhost:4000/camera-privacy-hack</id><content type="html" xml:base="http://localhost:4000/camera-privacy-hack/"><![CDATA[<h2 id="enhancing-privacy-of-cheap-security-cameras">Enhancing privacy of cheap security cameras</h2>
<h1 id="get-picture-of-whole-camera-to-put-here-as-well">get picture of whole camera to put here as well</h1>

<p>I’ve always been a little paranoid of having IoT devices live streaming views of my living space however I have a long trip coming up so a couple security cameras would be nice to keep an eye on my place. I considered a couple ways of modifying the cameras to provide more privacy:</p>
<ul>
  <li>A Python script that forges HTTP requests and orders the camera to turn around;</li>
  <li>A physical shutter external to the camera that blocks the lens; and</li>
  <li>An internal relay that cuts power to the camera module.
Unfortunately these were not ideal. The first idea was unreliable because turning the camera through a script still allows the camera to turn itself back on its own and may not be reliable should a software update be pushed that depreciates my integration of the camera’s API. The second was not an elegant solution and would be difficult to integrate on a PTZ camera that moves around. Finally, the third did not work because the camera would not come back online after the camera module got disconnected from its motherboard, no matter what I tried. In the end I settled on modifying the camera’s internal IR-CUT filter by covering the IR-CUT part with a sticker and integrating a microcontroller to toggle the state of the filter assembly. This was an elegant and invisible solution that should not noticeably affect image quality since the camera is being used indoors so there should be very little ambient IR light.</li>
</ul>

<p>The privacy mode of these cameras is toggled using a Python service running on a Linux server I have. The script regularly monitors what devices are connected to the local WiFi network, and once a known device is connected, the Python service blinds any security cameras within the apartment.</p>

<h1 id="hardware">Hardware</h1>

<p>While understandably not the most secure way to go about this, I used a few NodeMCU 1.0 modules I had lying around for this project. A more ideal solution would be to either use separate transceivers to air-gap the privacy microcontrollers from the internet or to use a WiFi/Bluetooth capable microcontroller that can sniff and determine what devices are around it. Regardless, the hardware here is relatively simple, the camera has:</p>
<ul>
  <li>A ESP-12E module;</li>
  <li>A WS2812B LED; and</li>
  <li>A MX1508 H-bridge IC.
The MX1508 was needed since the ESP operates at 3.3V however the IR-CUT filter mechanism requires a higher voltage to actuate. The LED provides a hardcoded correlation between the state of the IR-CUT filter and a visual indication of whether the camera is able to see anything.</li>
</ul>

<h1 id="code">Code</h1>]]></content><author><name>Serban Popovici</name></author><summary type="html"><![CDATA[Enhancing privacy of cheap security cameras get picture of whole camera to put here as well]]></summary></entry><entry><title type="html">Smart Holographic Sight</title><link href="http://localhost:4000/smart-sight/" rel="alternate" type="text/html" title="Smart Holographic Sight" /><published>2022-07-25T00:00:00-04:00</published><updated>2022-07-25T00:00:00-04:00</updated><id>http://localhost:4000/smart-sight</id><content type="html" xml:base="http://localhost:4000/smart-sight/"><![CDATA[<h2 id="intelligent-weapon-optics">Intelligent weapon optics</h2>

<p>My overarching goal with a lot of the things I build is to develop a small ecosystem of tactically useful devices that can exchange information and provide the user with an advantage over their adversary. These devices include anything from motorized ascenders to augmented reality devices and UAVs. The SmartSight may work in conjunction with a motorized ascender such that the user can maintain the optic at eye level while also being able to control their ascender. This would provide the ability to keep a weapon tracked on a target while moving up or down the side of a building, for example. The SmartSight idea came about as I saw an old project by a <a href="https://andymeng.dev/">friend</a> of mine and decided to elaborate on it.</p>

<h1 id="basic-premise">Basic Premise</h1>

<p>The SmartSight contains a small display which reflects through a mirrored lens that allows the user to see both the display and the real world, just like a traditional holographic sight. I’m not too sure how much information I will present on the display; so far I intend to display a shot counter and a reticle which can adjust based on weapon cant. Furthermore, I will add indicators that describe the motorized ascender’s state and possibly a rangefinder at the very least. I only intend to use this on airsoft rifles so the rangefinder doesn’t need to be excessively good.</p>

<h1 id="update-jun-2022">UPDATE Jun 2022</h1>
<p>I have been working on this on and off for a while now without updating this page.
<img src="/assets/img/smart-sight/frontV2.PNG" alt="FrontV2" style="float: right; width:50%; height:50%; margin-left: 10px;" />
 I received the new 1.3” displays about a month ago and have generated a new CAD model which accommodates the larger display. The new display covers the majority of the space available on the lens and a shroud was included in this design to ensure that the optic remains viable even when exposed to sunlight. The previous design would likely have suffered in bright environments given how weak the displays are. Below is an updated exploded view of the new design:
<img src="/assets/img/smart-sight/explodedV2.PNG" alt="Exploded View V2" style="display: block; margin-left: auto; margin-right: auto; margin-top: 10px" /></p>

<p>A couple iterations of this design have been printed and all that is left at the moment is to wire up the final version and develop software. Since this design uses an Arduino Nano with its USB port exposed at the back, iterating software should be a piece of cake which can’t be said for the <a href="/lora-sensor-suite/">LoRa Sensor Project</a>.</p>

<h1 id="update-mar-2022">UPDATE Mar 2022</h1>

<p>The last version used a 0.96” 80x160 <a href="https://www.aliexpress.com/item/1005003514645335.html">ST7735S display</a> which has great pixel density but does not manage to cover the whole lens that it’s being reflected through. To rectify the issue, I recently purchased a 1.3” 240x240 <a href="https://www.aliexpress.com/item/4001282467099.html">ST7789 display</a> that is large enough to mostly cover the exposed area of the lens.</p>

<h1 id="update-feb-2022">UPDATE Feb 2022</h1>

<p><img src="/assets/img/smart-sight/front.PNG" alt="Front" style="float: right; width:50%; height:50%; margin-left: 10px;" />
Got around to creating a CAD model of the sight; this model is technically the third iteration but it represents the first reasonably functional version. It has space for an Arduino Nano, LoRa SX1278 transceiver, display, and a LiPo though no antenna mounting hole has been added. Having created this model with a transceiver onboard, I considered the possibility of including a remote kill feature for disabling weapons and as such I will probably need to wire the sight into the gun’s electronics. This means that future designs don’t strictly need to include space for a LiPo but I’m unsure of whether or not I will remove it just yet.</p>

<p><img src="/assets/img/smart-sight/back.PNG" alt="Back" style="float: left; width:50%; height:50%; margin-right: 10px;" />
Unfortunately, this design was built to fit some standardized Picatinny rail dimensions I found <a href="https://upload.wikimedia.org/wikipedia/commons/thumb/9/95/Picatinny.svg/1200px-Picatinny.svg.png">online</a> and these did fit one of the rifles I own but not the functional one. I was picky in finding my dimensions since the design was built all in metric units which may have caused some inaccuracies so the next design will be built using real measurements from the functional rifle. The intent with this design was to stick the antenna out the side of the sight but this is a poor decision considering the wear and tear that the weapon will likely be subjected to so I try to will integrate the antenna within the sight for the next iteration.</p>

<p>Here is an exploded view of this model:
<img src="/assets/img/smart-sight/exploded_noWriting.PNG" alt="Exploded View" style="display: block; margin-left: auto; margin-right: auto; margin-top: 10px" /></p>]]></content><author><name>Serban Popovici</name></author><summary type="html"><![CDATA[Intelligent weapon optics]]></summary></entry></feed>