<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-05-12T17:02:30-04:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Ludicrous Tech</title><subtitle>This website keeps track of whichever projects I am most proud of and serves to share some of the knowledge I accumulate from tinkering on whatever comes to my mind. Enjoy!</subtitle><author><name>Serban Popovici</name></author><entry><title type="html">Two G-class Stage Rocket w/ Basic Telemetry</title><link href="http://localhost:4000/two-stage-rocket/" rel="alternate" type="text/html" title="Two G-class Stage Rocket w/ Basic Telemetry" /><published>2022-11-08T00:00:00-05:00</published><updated>2022-11-08T00:00:00-05:00</updated><id>http://localhost:4000/two-stage-rocket</id><content type="html" xml:base="http://localhost:4000/two-stage-rocket/"><![CDATA[<h2 id="experimenting-with-rocketry-electronics">Experimenting with rocketry electronics</h2>

<p>While I doubt I will ever get a high power rocketry license, I do thoroughly enjoy developing and flying model rockets. None of my past rockets have incorporated any amount of electronics so the purpose of this project is to get a feel for rocketry electronics without any risk by developing only non-terribly-flight-critical components. For this project, I purchased the two biggest rocket engines I can legally get my hands on without any license: AeroTech G80-7T motors.</p>

<h1 id="design">Design</h1>
<h2 id="motor-mounts">Motor mounts</h2>

<p>I watched a <a href="https://www.youtube.com/watch?v=4fhoCt9vXA8">video</a> by ProjectAir on YouTube about a rocket he built using similarly powerful motors and I based my rocket motor mounts on his design. The motor mounts consist of a small tube for the motor and a larger tube that fits snugly into the rocket body. These two are connected by 8 perpendicular supports between the two cylindrical extrusions. The holes on the bottom of this motor mount also work to hold the first stage onto the main stage by using 8 pegs protruding from the first stage which fit snugly into the 8 holes of the motor mount above.</p>

<h2 id="avionics">Avionics</h2>

<p>I intend to have live data logging and telemetry at the very least. This rocket will include a GPS, barometer, and accelerometer as well as an ignition system for the main stage engine. I would also like to include some system that can delay the deployment of the main chute since it will significantly increase the rocket’s drift during recovery however I’m unsure of how reliably I can integrate such a feature. All the electronics will be housed near/in the nose cone and the rocket will separate close to the main stage motor for recovery such that the body tube/nose cone section containing the electronics remains intact.</p>

<h1 id="update-nov-2022">UPDATE Nov 2022</h1>

<p>Project is not on track, too many things going on in school however the avionics bay had been printed and mostly assembled. The nose cone is being redesigned to house status LEDs, the GPS, and two cameras for in-flight footage. Pictures coming soon.</p>

<h1 id="update-oct-2022">UPDATE Oct 2022</h1>

<p><img src="/assets/img/habibi-express/recovery_layout_update.jpg" alt="Recovery layout update" style="float: right; width:10%; height:20%; margin-left: 10px;" /> 
Progress is being made on flight controller firmware, the I2C issue has been fixed, and the IMU data is now being read as well. Turns out the Adafruit BMP280 library was looking for the wrong address and I had to force it to read data from the true address. Engine mounts and fins have been attached to the rocket, currently focused on recovery charge and how to protect the rocket’s internals from the motor’s ejection charge as well as the true ejection charge. The motor mounts have plenty of space around them to allow the motor’s ejection charge gases to escape however I need to add a component following the motor to shield the parachute from the motor’s charge and contain the true ejection charge as well. The planned layout is pictured to the right where the green block represents the blast shield, red represents the true ejection charge, yellow represents the drogue chute, and cyan represents the final chute. The rocket splits between the cyan and yellow blocks when the ejection charge detonates.</p>

<p>The avionics bay has been expanded to include relays for the second stage and ejection charge igniters as well as an SD card reader for data logging, servo to retain the primary parachute, and two DVRs (scrapped the camera inside the body tube). The second stage will be ignited based on the following criteria:</p>
<ul>
  <li>Rocket attitude is within 30 degrees of launch attitude (makes sure the rocket is vertical)</li>
  <li>Rocket altitude is greater than 250 meters (should be 500 meters or so based on simulation)</li>
  <li>Rocket acceleration drops noticeably (simulation suggests peak of 13 Gs however the software will just look for a drop of ~5Gs)</li>
  <li>Launch was detected less than 10 seconds ago (makes sure the conditions cannot be met unless the rocket just took off)</li>
</ul>

<p>Once these conditions are met, the rocket will begin a 3-second timer before igniting the second stage, otherwise the flight controller will do nothing. Apogee will be detected when vertical acceleration drops below -5m/s^2 after which the ejection charge will be ignited. The final chute will be deployed 250 meters above ground level based on barometric data. Launch window has been slightly pushed back however it should be achievable by end of November :)</p>

<h1 id="update-sep-2022">UPDATE Sep 2022</h1>

<p><img src="/assets/img/habibi-express/fin_laser_cutting.jpg" alt="Laser cutting fins" style="float: right; width:30%; height:50%; margin-left: 10px;" />
Finally got around to laser cutting the fins and I have worked slightly on the firmware for the flight controller. Unfortunately I’m having issues with the barometer since it communicates using 3.3V so the Arduino Mega is not able to interpret the I2C data coming from it. The current solution is to replace the barometer with a proven chip that I can find online as working with the Arduino Mega. I will also attempt to read the I2C data using another 5V Arduino to verify that this is indeed the issue. Finally, I have decided to add a few <a href="https://www.aliexpress.com/item/1005002457700952.html">video recorders</a> and a few analog cameras to capture a few angles of the flight. I’m hoping to add a downward facing camera, a side facing camera, and one looking down the body tube towards the main stage engine to capture the ejection from inside the rocket. I intend model camera mounts and redo the avionics bay by the end of October such that the rocket can be flown early November at the latest.</p>

<h1 id="update-jun-2022">UPDATE Jun 2022</h1>

<p><img src="/assets/img/habibi-express/avionicsFront.jpg" alt="Assembled avionics bay" style="float: right; width:30%; height:50%; margin-left: 10px;" />
The avionics bay has been assembled though it is missing a couple key elements. Firstly, there is no voltage regulator to step down the LiPo’s voltage for the Arduino and related electronics; furthermore, I need to integrate a relay, so the Arduino can ignite the second stage motor once the initial one burns out. Finally, the antenna installed on the design right now can not be used and is solely there to ensure that I don’t accidentally burn the LoRa transceiver by powering it on without an antenna. Everything on the module at the moment is completely wired and ready to go. I have noted the I2C addresses of the MPU6050 and BMP280 and the wire with the white connector sticking out the top of the avionics bay goes to the GPS sensor in the nose cone of the aircraft.</p>

<p>The software for this design won’t be too involved as the Arduino only needs to ignite the second stage 3 seconds after the MPU6050 detects a decrease in vertical acceleration all while broadcasting GPS, altitude, and attitude data at regular intervals. The main concern now is developing viable fins for the rocket body. I am hoping to have them laser-cut at the university but I have yet to inquire about using the equipment.</p>

<h1 id="update-mar-2022">UPDATE Mar 2022</h1>

<p><img src="/assets/img/habibi-express/avionics-CAD-V2-back.PNG" alt="Avionics bay V2 back" style="float: right; width:30%; height:50%; margin-left: 10px;" />
The avionics bay is mostly finalized, and I will attempt to print this soon; I’ve done without the 18650 battery and kept the 3s LiPo which is now housed in a casing at the top of the avionics bay. The LoRa module is now positioned such that an antenna can be directly attached to the module and have space in the rocket fuselage. The only thing lacking from the model to the right is a relay holder to ignite the second stage. I still need to remodel the nose cone since the current GPS holder may not have clearance, so it must be shifted upwards after which I will begin 3D printing these components and assembling the rocket!</p>

<h1 id="update-feb-2022">UPDATE Feb 2022</h1>

<p><img src="/assets/img/habibi-express/rocket-CAD.PNG" alt="Rocket model" style="float: right; width:50%; height:50%; margin-left: 10px;" />
CAD model is now mostly finished, lots of small things still need to be figured out however most of the grunt work is done. I don’t have a concrete plan for how to wire the main stage motor’s igniter in a way that won’t risk tangling the parachute during recovery. Furthermore, I purchased two G80-7T motors however the rocket will need at least 10 seconds after the main stage burns out to reach its apogee meaning that I most likely need to source a G80-13T motor to avoid using any complex recovery mechanisms. Unfortunately, <a href="https://www.greathobbies.com/">Great Hobbies</a> does not carry G80 motors anymore, so I can only source these for unreasonably high prices from <a href="https://www.allrockets.ca/G80-13">AllRockets</a>.</p>

<p><img src="/assets/img/habibi-express/avionics-CAD.PNG" alt="Avionics model" style="float: right; width:30%; height:50%; margin-left: 10px;" />
Main focus now is the avionics bay. The model pictured here has space for an Arduino Mega 2560 (embed), a BMP280, an MPU6050, a LoRa SX1278 transceiver, and two batteries. The nose cone contains a GPS antenna bracket for positioning as well. This is the second iteration of the avionics bay, and it contains space for both an 18650 Li-Ion cell (in green) and a small 3S 700mAh LiPo next to the Li-Ion cell. I’m concerned that the ~3V from the 18650 will not be enough to ignite the main stage of the rocket even with a boost converter which is why I included the LiPo. I originally considered using the 18650 in light of its higher energy density however it only has roughly 1.5 times the energy stored by the LiPo so it will likely be discarded in the next iteration.</p>

<h1 id="update-dec-2021">UPDATE Dec 2021</h1>
<p>Rocket design was finalized in <a href="https://openrocket.info/">OpenRocket</a> and basic simulation was done; maximum altitude estimated at roughly 1.1km with a max speed of Mach 0.52. I made some faster designs and others with higher apogees, but this model seems the most predictable based on how much tech I want to fly with the rocket and how lightly I can manufacture things.</p>

<p><img src="/assets/img/habibi-express/open-rocket-sim.PNG" alt="OpenRocket Model" />
<img src="/assets/img/habibi-express/open-rocket-sim-graph.PNG" alt="OpenRocket Simulation" /></p>]]></content><author><name>Serban Popovici</name></author><summary type="html"><![CDATA[Experimenting with rocketry electronics]]></summary></entry><entry><title type="html">LoRa Sensor Suite</title><link href="http://localhost:4000/lora-sensor-suite/" rel="alternate" type="text/html" title="LoRa Sensor Suite" /><published>2022-10-16T00:00:00-04:00</published><updated>2022-10-16T00:00:00-04:00</updated><id>http://localhost:4000/lora-sensor-suite</id><content type="html" xml:base="http://localhost:4000/lora-sensor-suite/"><![CDATA[<h2 id="a-scalable-dynamic-solution-for-monitoring-activity-in-unknown-environments">A scalable dynamic solution for monitoring activity in unknown environments</h2>

<p>At some point in 2021, a friend and I had just finished exploring a construction site and as we were preparing to leave on the first floor, a security guard haphazardly walked in. Luckily we were out of sight and managed to get away undetected, but this presented a need for a system capable of monitoring activity within an uncontrolled environment. So far I have only built PIR sensors for this purpose though I intend to build tripwires and possibly audio sensors.</p>

<h1 id="update-november-2022">UPDATE November 2022</h1>

<p><img src="/assets/img/lora-sensor-suite/PIR-V3-front.jpg" alt="Second generation sensor" style="float: right; width:50%; height:50%" />
Forgot about this project for a while however I have decided to redesign the sensors to incorporate more functionality. I purchased a few ESP-CAM modules off of AliExpress and redesigned the sensors to fit these modules. The new iteration can now detect Bluetooth devices (the last generation was supposed to do this, but I only had ESP-12E modules on hand) and can now send pictures alongside motion and Bluetooth alerts. Further improvements will include adding a buzzer and possibly LEDs such that the sensors can generate distractions. The new design has two external antennas, one for the LoRa transceiver and another for WiFi, which I chose to keep exposed solely for the aesthetic. Future versions may internalize the WiFi antenna since I see no benefit in having it exposed.</p>

<h1 id="update-feb-2022">UPDATE Feb 2022</h1>

<p><img src="/assets/img/lora-sensor-suite/PIR-V2-front.PNG" alt="Front" style="float: right; width:50%; height:50%" />
I’ve decided to migrate from an Arduino to an ESP32 module; this CAD design has space for an ESP32-WROVER module. The reasoning behind this change is that an ESP32 module can be used to pick up bluetooth devices nearby which would allow the attacker to configure the device with their cell phone 
<img src="/assets/img/lora-sensor-suite/PIR-V2-back.PNG" alt="Back" style="float: right; width:50%; height:50%" /> 
and can be used to pick up unknown devices and send alerts even if the sensor itself fails to trip.</p>

<p>The current design does not have space for a battery management circuit and will need to be reiterated, but it does successfully house the LoRa SX1278, 18650, and PIR sensor. The general shape of the sensor allows for it to be placed on the floor with the PIR facing 45 degrees upwards, or it can be flipped and placed on top of a cabinet, for example, with the PIR facing 45 degrees downwards. The next iteration will likely also include magnets such that the sensor can attach to metallic cabinets, metal handrails on stairs, light fixtures, etc. I also took apart one of the 433MHz antennas and noticed that at least 10mm of the rubber housing is left empty meaning that I could omit the rubber housing in future designs to save space.</p>

<h1 id="basic-idea">Basic Idea</h1>

<p>Each sensor runs off of an 18650 Li-Ion cell with a battery protection circuit that enables USB charging and maintains the cell voltage within its acceptable range. Each sensor has an Arduino Nano with a LoRa SX1278 transceiver in addition to its sensing equipment. LoRa modules are ideal since they act as a mesh network and these sensors are intended for use within concrete buildings thus signals will have difficulty traveling far. An additional LoRa module with a high gain antenna connects the LoRa mesh network to the attacker’s phone or some other notification method. Due to the RF challenges faced by these sensors, they should transmit repeatedly once triggered until the attacker’s device is able to acknowledge the signal. Based on experimentation, the LoRa modules I own do not natively do this.</p>

<h2 id="sensor-construction">Sensor Construction</h2>

<p><img src="/assets/img/lora-sensor-suite/PIR-V1-front.png" alt="Front" style="float: right; width:50%; height:50%" />
Pins 0 and 1 of the Arduino are used for serial communication with the LoRa module (the RX pin of the LoRa module must be disconnected when code is uploaded to Arduino). Pin A0 is for the pair button and other pins are used as required for the relevant sensor. 
<img src="/assets/img/lora-sensor-suite/PIR-V1-back.png" alt="Back" style="float: right; width:50%; height:50%" /> 
Pins M0 and M1 on the module are shorted to ground in order for the module to transmit. The whole assembly is currently zip tied together in a rather minimalist form factor for software development, but future versions will be housed in 3D printed casings.</p>

<h2 id="communication-protocol">Communication Protocol</h2>

<p>Each sensor broadcasts an ‘alive’ packet once the pair button has been pressed; this packet contains a unique ID based on the microcontroller’s serial number to differentiate its ‘alive’ packet from that of other sensors. Alive packets are repeated up until the sensor receives an acknowledgment packet from the head unit in which the head unit will assign a numerical value to the sensor between 0 and 9998. The user is then able to assign a more descriptive identifying string to the sensor so that its location can be more apparent. Upon being triggered, the sensor will begin broadcasting a packed in the form of “SENSOR_ID:PACKET_ID:TRIG_VAL” where</p>
<ul>
  <li>PACKET_ID is a unique integer identifying the packet to ensure the head unit doesn’t register the same alert twice</li>
  <li>TRIG_VAL is an integer representative of the sensor’s states</li>
</ul>

<p>This packet is repeated every 0.5 seconds up until the sensor receives a packet from the head unit in the form of “9999;SENSOR_ID;PACKET_ID” where</p>
<ul>
  <li>9999 is the equivalent SENSOR_ID for the head unit</li>
  <li>SENSOR_ID is the id of whichever sensor tripped</li>
  <li>PACKET_ID is the packet id</li>
</ul>]]></content><author><name>Serban Popovici</name></author><summary type="html"><![CDATA[A scalable dynamic solution for monitoring activity in unknown environments]]></summary></entry><entry><title type="html">BRZ VIM4</title><link href="http://localhost:4000/brz-VIM4/" rel="alternate" type="text/html" title="BRZ VIM4" /><published>2022-10-01T00:00:00-04:00</published><updated>2022-10-01T00:00:00-04:00</updated><id>http://localhost:4000/brz-VIM4</id><content type="html" xml:base="http://localhost:4000/brz-VIM4/"><![CDATA[]]></content><author><name>Serban Popovici</name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Modernizing my 2013 Subaru BRZ</title><link href="http://localhost:4000/brz/" rel="alternate" type="text/html" title="Modernizing my 2013 Subaru BRZ" /><published>2022-10-01T00:00:00-04:00</published><updated>2022-10-01T00:00:00-04:00</updated><id>http://localhost:4000/brz</id><content type="html" xml:base="http://localhost:4000/brz/"><![CDATA[<h1 id="update">UPDATE</h1>
<p>This page is very much under construction, with the nice weather finally here I have begun work on the car and certain things will change/be populated as I get to them. I apologize for the organizational mess that is this page.</p>

<p>I recently acquired a car for recreational purposes since I had saved up a decent amount of money and didn’t feel like investing it. I purchased a BRZ because they are built in conjunction with Toyota and this should theoretically imply that they are relatively reliable and I won’t need to worry about the mechanical aspects of the vehicle. Furthermore, the BRZ’s interior is driver-centered while maintaining a relatively simple geometry that should facilitate the design of custom dash components to fit my upgraded electronics.</p>

<p>This project began as a way to disguise speed enforcement countermeasures within the car’s UI seeing as radar/lidar countermeasures are illegal in Ontario. As such, I figured that the best way to hide illegal features would be to program the UI entirely. Seeing as the current head unit is only capable of playing Bluetooth audio, it’s very unlikely that anything I do will result in less overall functionality so I see no downside to this project.</p>

<p>A lot of work has gone into the project so I have split up this post to include a variety of sub-pages detailing individual subsystems in greater detail. This page serves to provide a general overview of the project and a set of links to sub-pages is included below:</p>
<ul>
  <li><a href="/brz-head-unit">Head Unit</a></li>
  <li><a href="/brz-light-link">LightLink Module</a></li>
  <li><a href="/brz-wiring">Wiring</a></li>
  <li><a href="/brz-steering-wheel">Steering Wheel</a></li>
  <li><a href="/brz-user-interface">User Interface (Software)</a></li>
</ul>

<h1 id="idea">Idea</h1>

<h2 id="ui-enhancements">UI Enhancements</h2>

<p><img src="/assets/img/brz/planned_display_layout.jpg" alt="Picture of plan" style="float: right; width:50%; height:80%; margin-left: 10px;" /></p>

<p>The plan is to replace the head unit of the BRZ with a <a href="https://www.aliexpress.com/item/1005003546521274.html">12.3” touch-screen</a>, replace the small button cluster on the center console with a <a href="https://www.aliexpress.com/item/4000393713339.html">7” touch screen</a>, and convert the analog gauge cluster to a display. The 12.3” display will be used for most vehicle functionality such as navigation and media whereas the 7” display will provide diagnostic information about the vehicle as well as any subsystems I add.</p>

<h2 id="convenience-upgrades">Convenience Upgrades</h2>

<p>The car will have an LTE modem in it to provide WiFi connectivity for passengers and allow its internal computers to access Google Maps, media streaming services, and other resources such as the Waze database to protect against police encounters. Finally, I hope to add cameras all around the car and experiment with computer vision though, aside from collision warnings and enhanced cruise control I’m not sure what I’ll be able to code. The cameras will however provide a 360-degree dash cam and I will be able to use them for a Tesla-like sentry mode when the car is locked. Furthermore, it may be interesting to experiment with augmented reality headsets in the future to provide the driver with enhanced situational awareness, but this is not in the works as of this writing.</p>

<p>In order to improve the driver’s situational awareness, I’ve elected to replace the two fog lights of the car with thermal and low light high zoom cameras, respectively. The thermal camera will provide the driver with warnings about heat signatures detected ahead whereas the low light camera does not serve much of a practical purpose and was included because I had it lying around. Finally, I’m hoping to integrate blind spot detection radars and cruise control radars out of scrapped vehicles to provide additional peace of mind when merging lanes.</p>

<h2 id="speed-enforcement-countermeasures">Speed Enforcement Countermeasures</h2>

<p>I’m hoping to, at the very least, add passive sensors for radar/lidar and aircraft but I may not be able to add active countermeasures such as radar/lidar jamming. Based on some brief research, there is a significant risk that a radar/lidar device would detect my jamming attempts seeing as many of them have jamming detection built in. Proper commercial jammers are designed to identify the specific make/model of a lidar gun and behave accordingly however they are rather cost-prohibitive so I may not be able to reasonably source a commercial system.</p>

<p>Aircraft countermeasures are more achievable since aircraft speed detection works using lines painted on the pavement at a known distance interval such that an aircraft flying above can time a vehicle crossing a set of these lines. My plan for countering this is to use a front facing camera on the car to pick up the lines at which point an onboard computer will use a software defined radio to look for any aircraft transponders within a certain radius of the vehicle. Should there be an aircraft nearby, the onboard computer will begin calling out speeds for the user to match in hopes that the average speed across the two lines does not exceed the posted limit.</p>

<p>An even more complex countermeasure I’m hoping to integrate is cellular sniffing where a computer would once again use a software defined radio to look for nearby cellular devices and fingerprint them to single out the specific make and model of cellular modem present in a Ford Interceptor. I’m unsure if this is even theoretically possible since newer cellular devices may encrypt everything including metadata but I intend to research this in depth.</p>

<p>In addition to passive countermeasures and radar/lidar jammers, the vehicle will hopefully have cellular and VHF/UHF jammers. The purpose of these is to prevent a Ford Interceptor’s cellular modem and radio from working when in close proximity to the BRZ meaning that the officer will <em>hopefully</em> be unable to run driver’s licenses or issue tickets.</p>

<h1 id="build">Build</h1>

<h2 id="functional-diagram">Functional Diagram</h2>

<p><img src="/assets/img/brz/functional_diagram.png" alt="BRZ Functional Diagram" /></p>

<p>The diagram above displays the overall hierarchy of devices integrated in the car. Red boxes are video capture devices, green boxes are computers, blue boxes are displays, and purple devices are CAN bus devices. I have elected to create a second CAN bus for my devices and use the “Transceiver node” to forward relevant CAN bus data to my private bus. This is to prevent the risk of conflicting IDs and eliminate the possibility of damaging the vehicle should any of my custom devices malfunction and, for example, short circuit the CAN bus lines. A brief description of each device alongside its functionality is included in the section below.</p>

<h2 id="hardware">Hardware</h2>

<h3 id="computers">Computers</h3>

<p>The UI of the car is handled by two primary computers (a Raspberry Pi 4B and a <a href="https://www.khadas.com/vim4">Khadas VIM4</a>) whereas the hardware modifications are handled by a variety of other Arduinos integrated throughout the vehicle. All the computers denoted by green boxes in the diagram above connect through ethernet and have internet access.</p>

<p>The “Android computer” is a Raspberry Pi 4B running Android that controls the head unit and center console displays which function in tandem to deliver the interactive component of the vehicle’s UI whereas the VIM4 runs Linux and does most of the heavy lifting. The Android computer does not handle any logic and interacts with the VIM4 using a series of web services. The VIM4 handles a variety of tasks including Bluetooth media playback, camera feed management, and CANBUS communication. More information can be found <a href="/brz-VIM4">here</a>.</p>

<p>The “Vision computer” is meant to be an nVidia Jetson however those are too expensive for me at the moment so it is substituted with a second Raspberry Pi 4B running Linux. Finally, the SDR computer has not been set in stone at the moment but any modestly powerful SBC will be adequate as its sole purpose is to interact with a few RTL-SDR modules to listen for ADS-B, cellular, and possibly audio communications over radio.</p>

<h3 id="secondary-can-bus">Secondary CAN Bus</h3>

<p>Most of the hardware modifications are executed by Arduinos integrated throughout the vehicle that share a CAN bus. The list of integrated Arduinos as well as other CAN bus devices is as follows:</p>

<ul>
  <li>Blind spot radars –&gt; Will use some second hand eBay or junkyard radars from another car.</li>
  <li>Steering wheel button manager (NANO) –&gt; Converts steering wheel button presses into CAN messages for head unit.</li>
  <li>Center console button manager (NANO) –&gt; Controls MOSFETs that simulate button presses to maintain functionality of old center console buttons.</li>
  <li>Front-facing radar –&gt; Will use a second hand eBay or junkyard radar from another car.</li>
  <li>Ceiling switches –&gt; I would like to install a fancy ceiling switch panel in the car but this is a future project.</li>
  <li>Mirror manager (NANO) –&gt; Keeps track of mirror position and allows them to automatically tilt when backing up. One per mirror.</li>
  <li>Low light camera controller –&gt; Translates CAN messages into PWM signals to actuate the camera’s gimbal.</li>
  <li>Thermal camera controller –&gt; Translates CAN messages into a PWM pitch value to adjust the camera’s pitch.</li>
  <li>LightLink (2xMEGA_EMBED) –&gt; Used to control most exterior vehicle lights, more info <a href="/brz-light-link">here</a>.</li>
  <li>Rear defence controller –&gt; In charge of managing jammers in the rear of the vehicle.</li>
  <li>Uniden R9 –&gt; Reverse engineered CAN interface for the Uniden R9 system (not released at the time of this writing but am hoping to get one when they come out).</li>
  <li>Transceiver node –&gt; Forwards CAN data from vehicle’s CAN bus to my CAN bus. More info <a href="/brz-CAN">here</a>.</li>
</ul>

<h3 id="cameras">Cameras</h3>

<p>The planned camera layout is included below. The green semicircles are <a href="https://www.aliexpress.com/item/1005004337827464.html">136-degree FOV cameras</a> installed in the front windshield and above the rear license plate whereas the gray circles represent <a href="https://www.aliexpress.com/item/1005004335144138.html">210-degree cameras</a> (the listing says 180 degrees but they are actually 210) installed beneath the side view mirrors of the car (PIC). I planned on including a second front-facing camera on the right wing mirror to provide the driver with insight about any vehicles in the right lane ahead of the car however this camera is not included at this time since the 210-degree FOV camera installed beneath the mirror should theoretically capture all vehicles in the right lane.</p>

<p><img src="/assets/img/brz/camera_layout.png" alt="Camera layout" /></p>

<p>Beyond the cameras used for 360 degree coverage, both fog lights of the vehicle contain camera modules with the driver side being a thermal camera and the passenger side being a Sony Starvis low light camera with optical zoom. These are meant to be used in conjunction with AI to detect threats on the road ahead as well as to provide increased visibility in low light conditions. Of these two, the thermal camera uses a RCA to HDMI adapter to interface with the Khadas VIM4’s HDMI input and the low light camera simply outputs to ethernet and shares the vehicle’s ethernet network. A final camera is installed inside the vehicle and faces the driver for eye tracking such that the touch screen functionality of the center console display is disabled unless the driver is looking at the display to prevent accidental inputs (might not be included after all, depends on whether accidental input truly is an issue).</p>

<h2 id="software">Software</h2>

<p>I initially intended to build a custom image of Android Automotive for the BRZ and develop mobile applications that would mostly run as background services and overlay themselves on top of Android to display relevant information. Unfortunately this turned out to be a rather lucrative task and as of this writing I have elected to build a simple Android application running on a mobile image. The advantages of Android Automotive are as follows:</p>
<ul>
  <li>Better navigation with fully functional Google Maps (Android applications cannot have integrated navigation activities and can only display 2D maps as far as I am aware)</li>
  <li>Better media controls with proper Bluetooth integration (the Android Mobile OS cannot be used as a A2DP sink without modifying the source code)</li>
  <li>Better boot times</li>
</ul>

<p>Overall, I did not feel these advantages were enough to justify the increased complexity of building a custom Android Automotive image especially considering how many custom UI screens and functions I intend to incorporate as well as my lack of affinity for hardware-level programming.</p>

<p>The purpose of rebuilding the vehicle’s UI is not only to provide a seamless means of interacting with the additional functionality but also to fully hide any illegal functions on demand. As such, a ‘legal mode’ will be integrated in the software which will be activated on boot and will hide all illegal functionality from the vehicle’s UI. The driver can disable legal mode using an arbitrary set of seemingly random keystrokes using buttons throughout the car’s interior which will be intricate such that they cannot be haphazardly entered.</p>]]></content><author><name>Serban Popovici</name></author><summary type="html"><![CDATA[UPDATE This page is very much under construction, with the nice weather finally here I have begun work on the car and certain things will change/be populated as I get to them. I apologize for the organizational mess that is this page.]]></summary></entry><entry><title type="html">BRZ CAN</title><link href="http://localhost:4000/brz-CAN/" rel="alternate" type="text/html" title="BRZ CAN" /><published>2022-10-01T00:00:00-04:00</published><updated>2022-10-01T00:00:00-04:00</updated><id>http://localhost:4000/brz-CAN</id><content type="html" xml:base="http://localhost:4000/brz-CAN/"><![CDATA[]]></content><author><name>Serban Popovici</name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">BRZ Steering Wheel</title><link href="http://localhost:4000/brz-steering-wheel/" rel="alternate" type="text/html" title="BRZ Steering Wheel" /><published>2022-10-01T00:00:00-04:00</published><updated>2022-10-01T00:00:00-04:00</updated><id>http://localhost:4000/brz-steering-wheel</id><content type="html" xml:base="http://localhost:4000/brz-steering-wheel/"><![CDATA[<h3 id="steering-wheel-button-integration">Steering Wheel Button Integration</h3>

<p>Steering wheel buttons were added to BRZs in 2017 and mine is a 2013 so I purchased a salvage steering wheel in order to integrate its buttons into my systems. Should anybody else contemplate to do the same, be aware that even though steering wheels are cheap the airbag most certainly is not: a brand new OEM airbag for my car is $CAD 1100 from the dealer while a used one is ~$CAD 600.</p>

<p>The steering wheel uses an Arduino Pro Micro to convert button presses into keyboard output for the Khadas VIM4 to understand. Furthermore, it connects to the CANBUS to forward hardware-related commands to decrease latency as opposed to transferring commands from the VIM4 to other devices. In order to interface the Arduino with the steering wheel, I took apart the button clusters on each side of the 
<img src="/assets/img/brz/steering_wheel_button_connector.jpg" alt="Steering wheel button connector" style="float: right; width:50%; height:80%; margin-left: 10px;" />
steering wheel and followed traces to figure out the function of each wire. My findings are listed below for anybody else intending to reverse engineer the steering wheel buttons on a BRZ (wires are listed from left to right, top to bottom, looking at the connector from behind as depicted to the right):</p>
<ul>
  <li>Light green –&gt; Volume and arrow keys of left side cluster</li>
  <li>Red –&gt; Common of left side cluster</li>
  <li>Green –&gt; Arrow keys of right side cluster</li>
  <li>Purple –&gt; Enter and back key of right side cluster</li>
  <li>Yellow –&gt; Common of right side cluster</li>
  <li>Black –&gt; Call buttons, source button, left enter button, and voice button</li>
  <li>Blue –&gt; Steering wheel ground</li>
  <li>Brown –&gt; Cruise control pin 1</li>
  <li>Grey –&gt; Cruise control pin 2</li>
  <li>Black + White –&gt; LED ground</li>
  <li>White –&gt; LED VCC (5V works but dim. Not sure I’m willing to go higher so I’ll suck it up)</li>
</ul>

<p>The ‘voice’ button on the right side of the steering wheel is wired to the left button cluster and its state is transmitted through the (light green or black) wire. Button states are transmitted by varying the resistance between the common pin of each button cluster and one of the two output pins of each button cluster. The Arduino interprets these using an analog pin using the INPUT_PULLUP pin mode with the common pins being connected to ground. The resulting resistance and output wire for any button press is listed below in hopes of saving someone else the effort required to decode these circuit boards though I ended up using analogRead values in my code so these are useless to me.</p>

<table>
  <thead>
    <tr>
      <th>Left Side Cluster</th>
      <th>Right Side Cluster</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Source –&gt; 115 Ohm BLACK</td>
      <td>Up –&gt; 330 Ohm GREEN</td>
    </tr>
    <tr>
      <td>Call pickup –&gt; 425 Ohm BLACK</td>
      <td>Right –&gt; 3.1 kOhm GREEN</td>
    </tr>
    <tr>
      <td>Call hangup –&gt; 225 Ohm BLACK</td>
      <td>Down –&gt; 1 kOhm GREEN</td>
    </tr>
    <tr>
      <td>Volume up –&gt; short LIGHT GREEN</td>
      <td>Left –&gt; short GREEN</td>
    </tr>
    <tr>
      <td>Volume down –&gt; 50 Ohm LIGHT GREEN</td>
      <td>Enter –&gt; 100 kOhm PURPLE</td>
    </tr>
    <tr>
      <td>Right –&gt; 115 Ohm LIGHT GREEN</td>
      <td>Back –&gt; 101 kOhm PURPLE</td>
    </tr>
    <tr>
      <td>Left –&gt; 245 Ohm LIGHT GREEN</td>
      <td>Voice –&gt; 50 Ohm BLACK</td>
    </tr>
    <tr>
      <td>Enter –&gt; short BLACK</td>
      <td> </td>
    </tr>
  </tbody>
</table>]]></content><author><name>Serban Popovici</name></author><summary type="html"><![CDATA[Steering Wheel Button Integration]]></summary></entry><entry><title type="html">BRZ LightLink</title><link href="http://localhost:4000/brz-light-link/" rel="alternate" type="text/html" title="BRZ LightLink" /><published>2022-10-01T00:00:00-04:00</published><updated>2022-10-01T00:00:00-04:00</updated><id>http://localhost:4000/brz-light-link</id><content type="html" xml:base="http://localhost:4000/brz-light-link/"><![CDATA[<h2 id="lightlink-overview">LightLink Overview</h2>

<p>Control of a vehicle’s external lighting is safety critical, so I’ve settled on designing a fully-redundant custom circuit board with 12 MOSFET-driven channels to handle ‘dumb’ lights and 8 addressable channels to handle a set of addressable LED arrays retrofitted throughout the vehicle.</p>

<p>In addition to designing a fully-redundant board, I felt it necessary to minimize the number of functional components in an effort to limit design complexity and reduce the risk of component failure. All lights within the vehicle share a common ground which means they need to be toggled using a high side switch, ergo P-channel MOSFETs. The problem with this is that P-channel MOSFETs are off when the gate voltage high relative to <em>their</em> source which is the car battery whereas the Arduinos I will use to operate the MOSFETs run on 5V. A typical solution for this would be to include some form of transistor to toggle the P-channel MOSFET which would effectively double the components required for a fully redundant solution.</p>

<p><img src="/assets/img/brz/weird_arduino_p_channel_mosfet.png" alt="Picture of plan" style="float: right; width:50%; height:80%; margin-left: 10px;" /></p>

<p>This was not acceptable for me so I did some research and found the picture depicted here to the right. This schematic works by connecting the Arduino’s 5V to the MOSFET supply’s 12V but keeping the grounds disconnected. In this way, the Arduino can toggle the MOSFET when it sets digital pin 6 to LOW which appears as -5V to the MOSFET and should be enough to fully excite it. This circuit may work, however MOSFETs have an effective capacitance between their gate and source which needs to be charged in order to switch the MOSFET’s state. Alongside the additional concerns from having two different grounds on a PCB, not having a common ground could lead to unpredictable behaviour when switching the MOSFETs. For this reason, I’ve elected to use a decoupling capacitor between the +5V and +12V rails while maintaining a board-wide common ground.</p>

<p>An additional requirement in order to have proper redundancy is the ability to identify the status of each individual MOSFET such that a single component failure can be accurately diagnosed by the Arduino. Luckily, thanks to the common ground, I can simply use voltage dividers and followers alongside a summing amplifier to sense the voltage of each MOSFET. Two voltage dividers are included in each set of redundant MOSFETs; one drops the output voltage to 1V whereas the other drops the voltage to 3V. The two voltage dividers then go into a summing amplifier which allows the state of both MOSFETs to be sensed with a single pin. The voltage followers were included to prevent linking the MOSFET outputs as this would affect the accuracy of failure detection whereas the summing amplifier was included since the Arduino only has 16 analog sense pins and there are 24 MOSFETs on the board.</p>

<p>Finally, since I need three op amps for the sensing circuit and will be using quad op amp ICs, I have elected to use the last op amp for a shunt to measure the output current of each MOSFET pair. In this manner, the board can also diagnose blown bulbs or short circuits.</p>

<h3 id="redundant-mosfet-schematic">Redundant MOSFET Schematic</h3>

<p><img src="/assets/img/brz/mosfet_schematic.PNG" alt="MOSFET schematic" /></p>

<p>Two MOSFETs (bottom right) are included in parallel, both of which are immediately followed by a Schottky diode to prevent backflow from the other MOSFET. This is necessary because a diagnostic pin is included prior to the Schottky and senses voltage which would be biased by backflow from the other MOSFET therefore hindering the detection of a MOSFET failure. The diagnostic connections use two sets of voltage dividers and voltage followers (top left) to reduce Q1’s voltage to 1V and Q2’s voltage to 3V. The outputs of the voltage followers are funneled into a summing amplifier such that the final signal ranges between 0 and 4V. Finally, a differential amplifier (top right) is included for measuring current across the shunt.</p>

<p>MOSFETS SCHEMATIC</p>

<p>For control, two Arduino Mega EMBEDs are inclded. These were chosen because I have about a dozen on hand right now and they have been reliable in my experience. Regardless, two Arduinos with separate CAN transceivers are included on the board as depicted in the schematic below:</p>

<p>OVERALL SCHEMATIC</p>

<p>At any given moment, one of the Arduinos is considered the ‘master’. The master is in charge of outputting signals to the MOSFET and addressable channels while simoultaneously communicating its state over to the slave Arduino over a UART connection. The master updates the slave at regular intervals such that the updates themselves function as ‘heartbeat’ signals assuring the slave that the master is operating optimally. Should the master miss a heartbeat for whatever reason, the slave sends a hardware reset pin to the current master after which it assumes the master role and resumes signal outputs based on the last state update it received over UART. This system also allows the Arduinos to swap roles ever 30 days since my asynchronous code uses the millis() function to keep track of time and its value will exceed the maximum possible variable size in approximately 50 days.</p>

<h3 id="lighting-modifications">Lighting Modifications</h3>

<p>Some modifications require extensive control of the vehicle’s lights however I am not willing to alter anything about the car’s computers so my solution consists of placing relays along the wiring harnesses controlling the vehicle’s lights with two separate computers on each end of the car. Each computer has a combination of mechanical and solid state relays depending on how frequently a light is expected to toggle on/off. Mechanical relays are used for lights that rarely toggle and because they provide a normally closed and normally open set of contacts. This is important because the lighting computers receive constant power regardless of the vehicle’s state and therefore power draw must be minimized when the vehicle is not running.</p>

<p><img src="/assets/img/brz/rear_light_manager.jpg" alt="Rear light manager computer" style="float: right; width:50%; height:80%; margin-left: 10px;" /> The rear lighting computer is pictured to the right and I expect the front computer to be highly similar. It uses four solid state relays (top left) to drive the brake lights and turn signals of the car by connecting them to the car’s battery. The third and fourth brake light of the car (third is in the windshield and fourth is F1 style in bumper) are converted to addressable LEDs and do not require relays. Addressable LEDs have also been integrated into the reverse lights (two lights adjoined to the fourth brake light) and the two rear quarter panel windows of the car. Excluding the solid state relays, the computer contains two mechanical relays (bottom left) for running lights, a CANBUS module (bottom right), an Arduino (top right), and a 5V regulator on the backside. Currently, this computer turns lights on based on whether or not live data is being sent across the CANBUS since it is always powered and I have not yet figured out what value represents the stte of the vehicle’s running lights. This is not ideal since a side effect of my current solution is that running lights turn on when doors open or the car is unlocked etc.</p>]]></content><author><name>Serban Popovici</name></author><summary type="html"><![CDATA[LightLink Overview]]></summary></entry><entry><title type="html">BRZ Head Unit</title><link href="http://localhost:4000/brz-head-unit/" rel="alternate" type="text/html" title="BRZ Head Unit" /><published>2022-10-01T00:00:00-04:00</published><updated>2022-10-01T00:00:00-04:00</updated><id>http://localhost:4000/brz-head-unit</id><content type="html" xml:base="http://localhost:4000/brz-head-unit/"><![CDATA[<p>This page outlines the process of modifying the BRZ’s stock head unit to contain custom components. I maintained the casing of the original head unit to avoid designing custom mounting hardware and alleviate the need to reverse engineer the casing design.</p>

<h2 id="architecture">Architecture</h2>

<p><em>include block diagram of design here</em></p>

<h2 id="cad">CAD</h2>

<p>The head unit CAD is split into two parts: the internal components (SBCs, amplifiers, etc.) and the external components (display and driver-facing camera).</p>

<h3 id="internal-cad">Internal CAD</h3>

<p>The inside of the OEM head unit’s casing has been redesigned to utilize a series of stackable brackets providing mounting points for the following components:</p>

<ol>
  <li>Khadas VIM4 –&gt; Linux backend computer</li>
  <li>USB 5.1 sound card –&gt; Required since Khadas VIM4 does not have a DAC onboard</li>
  <li>RCA to HDMI converter –&gt; Used to convert thermal camera to HDMI since Khadas VIM4 has an HDMI in</li>
  <li>NVMe SSD –&gt; used for dashcam/blackbox purposes</li>
  <li>SPI CAN shield –&gt; connects Khadas VIM4 to the CAN bus</li>
  <li>Raspberry Pi 4B –&gt; Android frontend computer</li>
  <li>Head unit display driver boards –&gt; two boards, one for power delivery and another for logic</li>
  <li>2CH amplifier boards (2 of these) –&gt; amplify audio for FL, FR, RL, and RR channels</li>
  <li>5V regulator –&gt; provides 5V for Khadas VIM4, Raspberry Pi, USB DAC, and RCA to HDMI converter</li>
  <li>Voltage splitter –&gt; splits battery voltage for display driver, amplifiers, and 5V regulator which do not require upstream power regulation</li>
</ol>

<p>There are 4 total brackets in the CAD design depicted to the right <em>PUT UPDATED PIC ONCE RCA to HDMI thingy is in there</em>. The bottom bracket solely holds the display driver and Raspberry Pi, the second bracket holds the VIM4 alongside its NVMe SSD and CAN shield, the third holds one of the amplifiers and the display driver’s power board, and the fourth holds the final amplifier alongside the 5V regulator, USB DAC, and RCA to HDMI converter. The third bracket has a gap on the right side of the image to provide clearance for the VIM4’s fan.</p>

<p>The entire assembly mounts to three screw holes on the bottom of the head unit casing as well as two screw holes halfway up each side of the casing. An additional bracket, <em>pictured below</em>, mounts to the rear of the head unit and holds the stock power in/speaker out connector as well as other various I/O connectors for interfacing with the microphone, the CAN bus, and the secondary display of the head unit. All other connections go directly into their respective boards.</p>

<p>The head unit bracket is a perfect example of this technique. The design was built symmetrically, and as such, I began by modelling the left side before mirroring it to generate the entire assembly. I knew I would need two ‘platforms’ to house all the required components so I began by measuring the mount hole positions from the old head unit and generating two basic mount ‘ears’ before extruding an arbitrary platform attached to each ear. The platforms were extended an arbitrary amount in both directions based on how much space I estimated to be available inside the vehicle’s cavity and how far the head unit display would be mounted. The head unit bracket holds the following hardware as can be seen in the <em>PIC</em> to the right:</p>

<ol>
  <li>Head unit display</li>
  <li>Head unit display driver</li>
  <li>Khadas VIM4</li>
  <li>Voltage regulator</li>
  <li>Driver-facing camera</li>
</ol>

<p>No amp needed up front since it’s in the trunk from factory. That being said it only drives the front speakers and I can’t figure out how the rear side speakers are powered so there may be more amplifiers throughout the vehicle. I also need to include an amplifier for a loudspeaker up front which may end up in the head unit if there is space.</p>]]></content><author><name>Serban Popovici</name></author><summary type="html"><![CDATA[This page outlines the process of modifying the BRZ’s stock head unit to contain custom components. I maintained the casing of the original head unit to avoid designing custom mounting hardware and alleviate the need to reverse engineer the casing design.]]></summary></entry><entry><title type="html">BRZ Wiring</title><link href="http://localhost:4000/brz-wiring/" rel="alternate" type="text/html" title="BRZ Wiring" /><published>2022-10-01T00:00:00-04:00</published><updated>2022-10-01T00:00:00-04:00</updated><id>http://localhost:4000/brz-wiring</id><content type="html" xml:base="http://localhost:4000/brz-wiring/"><![CDATA[]]></content><author><name>Serban Popovici</name></author><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">LTE Mavic Pro</title><link href="http://localhost:4000/lte-mavic-pro/" rel="alternate" type="text/html" title="LTE Mavic Pro" /><published>2022-09-03T00:00:00-04:00</published><updated>2022-09-03T00:00:00-04:00</updated><id>http://localhost:4000/lte-mavic-pro</id><content type="html" xml:base="http://localhost:4000/lte-mavic-pro/"><![CDATA[<p>Cellular-based drone control has been a longstanding goal with the purpose of creating UAVs requiring minimal user input to function. I have found the need for constant input to significantly reduce the useability of drones for recon during my adventures because neither myself nor the people with me can dedicate significant attention to piloting them. This project aims to achieve basic autonomous control through an Android application that allows the user to place the drone at specific coordinates or land it. The first rendition was built to be submitted as an electronics project for a university course and is solely capable of navigation; takeoff and landing must be manually with a separate remote controller. This is because a F1 flight controller was used which is only capable of managing stability.</p>

<h1 id="final-update-feb-2022">FINAL UPDATE Feb 2022</h1>

<p>I never did test the Mavic camera with the Caddx Vista since I do not have a fully intact gimbal cable lying around and don’t fully intend on maintaining this project. Overall, the system worked. I initially had a physical relay with a separate Arduino to toggle between the FlySky i6 and the Raspberry Pi for control since I did not trust the Raspberry Pi but I ended up omitting this during the final build. The flight algorithm is incredibly buggy since I am relying on the Pi providing raw pitch, roll, and yaw control to the flight controller as opposed to using the flight controller itself to do the navigation.</p>

<h1 id="update-feb-2022">UPDATE Feb 2022</h1>

<p>Obtained a SucceX-D Mini F7 Twin G stack and redesigned the 3D printed bracket which holds all the electronics inside the Mavic. 
<img src="/assets/img/hacked-mavic/board-mount-V3.PNG" alt="Bracket V2" style="float: right" />
The new design no longer requires tape and glue but rather relies on three pre-existing screwholes used by the original DJI flight control board. It took a few revisions to finalize the fit of the board such that the components comfortably fit within the restricted space originally occupied by DJI’s proprietary electronics. This is the fifth revision of the bracket and it includes mount points for a 4-in-1 ESC board, flight controller, the Raspberry Pi, and a Flysky receiver. I’m sticking with the Flysky receiver over a Crossfire system since it is able to take advantage of the 2.4 GHz antennas already integrated in the Mavic leading to a more ‘stock’ look. The 4-in-1 ESC board is on the bottom such that it can be in contact with the bottom heatsink of the Mavic and hopefully take advantage of it. Realistically, this ESC board is rated for 45A per motor which is likely over double what the motors should be drawing. Finally, I have decided to remove the Arduino since I should be able to accomplish its tasks with threaded processes on the RPi. In doing so, I am now once again able to install the OEM gimbal on the drone and, since the DJI Mavic’s camera seems to use MIPI, I may be able to interface it with the RPi (I haven’t yet tested the camera’s protocol but its connector looks identical to that of the Caddx Polar camera I own).</p>

<p>Unfortunately I still do not have a compact cellular modem and I am not sure where I will be able to fit it. I also need to create a custom target to flash the F7 board with iNav since I don’t believe Betaflight is capable of executing waypoint missions through telemetry but I will see if that’s a possibility. I also need to figure out if the flight controller is able to arm and takeoff without any contribution from the receiver since I only intend to keep it for debugging/testing purposes and it is not intended to be used during regular operation.</p>

<h1 id="update-dec-2021">UPDATE Dec 2021</h1>

<p>Initial bracket designs relied on double sided adhesive and a small bracket to effectively hold down all the internals. 
<img src="/assets/img/hacked-mavic/board-mount-V1.PNG" alt="Bracket V1" style="float: right" />
This design makes maintenance virtually impossible without considerably disassembling the drone so current versions use existing screwholes to ensure a more secure fit. The varying boards within the Mavic are installed as follows:</p>
<ul>
  <li>The flight controller is installed sideways on the front of the bracket immediately following the pre-existing fan</li>
  <li>A 20x20mm 20A ESC board is installed immediately following the flight controller on the underside of the bracket. This allows for thermal pads to be placed between the ESCs and the Mavic’s pre-existing heatsink thereby providing some cooling.</li>
  <li>Following the ESC, the LTE modem and an Arduino Nano are installed on the bottom of the board.</li>
  <li>The top of the bracket is exclusively reserved for the Raspberry Pi Zero. Ideally, the Pi would be on the bottom so that the heatsink could cool it but unfortunately the ultrasonic sensors make this difficult so I had to place it on top. Fortunately, the Pi Zero does not need any cooling so I will keep it like this for future designs.</li>
  <li>Finally, a FlySky i6X receiver is shoved within the wiring towards the end of the drone body for debugging purposes.</li>
</ul>

<p><img src="/assets/img/hacked-mavic/build-V1.jpg" alt="Mavic Build V1" /></p>

<h1 id="basic-idea">Basic Idea</h1>

<p>The drone will be centered around a Raspberry Pi Zero and a LTE modem for internet access. A Raspberry Pi CM4 could fit and would be beneficial but I am not currently capable of developing carrier boards and a full size Raspberry Pi will not fit. The Pi’s serial port is dedicated to communicating with the flight controller through iBus since iBus operates at 115200 baud and bit bashing on the Pi becomes unreliable past 19200 baud. The GPS data will be received using a GPIO pin and bit bashing and another bit bashing serial connection will be used to communicate with an Arduino. The Arduino serves as an IO expander for the Pi to manage the LEDs on the drone as well as an ultrasonic sensor and sense voltage and current throughout the drone. Using an Arduino as such is advantageous since it has an ADC whereas the Pi does not. Additionally, offloading time-sensitive operations such as reading the ultrasonic sensor and running the drone’s LED patterns decreases the complexity of the Pi’s code.</p>

<h2 id="data-link">Data Link</h2>

<p>My current LTE modem filters all ports no matter what settings I chose within its menu. For this reason, I’ve elected to use a P2P UDP protocol which is able to punch through firewalls. A second Raspberry Pi will serve as an intermediary P2P server to connect the cell phone and drone given that neither has a static IP. The P2P code was largely copied from https://github.com/grakshith/p2p-chat-python.git and modified to better fit my protocol. Both the drone and cell phone should identify themselves during their initial UDP broadcast in order to identify what function they serve; this future proofs the server’s code since I can selectively connect devices based on functionality as opposed to the time at which they contact the server. Once two compatible hosts have broadcast their address/port to the P2P server, they will each receive the address/port of the other client and the server logs the connection before discarding all saved host data.</p>

<h2 id="flight-algorithm">Flight Algorithm</h2>

<p>The version submitted for my course uses a rather primal flight algorithm in which the Pi has a barometer and compass connected to it through I2C. Using GPS, compass, and altitude data the Pi is able to compute a vector from its current coordinates to the target coordinates using the haversine libary for Python and a bearing function I stole from StackExchange. It then points the drone in the target direction and goes forward; the drone’s speed varies based on distance to target and it progressively slows down as the distance decreases. The current version offloaded all navigation to the flight controller running iNav thereby reserving the Pi’s looptime for more useful functions such as WiFi, cellular, and UHF sniffing. OpenCV can also be used on the Pi to provide some level of active tracking and increase the effective autonomy of this platform. For this, I may need to choose a UAV platform with surround cameras such as the Mavic 2 or Skydio 2 and upgrade to an nVidia Jetson computer since having the drone actively follow subjects would require some level of obstacle avoidance.</p>

<h1 id="code">Code</h1>

<h2 id="raspberry-pi">Raspberry Pi</h2>

<p>The Raspberry Pi runs off of a Python program split into four key files:</p>
<ul>
  <li><strong>main.py</strong> –&gt; this file is what runs upon startup. It calls upon the other three and synchronizes data between files (takes updated target coordinates from network.py and sends them to flight.py)</li>
  <li><strong>network.py</strong> –&gt; this file handles all P2P communication and is responsible for maintaining a link with the cell phone. It receives target coordinates and saves them in a local variable which is then queried by main.py</li>
  <li><strong>flight.py</strong> –&gt; handled flight algorithm in implementation for my course however <strong>TODO</strong> current version dispatches target coords to the flight controller and monitors telemetry data so it can be passed on to the Android application</li>
  <li><strong>misc.py</strong> –&gt; contains random functions used by all files such as logging</li>
</ul>

<h2 id="arduino">Arduino</h2>

<p>Pins A0 and A1 are used for detecting voltage from the battery and the 5V rail. Pins 2 and 13 are used as digital outputs for controlling the LEDs on the left and right front arms of the Mavic, respectively. Pin 8 is used for the LEDs throughout the drone which are single WS2812b pixels while pins 5 and 6 are used to monitoring the ultrasonic sensor. The LED patterns were done by keeping track of loop time: every time an LED pattern begins the value of millis() is saved in cycleStartTime, and for every time the code runs the current output is compared to cycleStartTime. Each cycle has an arbitrary time step, for example a cycle may have 8 time steps all of which last 800ms. These time steps are encoded in if statements that compare millis() to cycleStartTime and figure out which time step the cycle should be running. Once all 8 time steps have finished, cycleStartTime is updated to represent the current time and the cycle restarts.</p>

<h2 id="android-studio">Android Studio</h2>

<p>The application is pretty simple overall, it displays a map on which the user can select a point for the drone to go do. By default, the drone will attempt to do so at an altitude of 50m, however a dialog exists for the user to modify that altitude. This application worked using a peer-to-peer server hosted on my server that connected the drone and app through UDP. Normally, the map would center around the drone but these screenshots were taken with the drone offline.</p>

<p><img src="/assets/img/hacked-mavic/app_map.png" alt="App map" style="float: left; width:50%;" />
<img src="/assets/img/hacked-mavic/app_parameter.png" alt="App parameter" style="float: right; width:50%;" /></p>]]></content><author><name>Serban Popovici</name></author><summary type="html"><![CDATA[Cellular-based drone control has been a longstanding goal with the purpose of creating UAVs requiring minimal user input to function. I have found the need for constant input to significantly reduce the useability of drones for recon during my adventures because neither myself nor the people with me can dedicate significant attention to piloting them. This project aims to achieve basic autonomous control through an Android application that allows the user to place the drone at specific coordinates or land it. The first rendition was built to be submitted as an electronics project for a university course and is solely capable of navigation; takeoff and landing must be manually with a separate remote controller. This is because a F1 flight controller was used which is only capable of managing stability.]]></summary></entry></feed>