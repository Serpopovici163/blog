<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-09-03T19:38:17-04:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Ludicrous Tech</title><subtitle>This website keeps track of whichever projects I am most proud of and serves to share some of the knowledge I accumulate from tinkering on whatever comes to my mind. Enjoy!</subtitle><author><name>Alex Ludicrous</name></author><entry><title type="html">Roof Anchor Drone</title><link href="http://localhost:4000/roof-anchor-drone/" rel="alternate" type="text/html" title="Roof Anchor Drone" /><published>2022-08-02T00:00:00-04:00</published><updated>2022-08-02T00:00:00-04:00</updated><id>http://localhost:4000/roof-anchor-drone</id><content type="html" xml:base="http://localhost:4000/roof-anchor-drone/"><![CDATA[<h2 id="a-physical-infiltration-tool">A physical infiltration tool</h2>

<p>This device was originally designed in hopes of rooftopping the second tallest building in Canada at the time of this writing: The St. Regis hotel in Toronto. The concern was that the lower roof at the St. Regis hotel is accessible while the higher roof is roughly 3 storeys taller and unnaccessible through conventional ways. In the end, there was an easier way of reach the top and the drone was not used however it remains a genuinely useful tool for ascending moderately tall commercial structures.</p>

<h1 id="general-premise">General premise</h1>

<p>The goal is to build a 3D-printable assembly that attaches to the bottom of a drone and holds a carbiner in an open position which can then be remotely shut. The drone must be small enough to be easily portable and nimple while the carabiner assembly must be able to support a moderate amount of weight as a rope must be carried alongside the carabiner. In cases where the distance to be ascended is too large for the drone to reasonably carry rope with it, a significantly thinner and lighter tag line can be passed through the carabiner and used to pull the climbing rope up once the carabiner is hooked onto the desired anchor. Finally, a camera must be integrated on the drone to provide the operator visual feedback relating the carabiner to the target roof anchor.</p>

<h1 id="preliminary-design">Preliminary design</h1>

<p>The initial design for this project was a singular 3D printed piece that mounts to a DJI F450 frame since I had a few of these lying around. While this design is functional, the large propeller diameter negatively impacts the drone’s agility and the drone’s size make it a poor solution in terms of portability. [PICS] Due to these reasons, a new design was created using a [215mm?] race drone frame. The new design is much more portable and breaks down into two pieces such that it can be more reasonably stored in a small volume.</p>

<h1 id="final-design">Final design</h1>

<p>In addition to its modularity, the final design has two servos on the carabiner holder component: the first (1) retains a rubber band which is wrapped around the holder to keep the latch open while the second (2) supports the weight of the rope being carried by the carabiner.</p>]]></content><author><name>Alex Ludicrous</name></author><summary type="html"><![CDATA[A physical infiltration tool]]></summary></entry><entry><title type="html">Modernizing my 2013 Subaru BRZ</title><link href="http://localhost:4000/brz/" rel="alternate" type="text/html" title="Modernizing my 2013 Subaru BRZ" /><published>2022-06-01T00:00:00-04:00</published><updated>2022-06-01T00:00:00-04:00</updated><id>http://localhost:4000/brz</id><content type="html" xml:base="http://localhost:4000/brz/"><![CDATA[<p>I recently acquired a car for recreational purposes since I had saved up a decent amount of money and didn’t feel like investing it. I purchased a BRZ because they are built in conjunction with Toyota and this should theoretically imply that they are relatively reliable so I won’t need to worry about the mechanical aspect of the vehicle. Furthermore, this colaboration with Toyota also makes them relatively easy to work on at home which I am thankful for since I’ve had to do a wealth of maintenance on it even going as far as removing failing drivetrain elements.</p>

<h1 id="idea">Idea</h1>

<h2 id="ui-enhancements">UI Enhancements</h2>

<p><img src="/assets/img/brz/planned_display_layout.jpg" alt="Picture of plan" style="float: right; width:50%; height:80%; margin-left: 10px;" /></p>

<p>The plan is to replace the head unit of the BRZ with a <a href="https://www.aliexpress.com/item/1005003546521274.html">12.3” touch-screen</a>, replace the small button cluster on the center console with a <a href="https://www.aliexpress.com/item/4000393713339.html">7” touch screen</a>, convert the analog gauge cluster to a display, and potentially add a heads up display in the windshield. The 12.3” display will be used for most vehicle functionality such as navigation and media whereas the 7” display will provide diagnostic information about the vehicle as well as any subsystems I add. Ideally, the computer running the 7” display will have access to the car’s internal computer to provide any information from DTC/SRS/ABS codes to general information about things like tire pressure.</p>

<p>The car will have an LTE modem in it to provide WiFi connectivity for passengers and allow its internal computers to access Google Maps, media streaming services, and other resources such as the Waze database to protect against police encounters. Finally, I hope to add cameras all around the car and experiment with computer vision though, aside from collision warnings and enhanced cruise control I’m not sure what I’ll be able to develop. The cameras will however provide a 360-degree dash cam and I will be able to use them for a Tesla-like sentry mode when the car is locked.</p>

<h2 id="speed-enforcement-countermeasures">Speed Enforcement Countermeasures</h2>

<p>I’m hoping to, at the very least, add passive sensors for police radar/lidar and possibly even aircraft but I may not be able to add active countermeasures such as radar/lidar jamming. Based on some brief research, there is a significant risk that the officer’s radar/lidar gun would detect my jamming attempts since many of them have jamming detection built in and proper commercial lidar jammers are designed to identify the specific make/model of a lidar gun and behave accordingly.</p>

<p>Aircraft countermeasures are more reasonably achieveable since aircraft speed detection works using lines painted on the pavement at a known distance interval such that an aircraft flying above can time a vehicle crossing a set of these lines. My plan for countering this is to use a front facing camera on the car to pick up the lines at which point an onboard computer will use a software defined radio to look for any aircraft transponders within a certain radius of the vehicle. Should there be an aircraft nearby, the onboard computer will begin calling out speeds for the user to match in hopes that the average speed across the two lines does not exceed the posted limit.</p>

<p>An even more complex countermeasure I’m hoping to integrate is cellular sniffing where a computer would once again use a software defined radio to look for nearby cellular devices and fingerprint them to single out the specific make and model of cellular modem present in a Ford Interceptor. I’m unsure if this is even theoretically possible since newer cellular devices may encrypt everything but I intend to research this in depth.</p>

<p>In addition to passive countermeasures and radar/lidar jammers, the vehicle will hopefully have cellular and VHF/UHF jammers. The purpose of these is to prevent a Ford Interceptor’s cellular modem and radio from working when in close proximity to the vehicle. This way the officer will not be able to run the driver’s license or even issue tickets and this could delay a call for backup during a police chase.</p>

<h1 id="build">Build</h1>

<h2 id="design-considerations">Design considerations</h2>

<p>I initially intended to build a custom image of Android Automotive for the BRZ and develop mobile applications that would mostly run as backgroud services and overlay themselves on top of Android to display relevant information. Unfortunately this turned out to be a rather lucrative task and as of this writing I have elected to build a simple Android application running on a mobile image. The advantages of Android Automotive are as follows:</p>
<ul>
  <li>Better navigation with fully functional Google Maps (I am using the Khadas VIM4 for the head unit and it does not support Google Play Services so it cannot have any Google Maps functionality)</li>
  <li>Better media controls with proper Bluetooth integration (As far as I am aware, Android Mobile cannot be used as a A2DP sink without modifying the source code)</li>
  <li>Better boot times
Overall, I did not feel these advantages were enough to justify the increased complexity of building a custom Android Automotive image especially considering how many custom UI screens and functions I ended up incorporating.</li>
</ul>

<p>The purpose of rebuilding the vehicle’s UI is not only to provide a seamless means of interacting with additional functionality but also to fully hide any illegal functions on demand. As such, there must not be any visible hint of any countermeasure functionality on the inside and outside of the vehicle and as such the car is able to hide illegal functionality when in ‘legal mode’ which can be enabled using arbitrary key strokes or combinations. Once in legal mode, the user is able to unlock hidden functions by entering an arbitrary set of seemingly random keystrokes using buttons throughout the car’s interior. The combination is such that it would be incredibly difficult to guess or mistakenly enter it.</p>

<h2 id="hardware">Hardware</h2>

<h3 id="computers">Computers</h3>

<p>The car will contain a multitude of computers listed below alongside their purpose:</p>
<ul>
  <li>Head Unit/Center Console (Khadas VIM4) –&gt; Mostly displays data and video feeds, very little logic goes on here</li>
  <li>Diagnostic computer (RPi ?) –&gt; Connects to OBDii port and reports back data as HTTP server on internal network</li>
  <li>Arduino head unit (Arduino Mega) –&gt; Acts as interface between ethernet network and Arduino serial networks</li>
  <li>Gauge cluster computer (RPi Zero?) –&gt; Listens to CANBUS and ethernet network to display data</li>
  <li>Safety computer (nVidia Jetson NX?) –&gt; Uses CV algorithms on vehicle cameras and exports HDMI feeds of cameras for head unit</li>
</ul>

<p>Most of the hardware modifications done to the vehicle are exectued by Arduinos integrated throughout the vehicle that share a set of serial networks with the Arduino head unit computer. The list of integrated Arduinos as well as the model used is as follows:</p>
<ul>
  <li>Head light manager (MEGA_EMBED) –&gt; Used for light animations up front, has relays to control lights and voltage dividers to light input from car’s computer as well as addressable LEDs integrated in the grill.</li>
  <li>Rear light manager (MEGA_EMBED) –&gt; Same idea but for rear lights. This Arduino also has an accelerometer such that it can flash the brake lights when braking hard.</li>
  <li>Siren manager (NANO?) –&gt; Has an SD card reader to store audio files and feeds audio to a dedicated amplifier for the vehicle’s loud speaker.</li>
  <li>Mirror manager (NANO) –&gt; Keeps track of mirror position and allows them to automatically tilt when backing up. One per mirror.</li>
  <li>HVAC manager (MEGA_EMBED) –&gt; Provides data regarding car’s HVAC system and is able to simulate button presses to modify HVAC settings. This Arduino also receives the ‘reverse signal’ from the car and forwards it to mirror managers etc.</li>
  <li>Diagnostic display button manager (NANO) –&gt; Controls relays that simulate button presses to maintain functionality of old center console buttons.</li>
  <li>Steering wheel button manager (LEONARDO) –&gt; Converts steering wheel button presses into USB keyboard data for head unit computer. Also forwards keystrokes to Arduino manager so commands can be dispatched downstream and eliminate latency by avoiding going through the head unit computer.</li>
  <li>Power managers (MEGA_EMBED) –&gt; Handles power delivery to components using large relay boards to provide active failover functionality and monitor current/voltage among vehicle power buses. Two of these will be installed: one in front near the head unit and one in the trunk.</li>
  <li>Audio manager (MEGA_EMBED) –&gt; Handles audio amplifier settings (equalizer and volume) and simulates keystrokes on a Bluetooth dongle used to receive mobile audio. Since the head unit computer can’t be used as a A2DP sink, I am using a standalone Bluetooth dongle to receive mobile audio. This allows me to control the music from the head unit however I won’t be able to keep track of the song’s progress or display the album cover.</li>
  <li>Controller (MEGA_FULL) –&gt; Has a few serial buses to unite all child devices as well as an ethernet adapter to communicate with ethernet network. There is a serial bus for devices which regularly and consistently broadcast data such as the power managers, a bus for each inconsistent device such as the steering wheel manager, and a bus for devices that solely execute actions without providing feedback.</li>
</ul>

<h3 id="cameras">Cameras</h3>

<p>The planned camera layout is included below however two cameras are omitted: one on the interior and another on the right side mirror. Of the cameras that are visible, the green semicircles are <a href="https://www.aliexpress.com/item/1005004337827464.html">136-degree FOV cameras</a> installed in the front windshield and above the rear license plate whereas the grey circles represent <a href="https://www.aliexpress.com/item/1005004335144138.html">180-degree cameras</a> installed beneath side view mirrors of the car. Of the omitted cameras, the interior camera faces the driver and is used for eye tracking such that the touch screen functionality of the center console is not enabled unless the driver is looking at the monitor to prevent accidental input. I planned on including a front-facing camera on the right wing mirror to provide the driver with insight about any vehicles in the right lane ahead of the car that the driver may not be able to see. This camera is not included at this time since the 180-degree FOV camera installed beneath the right side mirror should theoretically capture any vehicles in the right lane and as such the extra camera should not be necessary.</p>

<p><img src="/assets/img/brz/camera_layout.png" alt="Camera layout" /></p>

<h3 id="steering-wheel-button-integration">Steering Wheel Button Integration</h3>

<p>Steering wheel buttons were added to BRZs in 2017 and mine is a 2013 so I purchased a salvage steering wheel in order to integrate its buttons into my systems. Should anybody else contemplate to do the same, be aware that even though steering wheels are cheap the airbag most certainly is not: a brand new OEM airbag for my car is $CAD 1100 from the dealer while a used one is ~$CAD 600.</p>

<p>The steering wheel uses an Arduino Leonardo (is there a smaller solution available?) to convert button presses into keyboard output for the Khadas VIM4 to understand. Furthermore, it connects to the Arduino serial network to circumvent the car’s internal network when forwarding any hardware-related commands such as police light or horn/siren triggers. In order to program the Arduino, I took apart the button clusters on each side of the 
<img src="/assets/img/brz/steering_wheel_button_connector.jpg" alt="Steering wheel button connector" style="float: right; width:50%; height:80%; margin-left: 10px;" />
steering wheel and looked at the traces to figure out the function of each wire. My findings are listed below for anybody else intending to reverse engineer the steering wheel buttons on a BRZ (wires are listed from left to right, top to bottom, looking at the connector from behind as depicted to the right):</p>
<ul>
  <li>Light green –&gt; Volume + arrow keys of left side custer</li>
  <li>Red –&gt; Common of left side cluster</li>
  <li>Green –&gt; Arrow keys of right side cluster</li>
  <li>Purple –&gt; Other keys of right side cluster</li>
  <li>Yellow –&gt; Common of right side cluster</li>
  <li>Blue –&gt; Steering wheel ground</li>
  <li>Brown –&gt; Cruise control pin 1</li>
  <li>Grey –&gt; Cruise control pin 2</li>
  <li>Black + Yellow –&gt; LED ground</li>
  <li>Light yellow –&gt; LED VCC (3.3V works, not sure about 5V)</li>
</ul>

<p>The ‘voice’ button on the right side of the steering wheel is wired to the left button cluster and its state is transmitted through the (light green or black) wire. Button states are transmitted by varying the resistance between the common pin of each button cluster and one of the two output pins of each button cluster. The Arduino interprets these using a pulldown resistor on each output pin as explained <a href="https://www.circuitbasics.com/arduino-ohm-meter/">here</a>. Finally, the right side of the steering wheel is used to control the big fragment of the head unit while the left side is used to control the small fragment; the buttons change functionality based on which fragment is live when they are pressed.</p>

<h2 id="visual-user-interface">Visual User Interface</h2>

<h3 id="head-unit-display">Head Unit Display</h3>

<p>The large head unit display is split horizontally into two sections: a ‘big container’ which is 2/3 of the display’s width and a ‘small container’ which occupies the remaining space. The views displayed by the big container and their respective purpose are as follows:</p>
<ul>
  <li>Navigation fragment –&gt; Contains an interactive map that the user</li>
  <li>Lighting control fragment –&gt; Handles interior accent colours and vehicle underlighting (legal light functions)</li>
  <li>Safety fragment –&gt; Displays live view of cameras around the car as well as any computer vision-related safety warnings</li>
  <li>Settings fragment –&gt; Allows user to modify settings of any subsystem</li>
  <li>Defence fragment –&gt; Compliments defence fragment in small container, displays advanced countermeasures</li>
</ul>

<p>The views displayed by the small container and their respective purpose are as follows:</p>
<ul>
  <li>Media fragment –&gt; Handles media playback controls</li>
  <li>Diagnostic fragment –&gt; Mirror of center console display, describes states of vehicle systems</li>
  <li>Soundboard fragment –&gt; Enables playback of custom sounds through a loudspeaker in front of vehicle</li>
  <li>Pop-up defence fragment –&gt; Brief rundown of coutermeasure states, this fragment is automatically overlayed when vehicle detects radar/lidar etc.</li>
  <li>Traffic advisor fragment –&gt; Allows user to control illegal light patterns of vehicle including police and hazard strobes</li>
</ul>

<p>In addition to the two primary fragment containers, a few fragments can be overlayed on top of the whole display in specific circumstances:</p>
<ul>
  <li>Parking fragment –&gt; Overlayed when vehicle is put into reverse by driver and persists until vehicle speeds up regardless of which gear the vehicle is in. This fragment provides data from parking sensors and cameras around vehicle to facilitate parking.</li>
  <li>Merging fragment –&gt; Pops up when merging right, provides live view of right windshield camera and right mirror camera so driver can see into adjacent lane and blindspot.</li>
</ul>

<h3 id="diagnostic-display">Diagnostic Display</h3>

<p>This display provides the same view as the diagnostic fragment from the head unit display however there are also be four buttons underneath this view to replace the physical buttons that used to be in the center console (ADD PIC). Furthermore, this display is capable of opening in depth sub-system diagnostic dialogs and clear error codes as well as execute diagnostic actions whereas the head unit fragment solely provides status information. (TRUE?) This display runs off the same computer as the head unit since it has shared views and processes similar data.</p>

<h3 id="gauge-cluster-display">Gauge Cluster Display</h3>

<p>Listens to car’s CANBUS and displays the same information as was available with original gauge cluster though it also adds data for range and displays alerts from vehicle systems. (TRUE?) Furthermore, can be used to display night vision camera in front of vehicle to drive in less than optimal lighting conditions.</p>

<h3 id="heads-up-display">Heads Up Display</h3>

<p>Might scrap this but would display basic vehicle information.</p>

<h2 id="interactive-user-interface">Interactive User Interface</h2>

<p>The head unit and diagnostic displays have touchscreen functionality however the head unit display can also be controlled using steering wheel buttons for a hands free experience. The diagnostic display can only be used as a touch screen however the touch screen is disabled if the driver is not looking at the display in order to prevent misinput when shifting.</p>

<p>The right side steering wheel buttons are used to control the contents of the big container while the left side steering wheel buttons are used for the small container’s contents. Additionally, there are dedicated consistent buttons or combinations thereof that can be used to toggle critical functions such as the vehicle’s legal mode regardless of what content is live at the time.</p>]]></content><author><name>Alex Ludicrous</name></author><summary type="html"><![CDATA[I recently acquired a car for recreational purposes since I had saved up a decent amount of money and didn’t feel like investing it. I purchased a BRZ because they are built in conjunction with Toyota and this should theoretically imply that they are relatively reliable so I won’t need to worry about the mechanical aspect of the vehicle. Furthermore, this colaboration with Toyota also makes them relatively easy to work on at home which I am thankful for since I’ve had to do a wealth of maintenance on it even going as far as removing failing drivetrain elements.]]></summary></entry><entry><title type="html">Smart Holographic Sight</title><link href="http://localhost:4000/smart-sight/" rel="alternate" type="text/html" title="Smart Holographic Sight" /><published>2022-02-25T00:00:00-05:00</published><updated>2022-02-25T00:00:00-05:00</updated><id>http://localhost:4000/smart-sight</id><content type="html" xml:base="http://localhost:4000/smart-sight/"><![CDATA[<h2 id="intelligent-weapon-optics">Intelligent weapon optics</h2>

<p>My overarching goal with a lot of the things I build is to develop a small ecosystem of tactically useful devices that can exchange information and provide the user with an advantage over their adversary. These devices include anything from motorized ascenders to augmented reality devices and UAVs. The SmartSight may work in conjunction with a motorized ascender such that the user can maintain the optic at eye level while also being able to control their ascender. This would provide the ability to keep a weapon tracked on a target while moving up or down the side of a building, for example. The SmartSight idea came about as I saw an old project by a <a href="https://andymeng.dev/">friend</a> of mine and decided to elaborate on it.</p>

<h1 id="basic-premise">Basic Premise</h1>

<p>The SmartSight contains a small display which reflects through a mirrored lens that allows the user to see both the display and the real world, just like a traditional holographic sight. I’m not too sure how much information I will present on the display; so far I intend to display a shot counter and a reticle which can adjust based on weapon cant. Furthermore, I will add indicators that describe the motorized ascender’s state and possibly a rangefinder at the very least. I only intend to use this on airsoft rifles so the rangefinder doesn’t need to be excessively good.</p>

<h1 id="update-jun-2022">UPDATE Jun 2022</h1>
<p>I have been working on this ascender on and off for a while now without updating this page.
<img src="/assets/img/smart-sight/frontV2.PNG" alt="FrontV2" style="float: right; width:50%; height:50%; margin-left: 10px;" />
 I received the new 1.3” displays about a month ago and have generated a new CAD model which accomodates the larger display. The new display covers the majority of the space available on the lens and a shroud was included in this design to ensure that the optic remains viable even when exposed to sunlight. The previous design would likely have suffered in bright environments given how weak the displays are. Below is an updated exploded view of the new design:
<img src="/assets/img/smart-sight/explodedV2.PNG" alt="Exploded View V2" style="display: block; margin-left: auto; margin-right: auto; margin-top: 10px" /></p>

<p>A couple iterations of this design have been printed and all that is left at the moment is to wire up the final version and develop software. Since this design uses an Arduino Nano with its USB port exposed at the back, iterating software should be a piece of cake which can’t be said for the <a href="/lora-sensor-suite/">LoRa Sensor Project</a>.</p>

<h1 id="update-mar-2022">UPDATE Mar 2022</h1>

<p>The last version used a 0.96” 80x160 <a href="https://www.aliexpress.com/item/1005003514645335.html">ST7735S display</a> which has great pixel density but does not manage to cover the whole lens that it’s being reflected through. To rectify the issue, I recently purchased a 1.3” 240x240 <a href="https://www.aliexpress.com/item/4001282467099.html">ST7789 display</a> that is large enough to mostly cover the exposed area of the lens.</p>

<p><strong>TODO</strong> Generate new model with bigger display and whatnot.</p>

<h1 id="update-feb-2022">UPDATE Feb 2022</h1>

<p><img src="/assets/img/smart-sight/front.PNG" alt="Front" style="float: right; width:50%; height:50%; margin-left: 10px;" />
Got around to creating a CAD model of the sight; this model is technically the third iteration but it represents the first reasonably functional version. It has space for an Arduino Nano, LoRa SX1278 transceiver, display, and a LiPo though no antenna mounting hole has been added. Having created this model with a transceiver onboard, I considered the possibility of including a remote kill feature for disabling weapons and as such I will probably need to wire the sight into the gun’s electronics. This means that future designs don’t strictly need to include space for a LiPo but I’m unsure of whether or not I will remove it just yet.</p>

<p><img src="/assets/img/smart-sight/back.PNG" alt="Back" style="float: left; width:50%; height:50%; margin-right: 10px;" />
Unfortunately, this design was built to fit some standardized Picatinny rail dimensions I found <a href="https://upload.wikimedia.org/wikipedia/commons/thumb/9/95/Picatinny.svg/1200px-Picatinny.svg.png">online</a> and these did fit one of the rifles I own but not the functional one. I was picky in finding my dimensions since the design was built all in metric units which may have caused some inaccuracies so the next design will be built using real measurements from the functional rifle. The intent with this design was to stick the antenna out the side of the sight but this is a poor decision considering the wear and tear that the weapon will likely be subjected to so I try to will integrate the antenna within the sight for the next iteration.</p>

<p>Here is an exploded view of this model:
<img src="/assets/img/smart-sight/exploded_noWriting.PNG" alt="Exploded View" style="display: block; margin-left: auto; margin-right: auto; margin-top: 10px" /></p>]]></content><author><name>Alex Ludicrous</name></author><summary type="html"><![CDATA[Intelligent weapon optics]]></summary></entry><entry><title type="html">DIY 3D Printed Powered Ascender</title><link href="http://localhost:4000/powered-ascender/" rel="alternate" type="text/html" title="DIY 3D Printed Powered Ascender" /><published>2022-01-01T00:00:00-05:00</published><updated>2022-01-01T00:00:00-05:00</updated><id>http://localhost:4000/powered-ascender</id><content type="html" xml:base="http://localhost:4000/powered-ascender/"><![CDATA[<h2 id="shouldnt-work-but-it-might">Shouldn’t work but it might</h2>

<p>I figured that, considering people have 3D printed functional guns, surely it must be possible to 3D print an ascender without worrying about the material’s strength. Initial designs are solely for prototyping and, as such, have no accomodations for the ESCs, batteries, or any hardware besides pulleys and motors.</p>

<h1 id="update-jun-2022">UPDATE Jun 2022</h1>

<p>Took a relatively long break from personal projects and school work since I got burned out; this update should have come in March but I am only getting around to it in June. A friend of mine asked me to revisit the personal ascender project since we may have identified a genuine use case for it. 
<img src="/assets/img/ascender/mit-ascender.PNG" alt="MIT Ascender" style="float: right; width:60%;" />
I was simultaneously made aware of <a href="https://dspace.mit.edu/bitstream/handle/1721.1/92180/897205934-MIT.pdf;sequence=2">this paper</a> written by Daniel P. Gillund, a Mechanical Engineering student at MIT. He built a relatively cheap ascender using the motor and gearbox of a hand drill alongside a few machined parts of his own. The prototype (pictured to the right) relies on a Capstan pulley to generate adequate friction with the rope thereby solving my problem.</p>

<p>This design had a couple minor flaws described in section 7.4 of the paper which could easily be improved by iterating the design. The only other modification required will be to modify the ascender’s capstan pulley to accomodate thicker rope; my use case will require this ascender to work with 16mm polysteel rope commonly used by window washers. The thickness of this rope translates to a comparatively thicker Capstan pulley thereby hopefully increasing the feasabiliy of placing the planetary gearbox within the Capstan pulley itself. I will likely begin by designing an ascender for 8-10mm climbing rope and go from there once that design is proved to be feasible.</p>

<h1 id="update-feb-2022">UPDATE Feb 2022</h1>

<p>Previous design did not work well, there was a substantial lack of grip on the rope which led to excessive friction that melted part of the rope. Furthermore, the ‘teeth’ on the drive pulley wore out in no time so I will be abandoning these in the future; I knew they wouldn’t last long but I assumed they would simply round off as opposed to completely melting off.</p>

<p>One solution to the lack of grip is increasing the number of drive pulleys in the design, but in the interest of keeping things simple and compact the new design simply has the rope loop around the drive pulley multiple times. The new issue to consider here is is whether or not the drive pulley will get crushed now because, by looping the rope around multiple times, the drive pulley is now effectively supporting the full weight of the wearer.</p>

<h1 id="update-jan-2022">UPDATE Jan 2022</h1>

<p>I only have 5015 320kV motors available to me which are meant to be used for the Jaguar UAV; given their high kV and low torque rating I will be using two of these in tandem. I am confident in the motor mount and side panel of this prototype, however I fully expect the main pulley to fail but only time will tell.</p>

<p>I started with the main gear that is responsible for feeding the rope through the ascender. Initially, the gear was 80 mm in diameter to provide more surface area thereby having greater grip on the rope; this was later reduced to 40mm because the motors I own have a relatively high kV so they need to work at a higher RPM to produce their rated torque. Below is a preliminary model of the main pulley. It has a hole in the center to accomodate the motor’s shaft and four holes that are meant to be occupied by the heads of 4 screws mounted to each motor. I was unsure of how else to link the motors and pulley without overcomplicating the design.
<img src="/assets/img/ascender/V1-main-pulley.PNG" alt="Main pulley design" />
The image below depicts the assembly without a sidepanel to display the internals. The blue solid demonstrates where the rope is meant to go and the red arrow point upwards.
<img src="/assets/img/ascender/V1-assy-without-sidepanel.PNG" alt="Assembly w/o side panel" />
Below is the complete assembly.
<img src="/assets/img/ascender/V1-assy.PNG" alt="Complete assembly" /></p>]]></content><author><name>Alex Ludicrous</name></author><summary type="html"><![CDATA[Shouldn’t work but it might]]></summary></entry><entry><title type="html">LTE Mavic Pro</title><link href="http://localhost:4000/lte-mavic-pro/" rel="alternate" type="text/html" title="LTE Mavic Pro" /><published>2021-12-03T00:00:00-05:00</published><updated>2021-12-03T00:00:00-05:00</updated><id>http://localhost:4000/lte-mavic-pro</id><content type="html" xml:base="http://localhost:4000/lte-mavic-pro/"><![CDATA[<h2 id="limitless-range-and-enhanced-autonomy">Limitless range and enhanced autonomy</h2>

<p>LTE based drone control has been a longstanding goal with the purpose of creating UAVs requiring minimal user input to function. I have found the need for constant input to significantly reduce the useability of drones for recon during my adventures because neither myself nor the people with me can dedicate significant attention to piloting them. This project aims to achieve basic autonomous control through an Android application that allows the user to place the drone at specific coordinates or land it. The first rendition was built to be submitted as an electronics project for a university course and is solely capable of navigation; takeoff and landing must be manually with a separate remote controller. This is because a F1 flight controller was used which is only capable of managing stability.</p>

<h1 id="basic-idea">Basic Idea</h1>

<p>The drone will be centered around a Raspberry Pi Zero and a LTE modem for internet access. A Raspberry Pi CM4 could fit and would be beneficial but I am not currently capable of developing carrier boards and a full size Raspberry Pi will not fit. The Pi’s serial port is dedicated to communicating with the flight controller through iBus since iBus operates at 115200 baud and bit bashing on the Pi becomes unreliable past 19200 baud. The GPS data will be received using a GPIO pin and bit bashing and another bit bashing serial connection will be used to communicate with an Arduino. The Arduino serves as an IO expander for the Pi to manage the LEDs on the drone as well as an ultrasonic sensor and sense voltage and current throughout the drone. Using an Arduino as such is advantageous since it has an ADC whereas the Pi does not. Additionally, offloading time-sensitive operations such as reading the ultrasonic sensor and running the drone’s LED patterns decreases the complexity of the Pi’s code.</p>

<h2 id="data-link">Data Link</h2>

<p>My current LTE modem filters all ports no matter what settings I chose within its menu. For this reason, I’ve elected to use a P2P UDP protocol which is able to punch through firewalls. A second Raspberry Pi will serve as an intermediary P2P server to connect the cell phone and drone given that neither has a static IP. The P2P code was largely copied from https://github.com/grakshith/p2p-chat-python.git and modified to better fit my protocol. Both the drone and cell phone should identify themselves during their initial UDP broadcast in order to identify what function they serve; this future proofs the server’s code since I can selectively connect devices based on functionality as opposed to the time at which they contact the server. Once two compatible hosts have broadcast their address/port to the P2P server, they will each receive the address/port of the other client and the server logs the connection before discarding all saved host data.</p>

<h2 id="flight-algorithm">Flight Algorithm</h2>

<p>The version submitted for my course uses a rather primal flight algorithm in which the Pi has a barometer and compass connected to it through I2C. Using GPS, compass, and altitude data the Pi is able to compute a vector from its current coordinates to the target coordinates using the haversine libary for Python and a bearing function I stole from StackExchange. It then points the drone in the target direction and goes forward; the drone’s speed varies based on distance to target and it progressively slows down as the distance decreases. The current version offloaded all navigation to the flight controller running iNav thereby reserving the Pi’s looptime for more useful functions such as WiFi, cellular, and UHF sniffing. OpenCV can also be used on the Pi to provide some level of active tracking and increase the effective autonomy of this platform. For this, I may need to choose a UAV platform with surround cameras such as the Mavic 2 or Skydio 2 and upgrade to an nVidia Jetson computer since having the drone actively follow subjects would require some level of obstacle avoidance.</p>

<h1 id="update-feb-2022">UPDATE Feb 2022</h1>

<p>Obtained a SucceX-D Mini F7 Twin G stack and redesigned the 3D printed bracket which holds all the electronics inside the Mavic. 
<img src="/assets/img/hacked-mavic/board-mount-V3.PNG" alt="Bracket V2" style="float: right" />
The new design no longer requires tape and glue but rather relies on three pre-existing screwholes used by the original DJI flight control board. It took a few revisions to finalize the fit of the board such that the components comfortably fit within the restricted space originally occupied by DJI’s proprietary electronics. This is the fifth revision of the bracket and it includes mount points for a 4-in-1 ESC board, flight controller, the Raspberry Pi, and a Flysky receiver. I’m sticking with the Flysky receiver over a Crossfire system since it is able to take advantage of the 2.4 GHz antennas already integrated in the Mavic leading to a more ‘stock’ look. The 4-in-1 ESC board is on the bottom such that it can be in contact with the bottom heatsink of the Mavic and hopefully take advantage of it. Realistically, this ESC board is rated for 45A per motor which is likely over double what the motors should be drawing. Finally, I have decided to remove the Arduino since I should be able to accomplish its tasks with threaded processes on the RPi. In doing so, I am now once again able to install the OEM gimbal on the drone and, since the DJI Mavic’s camera seems to use MIPI, I should be able to interface it with the RPi (I haven’t yet tested the camera’s protocol but its connector looks identical to that of the Caddx Polar camera I own).</p>

<p>Unfortunately I still do not have a compact cellular modem and I am not sure where I will be able to fit it. I also need to create a custom target to flash the F7 board with iNav since I don’t believe Betaflight is capable of executing waypoint missions through telemetry but I will see if that’s a possibility. I also need to figure out if the flight controller is able to arm and takeoff without any contribution from the receiver since I only intend to keep it for debugging/testing purposes and it is not intended to be used during regular operation.</p>

<h1 id="update-dec-2021">UPDATE Dec 2021</h1>

<p>Initial bracket designs relied on double sided adhesive and a small bracket to effectively hold down all the internals. 
<img src="/assets/img/hacked-mavic/board-mount-V1.PNG" alt="Bracket V1" style="float: right" />
This design makes maintenance virtually impossible without considerably disassembling the drone so current versions use existing screwholes to ensure a more secure fit. The varying boards within the Mavic are installed as follows:</p>
<ul>
  <li>The flight controller is installed sideways on the front of the bracket immediately following the pre-existing fan</li>
  <li>A 20x20mm 20A ESC board is installed immediately following the flight controller on the underside of the bracket. This allows for thermal pads to be placed between the ESCs and the Mavic’s pre-existing heatsink thereby providing some cooling.</li>
  <li>Following the ESC, the LTE modem and an Arduino Nano are installed on the bottom of the board.</li>
  <li>The top of the bracket is exclusively reserved for the Raspberry Pi Zero. Ideally, the Pi would be on the bottom so that the heatsink could cool it but unfortunately the ultrasonic sensors make this difficult so I had to place it on top. Fortunately, the Pi Zero does not need any cooling so I will keep it like this for future designs.</li>
  <li>Finally, a FlySky i6X receiver is shoved within the wiring towards the end of the drone body for debugging purposes.</li>
</ul>

<p><img src="/assets/img/hacked-mavic/build-V1.jpg" alt="Mavic Build V1" /></p>

<h1 id="code">Code</h1>

<h2 id="raspberry-pi">Raspberry Pi</h2>

<p>The Raspberry Pi runs off of a Python program split into four key files:</p>
<ul>
  <li><strong>main.py</strong> –&gt; this file is what runs upon startup. It calls upon the other three and synchronizes data between files (takes updated target coordinates from network.py and sends them to flight.py)</li>
  <li><strong>network.py</strong> –&gt; this file handles all P2P communication and is responsible for maintaining a link with the cell phone. It receives target coordinates and saves them in a local variable which is then queried by main.py</li>
  <li><strong>flight.py</strong> –&gt; handled flight algorithm in implementation for my course however <strong>TODO</strong> current version dispatches target coords to the flight controller and monitors telemetry data so it can be passed on to the Android application</li>
  <li><strong>misc.py</strong> –&gt; contains random functions used by all files such as logging</li>
</ul>

<h2 id="arduino">Arduino</h2>

<p>Pins A0 and A1 are used for detecting voltage from the battery and the 5V rail. Pins 2 and 13 are used as digital outputs for controlling the LEDs on the left and right front arms of the Mavic, respectively. Pin 8 is used for the LEDs throughout the drone which are single WS2812b pixels while pins 5 and 6 are used to monitoring the ultrasonic sensor. The LED patterns were done by keeping track of loop time: every time an LED pattern begins the value of millis() is saved in cycleStartTime, and for every time the code runs the current output is compared to cycleStartTime. Each cycle has an arbitrary time step, for example a cycle may have 8 time steps all of which last 800ms. These time steps are encoded in if statements that compare millis() to cycleStartTime and figure out which time step the cycle should be running. Once all 8 time steps have finished, cycleStartTime is updated to represent the current time and the cycle restarts.</p>

<h2 id="android-studio">Android Studio</h2>

<p>Not sure where exactly to go with the application. Probably gonna open to a full screen map but also have another activity for the drone camera feed/more complex controls. The user will be able to have either activity open full screen or split the screen so both can be viewed at the same time.</p>]]></content><author><name>Alex Ludicrous</name></author><summary type="html"><![CDATA[Limitless range and enhanced autonomy]]></summary></entry><entry><title type="html">Jaguar (Medium-sized VTOL UAV Platform)</title><link href="http://localhost:4000/jaguar/" rel="alternate" type="text/html" title="Jaguar (Medium-sized VTOL UAV Platform)" /><published>2021-12-01T00:00:00-05:00</published><updated>2021-12-01T00:00:00-05:00</updated><id>http://localhost:4000/jaguar</id><content type="html" xml:base="http://localhost:4000/jaguar/"><![CDATA[<h2 id="simple-but-limited-uav-platform-for-urban-operations">Simple but limited UAV platform for urban operations</h2>

<p>I kept seeing ~2.5m wide VTOL UAVs on AliExpress that I would love to own but they are all rather overpriced so I decided to make my own. Using the tech I played with while developing the LTE-based Mavic Pro I intend to have this drone operated by a cellular application and AI to minimize how much interaction is required from the user.</p>

<p>I purchased motors and ESCs in accordance with <a href="https://www.aliexpress.com/item/1005002831031206.html?spm=a2g0o.productlist.0.0.38ef1d39JjUhDN&amp;algo_pvid=7475fc42-48b8-4b91-ad05-eff71d8d9826&amp;algo_exp_id=7475fc42-48b8-4b91-ad05-eff71d8d9826-8">this</a> VTOL from AliExpress because it will be similarly sized to my final design.</p>

<h1 id="design-overview">Design Overview</h1>

<p>This design relies heavily on 3D printed components and foamboard/spars which can be sourced at Dollarama. The general premise is to create a form of outline using 3D printed ribs and cover it in delaminated foamboard. The spars inside the fuselage are fiberglass whereas all other spars in the aircraft are steel broomsticks from Dollarama. The current design is solely a prototype and, as such, the extra weight should not matter.</p>

<h1 id="update-mar-2022">UPDATE Mar 2022</h1>

<p>Project abandoned for financial reasons.</p>

<h1 id="update-feb-2022">UPDATE Feb 2022</h1>

<p>Removable wing extensions have been finished.</p>

<p><strong>WING PICS</strong></p>

<p><img src="/assets/img/jaguar/CAD-V1.PNG" alt="Tail closeup" style="float: right; width:50%; height:50%" />
The CAD design has also been updated to include more specific design considerations for the tail: there are now servo and LED holes. The VTOL motors and mounts have been omitted in the design below. I also doubled the rib density in the wing based on my experience when building the removable portions; one rib every 8 inches allowed for an inconsistent profile at the leading edge once the foamboard was delaminated on one side.</p>

<p><img src="/assets/img/jaguar/CAD-V2.PNG" alt="Updated CAD" /></p>

<h1 id="update-dec-2021">UPDATE Dec 2021</h1>

<p>Went on a last minute trip before the COVID-19 Omicron wave and, for some reason, I find that my design productivity is very high while travelling so I was able to finish the CAD design for this UAV. The internals of the plane are not yet finalized because I have not yet decided on the specifications of the battery and I can’t fully imagine what components will be included in the UAV just yet. The current CAD progress focused on obtaining a general shape for the aircraft and fully designing the wings as well as the rear half of the fuselage containing the camera gimbal, electronics, and thrust motor. The tail is currently designed but without any considerations about the electronics which will be housed within.</p>

<p><img src="/assets/img/jaguar/CAD-V1.PNG" alt="Original CAD" /></p>

<p>I’ve also been printing wing ribs on and off for a few weeks now in hopes that I can begin construction soon. It’s difficult to decide where I should begin with a project as daunting as this one.</p>]]></content><author><name>Alex Ludicrous</name></author><summary type="html"><![CDATA[Simple but limited UAV platform for urban operations]]></summary></entry><entry><title type="html">Mining Rig Temperature Control</title><link href="http://localhost:4000/mining-rig-temp-control/" rel="alternate" type="text/html" title="Mining Rig Temperature Control" /><published>2021-11-25T00:00:00-05:00</published><updated>2021-11-25T00:00:00-05:00</updated><id>http://localhost:4000/mining-rig-temp-control</id><content type="html" xml:base="http://localhost:4000/mining-rig-temp-control/"><![CDATA[<h2 id="a-solution-for-outdoor-mining-rigs-during-winter">A solution for outdoor mining rigs during winter</h2>

<p>I briefly decided to invest in a few graphics cards with all the recent hype surrounding cryptocurrencies and mining. I figured, with GPU prices today, it would be rather impossible to lose money from such an investment and I wanted to try my hand out at mining. Luckily, I began mining just as temperatures began dropping in Canada and considering that I live in an apartment, it made sense to place my mining rig outdoors.
<img src="/assets/img/mining-rig/basic-diagram.PNG" alt="Enclosure diagram" style="float: right; width:50%; height:50%" />
Firstly, I constructed a relatively waterproof enclosure for the rig to protect it from rain and snow while it sits on my balcony. This enclosure uses three 120mm fans to pull cold air in at the bottom which naturally flows upwards and exits through the top of the enclosure. While this works well for colder temperatures, I have found that the lid of the enclosure must remain open for temperatures above ~ -10 C (lid is grey in the image above). Around -10 C and below, heat generated by the graphics cards is no longer enough to reliably maintain all the internals above 0 C and therefore I needed some way to cut off the influx of cold air when the internals got too cold.</p>

<h1 id="basic-idea">Basic Idea</h1>

<p>I know from experimentation that having the enclosure’s fans off results in incredibly hot temperatures so cutting off the fans should be enough to maintain the internals above 0 C. I purchased some cheap DHT11 temperature and humidity sensors off of AliExpress for another project a while ago so I will be using those for this application. To more accurately measure the temperature within the enclosure, three sensors will be used to measure the temperature at different points:</p>
<ul>
  <li>(1) will monitor a known hotspot behind two GPUs</li>
  <li>(2) will monitor the motherboard</li>
  <li>(3) will monitor the temperature at the emptier end of the rig given the lack of GPUs which results in lower temps
<strong>IMAGE</strong></li>
</ul>

<h2 id="logic">Logic</h2>

<p>I am not monitoring humidity since I want the microcontroller to prioritize temperature over humidity and Canada’s winters are traditionally dry. The microcontroller will average the temperature across all three DHTs and cut off fans whenever this average dips below 10 C. Furthermore, the fans will cut off if any sensor dips below 5 C; the thresholds are high because I do not trust the accuracy of my cheap AliExpress DHTs.</p>

<h2 id="build">Build</h2>

<p>I am using an ESP-12E, since that is what I have on hand, as well as a cheap 4-channel relay board in conjunction with the three DHT sensors. Connections are as follows:</p>
<ul>
  <li>Motherboard DHT –&gt; digital pin 5</li>
  <li>GPU DHT –&gt; digital pin 4</li>
  <li>PSU DHT –&gt; digital pin 0</li>
  <li>Fan relay –&gt; digital pin 16</li>
</ul>

<h2 id="code">Code</h2>

<p>The code can be found at https://github.com/Serpopovici163/miningRigTempCtrl and the ESP’s webpage: 
<img src="/assets/img/mining-rig/webpage.PNG" alt="Wepbage screenshot" />
The webpage automatcally refreshes every 30 seconds and I am currently displaying it on a Wink Relay in my living room seeing as that’s about the only thing a Wink Relay is good for nowadays. One note from the screenshot above is that the low temperature saved by the ESP is wrong: there seems to be some issue with at least one sensor causing it to briefly report a temperature of -21 Celsius but the enclosure never actually drops below 0 Celsius.</p>

<h1 id="update-dec-2021">UPDATE Dec 2021</h1>

<p>Everything works as intended! The rig manages its temperature accurately and has been up for 24/7 with this system installed.</p>]]></content><author><name>Alex Ludicrous</name></author><summary type="html"><![CDATA[A solution for outdoor mining rigs during winter]]></summary></entry><entry><title type="html">Two G-class Stage Rocket w/ Basic Telemetry</title><link href="http://localhost:4000/two-stage-rocket/" rel="alternate" type="text/html" title="Two G-class Stage Rocket w/ Basic Telemetry" /><published>2021-11-08T00:00:00-05:00</published><updated>2021-11-08T00:00:00-05:00</updated><id>http://localhost:4000/two-stage-rocket</id><content type="html" xml:base="http://localhost:4000/two-stage-rocket/"><![CDATA[<h2 id="experimenting-with-rocketry-electronics">Experimenting with rocketry electronics</h2>

<p>While I doubt I will ever get a high power rocketry license, I do thoroughly enjoy developing and flying model rockets. None of my past rockets have incorporated any amount of electronics so the purpose of this project is to get a feel for rocketry electronics without any risk by developing only non-terribly-flight-critical components. For this project, I purchased the two biggest rocket engines I can legally get my hands on without any license: AeroTech G80-7T motors.</p>

<h1 id="design">Design</h1>
<h2 id="motor-mounts">Motor mounts</h2>

<p>I watched a <a href="https://www.youtube.com/watch?v=4fhoCt9vXA8">video</a> by ProjectAir on YouTube about a rocket he built using similarly powerful motors and I based my rocket motor mounts on his design. The motor mounts consist of a small tube for the motor and a larger tube that fits snuggly into the rocket body. These two are connected by 8 perpendicular supports between the two cylindrical extrusions. The holes on the bottom of this motor mount also work to hold the first stage onto the main stage by using 8 pegs protruding from the first stage which fit snuggly into the 8 holes of the motor mount above.</p>

<h2 id="avionics">Avionics</h2>

<p>I intend to have live data logging and telemetry at the very least. This rocket will include a GPS, barometer, and accelerometer as well as an ignition system for the main stage engine. I would also like to include some system that can delay the deployment of the main chute since it will significantly increase the rocket’s drift during recovery however I’m unsure of how reliably I can integrate such a feature. All the electronics will be housed near/in the nose cone and the rocket will separate close to the main stage motor for recovery such that the body tube/nose cone section containing the electronics remains intact.</p>

<h1 id="update-jun-2022">UPDATE Jun 2022</h1>

<p><img src="/assets/img/habibi-express/avionicsFront.jpg" alt="Assembled avionics bay" style="float: right; width:30%; height:50%; margin-left: 10px;" />
The avionics bay has been assembled though it is missing a couple key elements. Firstly, there is no voltage regulator to step down the LiPo’s voltage for the Arduino and related electronics; furthermore, I need to integrate a relay so the Arduino can ignite the second stage motor once the initial one burns out. Finally, the antenna installed on the design right now can not be used and is solely there to ensure that I don’t accidentally burn the LoRa transceiver by powering it on without an antenna. Everything on the module at the moment is completely wired and ready to go. I have noted the I2C addresses of the MPU6050 and BMP280 and the wire with the white connector sticking out the top of the avionics bay goes to the GPS sensor in the nose cone of the aircraft.</p>

<p>The software for this design won’t be too involved as the arduino only needs to ignite the second stage 3 seconds after the MPU6050 detects a decrease in vertical acceleration all while broadcasting GPS, altitude, and attitude data at regular intervals. The main concern now is developing viable fins for the rocket body. I am hoping to have them laser-cut at the university but I have yet to inquire about using the equipment.</p>

<h1 id="update-mar-2022">UPDATE Mar 2022</h1>

<p><img src="/assets/img/habibi-express/avionics-CAD-V2-back.PNG" alt="Avionics bay V2 back" style="float: right; width:30%; height:50%; margin-left: 10px;" />
The avionics bay is mostly finalized and I will attempt to print this soon; I’ve done without the 18650 battery and kept the 3s LiPo which is now housed in a casing at the top of the avionics bay. The LoRa module is now positioned such that an antenna can be directly attached to the module and have space in the rocket fuselage. The only thing lacking from the model to the right is a relay holder to ignite the second stage. I still need to remodel the nose cone since the current GPS holder may not have clearance so it must be shifted upwards after which I will begin 3D printing these components and assembling the rocket!</p>

<h1 id="update-feb-2022">UPDATE Feb 2022</h1>

<p><img src="/assets/img/habibi-express/rocket-CAD.PNG" alt="Rocket model" style="float: right; width:50%; height:50%; margin-left: 10px;" />
CAD model is now mostly finished, lots of small things still need to be figured out however most of the grunt work is done. I don’t have a concrete plan for how to wire the main stage motor’s igniter in a way that won’t risk tangling the parachute during recovery. Furthermore, I purchased two G80-7T motors however the rocket will need at least 10 seconds after the main stage burns out to reach its apogee so I most likely need to source a G80-13T motor to avoid using any complex recovery mechanisms. Unfortunately, <a href="https://www.greathobbies.com/">Great Hobbies</a> does not carry G80 motors anymore so I can only source these for unreasonably high prices from <a href="https://www.allrockets.ca/G80-13">AllRockets</a>.</p>

<p><img src="/assets/img/habibi-express/avionics-CAD.PNG" alt="Avionics model" style="float: right; width:30%; height:50%; margin-left: 10px;" />
Main focus now is the avionics bay. The model pictured here has space for an Arduino Mega 2560 (embed), a BMP280, an MPU6050, a LoRa SX1278 transceiver, and two batteries. The nose cone contains a GPS antenna bracket for positioning as well. This is the second iteration of the avionics bay and it contains space for both an 18650 LiIon cell (in green) and a small 3S 700mAh LiPo next to the LiIon cell. I’m concerned that the ~3V from the 18650 will not be enough to ignite the main stage of the rocket even with a boost converter which is why I included the LiPo. I originally considered using the 18650 in light of its higher energy density however it only has roughly 1.5 times the energy stored by the LiPo so it will likely be discarded in the next iteration.</p>

<h1 id="update-dec-2021">UPDATE Dec 2021</h1>
<p>Rocket design was finalized in <a href="https://openrocket.info/">OpenRocket</a> and basic simulation was done; maximum altitude estimated at roughly 1.1km with a max speed of Mach 0.52. I made some faster designs and others with higher apogees but this model seems the most predictable based on how much tech I want to fly with the rocket and how lightly I can manufacture things.</p>

<p><img src="/assets/img/habibi-express/open-rocket-sim.PNG" alt="OpenRocket Model" />
<img src="/assets/img/habibi-express/open-rocket-sim-graph.PNG" alt="OpenRocket Simulation" /></p>]]></content><author><name>Alex Ludicrous</name></author><summary type="html"><![CDATA[Experimenting with rocketry electronics]]></summary></entry><entry><title type="html">LoRa Sensor Suite</title><link href="http://localhost:4000/lora-sensor-suite/" rel="alternate" type="text/html" title="LoRa Sensor Suite" /><published>2021-08-16T00:00:00-04:00</published><updated>2021-08-16T00:00:00-04:00</updated><id>http://localhost:4000/lora-sensor-suite</id><content type="html" xml:base="http://localhost:4000/lora-sensor-suite/"><![CDATA[<h2 id="a-scalable-dynamic-solution-for-monitoring-activity-in-unknown-environments">A scalable dynamic solution for monitoring activity in unknown environments</h2>

<p>At some point in 2021, a friend and I had just finished exploring a construction site and as we were preparing to leave on the first floor, a security guard haphazardly walked in. kLuckily we were out of sight and managed to get away undetected but this presented a need for a system capable of monitoring activity within an uncontrolled environment. So far I have only build PIR sensors for this purpose though I intend to build tripwires and possibly audio sensors.</p>

<h1 id="basic-idea">Basic Idea</h1>

<p>Each sensor runs off of an 18650 Li-Ion cell with a battery protection circuit that enables USB charging and maintains the cell voltage within its acceptable range. Each sensor has an Arduino Nano with a LoRa SX1278 transceiver in addition to its sensing equipment. LoRa modules are ideal since they act as a mesh network and these sensors are intended for use within concrete buildings thus signals will have difficulty travelling far. An additional LoRa module with a high gain antenna connects the LoRa mesh network to the attacker’s phone or some other notification method. Due to the RF challenges faced by these sensors, they should transmit repeteadly once triggered until the attacker’s device is able to acknowledge the signal. Based on experimentation, the LoRa modules I own do not natively do this.</p>

<h1 id="update-feb-2022">UPDATE Feb 2022</h1>

<p><img src="/assets/img/lora-sensor-suite/PIR-V2-front.PNG" alt="Front" style="float: right; width:50%; height:50%" />
I’ve decided to migrate from an Arduino to an ESP32 module; this CAD design has space for an ESP32-WROVER module. The reasoning behind this change is that an ESP32 module can be used to pick up bluetooth devices nearby which would allow the attacker to configure the device with their cell phone 
<img src="/assets/img/lora-sensor-suite/PIR-V2-back.PNG" alt="Back" style="float: right; width:50%; height:50%" /> 
and can be used to pick up unknown devices and send alerts even if the sensor itself fails to trip.</p>

<p>The current design does not have space for a battery management circuit so I will need to reiterate but it does successfully house the LoRa SX1278, 18650, and PIR sensor. The general shape of the sensor allows for it to be placed on the floor with the PIR facing 45 degrees upwards or it can be flipped and placed on top of a cabinet, for example, with the PIR facing 45 degrees downwards. The next iteration will likely also include magnets such that the sensor can attach to metallic cabinets, metal hand rails on stairs, light fixtures, etc. I also took apart one of the 433 antennas and noticed that at least 10mm of the rubber housing is left empty so I will take this in account and ommit the rubber housing in future designs.</p>

<h1 id="update-oct-2021">UPDATE Oct 2021</h1>

<h2 id="sensor-construction">Sensor Construction</h2>

<p><img src="/assets/img/lora-sensor-suite/PIR-V1-front.png" alt="Front" style="float: right; width:50%; height:50%" />
Pins 0 and 1 of the Arduino are used for serial communication with the LoRa module (the RX pin of the LoRa module must be disconnected when code is uploaded to Arduino). Pin A0 is for the pair button and other pins are used as required for the relevant sensor. 
<img src="/assets/img/lora-sensor-suite/PIR-V1-back.png" alt="Back" style="float: right; width:50%; height:50%" /> 
Pins M0 and M1 on the module are shorted to ground in order for the module to transmit. The whole assembly is zip tied together in a rather minimalistic form factor but a bit of paint is needed to cover the green and blue circuit boards.</p>

<h2 id="communication-protocol">Communication Protocol</h2>

<p>Each sensor broadcasts an ‘alive’ packet once the pair button has been pressed; this packet contains a unique ID based on the microcontroller’s serial number to differentiate its ‘alive’ packet from that of other sensors. Alive packets are repeated up until the sensor receives an acknowledgment packet from the head unit in which the head unit will assign a numerical value to the sensor between 0 and 9998. The user is then able to assign a more descriptive identifying string to the sensor so that its location can be more apparent. Upon being triggered, the sensor will begin boardcasting a packed in the form of “SENSOR_ID:PACKET_ID:TRIG_VAL” where</p>
<ul>
  <li>PACKET_ID is a unique integer identifying the packet to ensure the head unit doesn’t register the same alert twice</li>
  <li>TRIG_VAL is an integer representative of the sensor’s states</li>
</ul>

<p>This packet is repeated every 0.5 seconds up until the sensor receives a packet from the head unit in the form of “9999;SENSOR_ID;PACKET_ID” where</p>
<ul>
  <li>9999 is the equivalent SENSOR_ID for the head unit</li>
  <li>SENSOR_ID is the id of whichever sensor tripped</li>
  <li>PACKET_ID is the packet id</li>
</ul>]]></content><author><name>Alex Ludicrous</name></author><summary type="html"><![CDATA[A scalable dynamic solution for monitoring activity in unknown environments]]></summary></entry><entry><title type="html">Annota Application</title><link href="http://localhost:4000/annota-mobile-application/" rel="alternate" type="text/html" title="Annota Application" /><published>2021-07-20T00:00:00-04:00</published><updated>2021-07-20T00:00:00-04:00</updated><id>http://localhost:4000/annota-mobile-application</id><content type="html" xml:base="http://localhost:4000/annota-mobile-application/"><![CDATA[<h2 id="my-first-android-application">My first android application</h2>

<p>Annota is my first ever attempt at developing software for Android devices. As part of a second year course, we were challenged to develop an application that could digitize a user’s notes in order to categorize and index them. This application is far from exemplar for a variety of reasons however I had a tremendous level of success considering I knew very little about Java and Android development prior to this project. This was a group project so the work was done in conjunction with three other students though I got away with doing the coding work while the others focused on testing the application and taking care of written deliverables.</p>

<h1 id="clients-needs">Client’s Needs</h1>

<p>The client for this product suffers from Multiple Sclerosis (MS), an auto-immune disase impacting the central nervous, which causes her to suffer from short-term memory loss and fatigue. Since there is no known cure for MS as of this writing, available treatments focus on mitigating the impact of symptoms in patients. For our client, this entails developing an application which can digitize and index important information and provide them with time-based and potentially location-based reminders. Based on a couple interviews, the following needs were identified for the project:</p>

<table>
  <thead>
    <tr>
      <th>Customer Need</th>
      <th>Design Criteria</th>
      <th>Importance</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>A product for everybody</td>
      <td>Must be accessible and usable by everyone.</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Ideally a virtual ‘cork board’</td>
      <td>Must be able to capture and organize text and images with possible support for other medias such as video</td>
      <td>2</td>
    </tr>
    <tr>
      <td>Needs notifications</td>
      <td>Should have reminder function</td>
      <td>3</td>
    </tr>
    <tr>
      <td>Red and green need to be avoided</td>
      <td>Accessibilty-focused UI</td>
      <td>4</td>
    </tr>
    <tr>
      <td>Automate organization</td>
      <td>Enable easy transfer of handwritten text to digital form</td>
      <td>5</td>
    </tr>
    <tr>
      <td>English as primary language</td>
      <td>Multiple language option with English as primary</td>
      <td>6</td>
    </tr>
    <tr>
      <td>Compatible with many devices</td>
      <td>Should support multiple platforms</td>
      <td>7</td>
    </tr>
    <tr>
      <td>Copy annotations from textbook</td>
      <td>Read, annotate, and categorize selective parts of written content</td>
      <td>8</td>
    </tr>
    <tr>
      <td>Zoom in and out of documents</td>
      <td>Integrate an image viewer interface</td>
      <td>9</td>
    </tr>
    <tr>
      <td>Make it aesthetic</td>
      <td>Visual appeal and stimulate user</td>
      <td>10</td>
    </tr>
  </tbody>
</table>]]></content><author><name>Alex Ludicrous</name></author><summary type="html"><![CDATA[My first android application]]></summary></entry></feed>