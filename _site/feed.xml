<<<<<<< Updated upstream
<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-10-12T00:09:12-04:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Ludicrous Tech</title><subtitle>This website keeps track of whichever projects I am most proud of and serves to share some of the knowledge I accumulate from tinkering on whatever comes to my mind. Enjoy!</subtitle><author><name>Alex Ludicrous</name></author><entry><title type="html">Roof Anchor Drone</title><link href="http://localhost:4000/roof-anchor-drone/" rel="alternate" type="text/html" title="Roof Anchor Drone" /><published>2022-08-02T00:00:00-04:00</published><updated>2022-08-02T00:00:00-04:00</updated><id>http://localhost:4000/roof-anchor-drone</id><content type="html" xml:base="http://localhost:4000/roof-anchor-drone/"><![CDATA[<h2 id="a-physical-infiltration-tool">A physical infiltration tool</h2>
=======
<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-10-15T18:19:03-04:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Ludicrous Tech</title><subtitle>This website keeps track of whichever projects I am most proud of and serves to share some of the knowledge I accumulate from tinkering on whatever comes to my mind. Enjoy!</subtitle><author><name>Alex Ludicrous</name></author><entry><title type="html">Roof Anchor Drone</title><link href="http://localhost:4000/roof-anchor-drone/" rel="alternate" type="text/html" title="Roof Anchor Drone" /><published>2022-08-02T00:00:00-04:00</published><updated>2022-08-02T00:00:00-04:00</updated><id>http://localhost:4000/roof-anchor-drone</id><content type="html" xml:base="http://localhost:4000/roof-anchor-drone/"><![CDATA[<h2 id="a-physical-infiltration-tool">A physical infiltration tool</h2>
>>>>>>> Stashed changes

<p>This device was originally designed in hopes of rooftopping the second tallest building in Canada at the time of this writing: The St. Regis hotel in Toronto. The concern was that the lower roof at the St. Regis hotel is accessible while the higher roof is roughly 3 storeys taller and unnaccessible through conventional ways. In the end, there was an easier way of reach the top and the drone was not used however it remains a genuinely useful tool for ascending moderately tall structures with no internal access.</p>

<h1 id="general-premise">General premise</h1>

<p>The goal is to build a 3D-printable assembly that attaches to the bottom of a drone and holds a carbiner in an open position which can then be remotely shut. The drone must be small enough to be easily portable and nimble while the carabiner assembly must be able to support a moderate amount of weight as a rope will be carried attached to the carabiner. In cases where the distance to be ascended is too large for the drone to reasonably carry the required length of rope, a thinner and lighter ‘tag line’ can be passed through the carabiner and used to pull the climbing rope up once the carabiner is hooked onto an anchor. Finally, a camera must be integrated on the drone to provide the operator visual feedback to line up the carabiner with the target roof anchor.</p>

<h1 id="build">BUILD</h1>

<p>The initial design for this project was a singular 3D printed piece that mounts to a DJI F450 frame since I had a few of these lying around. While this design is functional, the large propeller diameter negatively impacts the drone’s agility and the drone’s size make it a poor solution in terms of portability. [PICS] For these reasons, a new design was created using a 215mm race drone frame. The new design (depicted) is much more portable and breaks down into two pieces such that it can be more reasonably stored in a small volume. 
<img src="/assets/img/roof-anchor-drone/CAD_assembly_view.PNG" alt="CAD view" />
Here the green component houses the flight controller, ESCs, battery, and radio gear whereas the purple component is the carabiner holder.</p>

<h2 id="carabiner-mechanism">Carabiner mechanism</h2>

<p>In addition to its modularity, the final design has two servos on the carabiner holder component: the first (1) retains a rubber band which is wrapped around the holder to keep the latch open while the second (2) supports the weight of the rope being carried by the carabiner.</p>]]></content><author><name>Alex Ludicrous</name></author><summary type="html"><![CDATA[A physical infiltration tool]]></summary></entry><entry><title type="html">Modernizing my 2013 Subaru BRZ</title><link href="http://localhost:4000/brz/" rel="alternate" type="text/html" title="Modernizing my 2013 Subaru BRZ" /><published>2022-06-01T00:00:00-04:00</published><updated>2022-06-01T00:00:00-04:00</updated><id>http://localhost:4000/brz</id><content type="html" xml:base="http://localhost:4000/brz/"><![CDATA[<p>I recently acquired a car for recreational purposes since I had saved up a decent amount of money and didn’t feel like investing it. I purchased a BRZ because they are built in conjunction with Toyota and this should theoretically imply that they are relatively reliable so I won’t need to worry about the mechanical aspect of the vehicle. Furthermore, this collaboration with Toyota also makes them relatively easy to work on at home which I am thankful for since I’ve had to do a wealth of maintenance on it.</p>

<h1 id="idea">Idea</h1>

<h2 id="ui-enhancements">UI Enhancements</h2>

<p><img src="/assets/img/brz/planned_display_layout.jpg" alt="Picture of plan" style="float: right; width:50%; height:80%; margin-left: 10px;" /></p>

<p>The plan is to replace the head unit of the BRZ with a <a href="https://www.aliexpress.com/item/1005003546521274.html">12.3” touch-screen</a>, replace the small button cluster on the center console with a <a href="https://www.aliexpress.com/item/4000393713339.html">7” touch screen</a>, convert the analog gauge cluster to a display, and potentially add a heads up display in the windshield. The 12.3” display will be used for most vehicle functionality such as navigation and media whereas the 7” display will provide diagnostic information about the vehicle as well as any subsystems I add. Ideally, the computer running the 7” display will have access to the car’s internal computer to provide any information from DTC/SRS/ABS codes to general information about things like tire pressure.</p>

<p>The car will have an LTE modem in it to provide WiFi connectivity for passengers and allow its internal computers to access Google Maps, media streaming services, and other resources such as the Waze database to protect against police encounters. Finally, I hope to add cameras all around the car and experiment with computer vision though, aside from collision warnings and enhanced cruise control I’m not sure what I’ll be able to develop. The cameras will however provide a 360-degree dash cam and I will be able to use them for a Tesla-like sentry mode when the car is locked.</p>

<h2 id="speed-enforcement-countermeasures">Speed Enforcement Countermeasures</h2>

<p>I’m hoping to, at the very least, add passive sensors for police radar/lidar and possibly even aircraft but I may not be able to add active countermeasures such as radar/lidar jamming. Based on some brief research, there is a significant risk that the officer’s radar/lidar gun would detect my jamming attempts since many of them have jamming detection built in and proper commercial lidar jammers are designed to identify the specific make/model of a lidar gun and behave accordingly.</p>

<p>Aircraft countermeasures are more reasonably achieveable since aircraft speed detection works using lines painted on the pavement at a known distance interval such that an aircraft flying above can time a vehicle crossing a set of these lines. My plan for countering this is to use a front facing camera on the car to pick up the lines at which point an onboard computer will use a software defined radio to look for any aircraft transponders within a certain radius of the vehicle. Should there be an aircraft nearby, the onboard computer will begin calling out speeds for the user to match in hopes that the average speed across the two lines does not exceed the posted limit.</p>

<p>An even more complex countermeasure I’m hoping to integrate is cellular sniffing where a computer would once again use a software defined radio to look for nearby cellular devices and fingerprint them to single out the specific make and model of cellular modem present in a Ford Interceptor. I’m unsure if this is even theoretically possible since newer cellular devices may encrypt everything but I intend to research this in depth.</p>

<p>In addition to passive countermeasures and radar/lidar jammers, the vehicle will hopefully have cellular and VHF/UHF jammers. The purpose of these is to prevent a Ford Interceptor’s cellular modem and radio from working when in close proximity to the vehicle. This way the officer will not be able to run the driver’s license or even issue tickets and this could delay a call for backup during a police chase.</p>

<h1 id="build">Build</h1>

<h2 id="design-considerations">Design considerations</h2>

<p>I initially intended to build a custom image of Android Automotive for the BRZ and develop mobile applications that would mostly run as backgroud services and overlay themselves on top of Android to display relevant information. Unfortunately this turned out to be a rather lucrative task and as of this writing I have elected to build a simple Android application running on a mobile image. The advantages of Android Automotive are as follows:</p>
<ul>
  <li>Better navigation with fully functional Google Maps (I am using the Khadas VIM4 for the head unit and it does not support Google Play Services so it cannot have any Google Maps functionality)</li>
  <li>Better media controls with proper Bluetooth integration (As far as I am aware, Android Mobile cannot be used as a A2DP sink without modifying the source code)</li>
  <li>Better boot times</li>
</ul>

<p>Overall, I did not feel these advantages were enough to justify the increased complexity of building a custom Android Automotive image especially considering how many custom UI screens and functions I intend to incorporate.</p>

<p>The purpose of rebuilding the vehicle’s UI is not only to provide a seamless means of interacting with additional functionality but also to fully hide any illegal functions on demand. As such, there must not be any visible hint of any countermeasure functionality on the inside and outside of the vehicle and as such the car is able to hide illegal functionality when in ‘legal mode’ which can be enabled using arbitrary key strokes or combinations. Once in legal mode, the user is able to unlock hidden functions by entering an arbitrary set of seemingly random keystrokes using buttons throughout the car’s interior. The combination is such that it would be incredibly difficult to guess or mistakenly enter it.</p>

<h2 id="hardware">Hardware</h2>

<h3 id="computers">Computers</h3>

<p>The car will contain a multitude of computers listed below alongside their purpose:</p>
<ul>
  <li>Head Unit/Center Console (Khadas VIM4) –&gt; Mostly displays data and video feeds, very little logic goes on here</li>
  <li>CANBUS server (Arduino) –&gt; Acts as interface between ethernet network and vehicle’s CANBUS</li>
  <li>Gauge cluster computer (RPi Zero?) –&gt; Listens to CANBUS and ethernet network to display data, may link this as a second display for the Khadas VIM4</li>
  <li>Safety computer (nVidia Jetson NX?) –&gt; Uses CV algorithms on vehicle cameras and exports HDMI feeds of cameras for head unit</li>
</ul>

<p>Most of the hardware modifications are exectued by Arduinos integrated throughout the vehicle that share its CANBUS. The list of integrated Arduinos as well as the model used is as follows:</p>
<ul>
  <li>Head light manager (MEGA_EMBED) –&gt; Used for light animations up front, has relays to control lights and voltage dividers to light input from car’s computer as well as addressable LEDs integrated in the grill.</li>
  <li>Rear light manager (MEGA_EMBED) –&gt; Same idea but for rear lights. This Arduino also flashes the rear lights of the vehicle based on CANBUS data of vehicle speed and brake pressure (the required brake pressure for a flash differs based on vehicle speed)</li>
  <li>Mirror manager (NANO) –&gt; Keeps track of mirror position and allows them to automatically tilt when backing up. One per mirror.</li>
  <li>Diagnostic display button manager (NANO) –&gt; Controls relays that simulate button presses to maintain functionality of old center console buttons.</li>
  <li>Steering wheel button manager (PRO MICRO) –&gt; Converts steering wheel button presses into USB keyboard data for head unit computer and sends keystrokes to CANBUS of car</li>
  <li>Power managers (MEGA_EMBED) –&gt; Handles power delivery to components using large relay boards to provide active failover functionality and monitor current/voltage among vehicle power buses. Two of these will be installed: one in front near the head unit and one in the trunk.</li>
  <li>Audio manager (MEGA_EMBED) –&gt; Handles audio amplifier settings (equalizer and volume) and simulates keystrokes on a Bluetooth dongle used to receive mobile audio. Since the head unit computer can’t be used as a A2DP sink, I am using a standalone Bluetooth dongle to receive mobile audio. This allows me to control the music from the head unit however I won’t be able to keep track of the song’s progress or display the album cover.</li>
  <li>Controller (Arduino but idk) –&gt; Doesn’t really matter so long as it has an ethernet shield or other interface. Will store any CANBUS values used by the other computers in a local database that updates anytime new data becomes available on the CANBUS.</li>
</ul>

<h3 id="cameras">Cameras</h3>

<p>The planned camera layout is included below. The green semicircles are <a href="https://www.aliexpress.com/item/1005004337827464.html">136-degree FOV cameras</a> installed in the front windshield and above the rear license plate whereas the grey circles represent <a href="https://www.aliexpress.com/item/1005004335144138.html">210-degree cameras</a> (the listing says 180 degrees but they are actually 210) installed beneath side view mirrors of the car. A fifth camera is installed inside the vehicle and faces the driver for eye tracking such that the touch screen functionality of the center console display is disabled unless the driver is looking at the display to prevent accidental inputs. I planned on including a second front-facing camera on the right wing mirror to provide the driver with insight about any vehicles in the right lane ahead of the car that they may not be able to see. This camera is not included at this time since the 210-degree FOV camera installed beneath the right side mirror should theoretically capture any vehicles in the right lane though distortion may severely impact the resolution and thus the viability of using it.</p>

<p><img src="/assets/img/brz/camera_layout.png" alt="Camera layout" /></p>

<h3 id="steering-wheel-button-integration">Steering Wheel Button Integration</h3>

<p>Steering wheel buttons were added to BRZs in 2017 and mine is a 2013 so I purchased a salvage steering wheel in order to integrate its buttons into my systems. Should anybody else contemplate to do the same, be aware that even though steering wheels are cheap the airbag most certainly is not: a brand new OEM airbag for my car is $CAD 1100 from the dealer while a used one is ~$CAD 600.</p>

<p>The steering wheel uses a Arduino Pro Micro to convert button presses into keyboard output for the Khadas VIM4 to understand. Furthermore, it connects to the CANBUS to foward hardware-related commands to decrease latency as opposed to transferring commands from the VIM4 to other devices. In order to interface the Arduino with the steering wheel, I took apart the button clusters on each side of the 
<img src="/assets/img/brz/steering_wheel_button_connector.jpg" alt="Steering wheel button connector" style="float: right; width:50%; height:80%; margin-left: 10px;" />
steering wheel and followed traces to figure out the function of each wire. My findings are listed below for anybody else intending to reverse engineer the steering wheel buttons on a BRZ (wires are listed from left to right, top to bottom, looking at the connector from behind as depicted to the right):</p>
<ul>
  <li>Light green –&gt; Volume and arrow keys of left side cluster</li>
  <li>Red –&gt; Common of left side cluster</li>
  <li>Green –&gt; Arrow keys of right side cluster</li>
  <li>Purple –&gt; Enter and back key of right side cluster</li>
  <li>Yellow –&gt; Common of right side cluster</li>
  <li>Black –&gt; Call buttons, source button, left enter button, and voice button</li>
  <li>Blue –&gt; Steering wheel ground</li>
  <li>Brown –&gt; Cruise control pin 1</li>
  <li>Grey –&gt; Cruise control pin 2</li>
  <li>Black + White –&gt; LED ground</li>
  <li>White –&gt; LED VCC (5V works but dim. Not sure I’m willing to go higher so I’ll suck it up)</li>
</ul>

<p>The ‘voice’ button on the right side of the steering wheel is wired to the left button cluster and its state is transmitted through the (light green or black) wire. Button states are transmitted by varying the resistance between the common pin of each button cluster and one of the two output pins of each button cluster. The Arduino interprets these using an analog pin using the INPUT_PULLUP pin mode with the common pins being connected to ground. The resulting resistance and output wire for any button press is listed below in hopes of saving someone else the effort required to decode these circuit boards though I ended up using analogRead values so these were useless to me.</p>

<table>
  <thead>
    <tr>
      <th>Left Side Cluster</th>
      <th>Right Side Cluster</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Source –&gt; 115 Ohm BLACK</td>
      <td>Up –&gt; 330 Ohm GREEN</td>
    </tr>
    <tr>
      <td>Call pickup –&gt; 425 Ohm BLACK</td>
      <td>Right –&gt; 3.1 kOhm GREEN</td>
    </tr>
    <tr>
      <td>Call hangup –&gt; 225 Ohm BLACK</td>
      <td>Down –&gt; 1 kOhm GREEN</td>
    </tr>
    <tr>
      <td>Volume up –&gt; short LIGHT GREEN</td>
      <td>Left –&gt; short GREEN</td>
    </tr>
    <tr>
      <td>Volume down –&gt; 50 Ohm LIGHT GREEN</td>
      <td>Enter –&gt; 100 kOhm PURPLE</td>
    </tr>
    <tr>
      <td>Right –&gt; 115 Ohm LIGHT GREEN</td>
      <td>Back –&gt; 101 kOhm PURPLE</td>
    </tr>
    <tr>
      <td>Left –&gt; 245 Ohm LIGHT GREEN</td>
      <td>Voice –&gt; 50 Ohm BLACK</td>
    </tr>
    <tr>
      <td>Enter –&gt; short BLACK</td>
      <td> </td>
    </tr>
  </tbody>
</table>

<h3 id="lighting-modifications">Lighting Modifications</h3>

<p>Some of the modifications require extensive control of the vehicle’s lights however I am not willing to alter anything about the car’s computers so my solution consists of relays placed along the wiring harnesses controlling the vehicle’s lights with two separate computers on each end of the car. Each computer has a combination of mechanical and solid state relays depending on how frequent a light is expected to toggle on/off. Mechanical relays are used for lights that rarely toggle and because they provide a normally closed and normally open set of contacts. This is important because the lighting computers receive constant power regardless of the vehicle’s state and therefore power draw must be minimized when the vehicle is not running.</p>

<p><img src="/assets/img/brz/rear_light_manager.jpg" alt="Rear light manager computer" style="float: right; width:50%; height:80%; margin-left: 10px;" /> The rear lighting computer is pictured to the right and I expect the front computer to be highly similar. It uses four solid state relays (top left) to drive the brake lights and turn signals of the car by connecting them to the car’s battery. The third and fourth brake light of the car (third is in the windshield and fourth is F1 style in bumper) are converted to addressable LEDs and do not require relays. Addressable LEDs have also been integrated into the reverse lights (two lights adjoined to the fourth brake light) and the two rear quarter panel windows of the car. Excluding the solid state relays, the computer contains two mechanical relays (bottom left) for running lights, a CANBUS module (bottom right), an Arduino (top right), and a 5V regulator on the backside. Currently, this computer turns lights on based on whether or not live data is being sent across the CANBUS since it is always powered and I have not yet figured out what value represents the stte of the vehicle’s running lights. This is not ideal since a side effect of my current solution is that running lights turn on when doors open or the car is unlocked etc.</p>

<h3 id="cad">CAD</h3>

<p>The retrofit brackets for this vehicle were designed by first measuring and modelling the mount points to the vehicle before extruding a general shape to house all the required components. The components are then arranged on the aforementioned general shape such that their screw holes/mount points can be cut after which the bulk of the material is removed leaving a barebones structure which can be further broken down into smaller pieces to facilitate manufacturing.</p>

<p>The head unit bracket is a perfect example of this technique. The design was built symmetrically, and as such, I began by modelling the left side before mirroring it to generate the entire assembly. I knew I would need two ‘platforms’ to house all the required components so I began by measuring the mount hole positions from the old head unit and generating two basic mount ‘ears’ before extruding an arbitrary platform attached to each ear. The platforms were extended an arbitrary amount in both directions based on how much space I estimated to be available inside the vehicle’s cavity and how far the head unit display would be mounted. The head unit bracket holds the following hardware as can be seen in the <em>PIC</em> to the right:</p>

<ol>
  <li>Head unit display</li>
  <li>Head unit display driver</li>
  <li>Khadas VIM4</li>
  <li>Voltage regulator</li>
  <li>Driver-facing camera</li>
</ol>

<p>No amp needed up front since it’s in the trunk from factory. That being said it only drives the front speakers and I can’t figure out how the rear side speakers are powered so there may be more amplifiers throughout the vehicle. I also need to include an amplifier for the siren up front which may end up in the head unit if there is space.</p>

<h2 id="visual-user-interface">Visual User Interface</h2>

<h3 id="head-unit-display">Head Unit Display</h3>

<p>The large head unit display is split horizontally into two sections: a ‘big container’ which is 2/3 of the display’s width and a ‘small container’ which occupies the remaining space. The views displayed by the big container and their respective purpose are as follows:</p>
<ul>
  <li>Navigation fragment –&gt; Contains an interactive map that the user</li>
  <li>Lighting control fragment –&gt; Handles interior accent colours and vehicle underlighting (legal light functions)</li>
  <li>Safety fragment –&gt; Displays live view of cameras around the car as well as any computer vision-related safety warnings</li>
  <li>Settings fragment –&gt; Allows user to modify settings of any subsystem</li>
  <li>Defence fragment –&gt; Compliments defence fragment in small container, displays advanced countermeasures</li>
</ul>

<p>The views displayed by the small container and their respective purpose are as follows:</p>
<ul>
  <li>Media fragment –&gt; Handles media playback controls</li>
  <li>Diagnostic fragment –&gt; Mirror of center console display, describes states of vehicle systems</li>
  <li>Soundboard fragment –&gt; Enables playback of custom sounds through a loudspeaker in front of vehicle</li>
  <li>Pop-up defence fragment –&gt; Brief rundown of coutermeasure states, this fragment is automatically overlayed when vehicle detects radar/lidar etc.</li>
  <li>Traffic advisor fragment –&gt; Allows user to control illegal light patterns of vehicle including police and hazard strobes</li>
</ul>

<p>In addition to the two primary fragment containers, a few fragments can be overlayed on top of the whole display in specific circumstances:</p>
<ul>
  <li>Parking fragment –&gt; Overlayed when vehicle is put into reverse by driver and persists until vehicle speeds up regardless of which gear the vehicle is in. This fragment provides data from parking sensors and cameras around vehicle to facilitate parking.</li>
  <li>Merging fragment –&gt; Pops up when merging right, provides live view of traffic in right lane so driver can see all vehicles in adjacent lane and blindspot.</li>
</ul>

<h3 id="diagnostic-display">Diagnostic Display</h3>

<p>This display provides the same view as the diagnostic fragment from the head unit display however there are also be four buttons underneath this view to replace the physical buttons that used to be in the center console. Furthermore, this display is capable of opening in depth sub-system diagnostic dialogs and clear error codes as well as execute diagnostic actions whereas the head unit fragment solely provides status information. This display runs off the same computer as the head unit since it has shared views and processes similar data (TRUE?).</p>

<p>The touch screen functionality of this display is toggled on demand using an interior-facing camera installed next to the 12.3” head unit display to track the driver’s eyes. As such, all touch screen functionality aside from the passenger seat warmer button will not function unless the driver is looking down towards the display.</p>

<h3 id="gauge-cluster-display">Gauge Cluster Display</h3>

<p>Listens to car’s CANBUS and displays the same information as was available with original gauge cluster though it also adds data for range and displays alerts from vehicle systems. (TRUE?) Furthermore, can be used to display night vision camera in front of vehicle to drive in less than optimal lighting conditions.</p>

<h3 id="heads-up-display">Heads Up Display</h3>

<p>Might scrap this but would display basic vehicle information.</p>

<h2 id="interactive-user-interface">Interactive User Interface</h2>

<p>The head unit and diagnostic displays have touchscreen functionality however the head unit display can also be controlled using steering wheel buttons for a hands free experience. The diagnostic display can only be used as a touch screen however the touch screen is disabled if the driver is not looking at the display in order to prevent misinput when shifting.</p>

<p>The right side steering wheel buttons are used to control the contents of the big container while the left side steering wheel buttons are used for the small container’s contents. Additionally, there are dedicated buttons or combinations thereof that can always be used to toggle critical functions such as the vehicle’s legal mode regardless of what content is live at the time.</p>]]></content><author><name>Alex Ludicrous</name></author><summary type="html"><![CDATA[I recently acquired a car for recreational purposes since I had saved up a decent amount of money and didn’t feel like investing it. I purchased a BRZ because they are built in conjunction with Toyota and this should theoretically imply that they are relatively reliable so I won’t need to worry about the mechanical aspect of the vehicle. Furthermore, this collaboration with Toyota also makes them relatively easy to work on at home which I am thankful for since I’ve had to do a wealth of maintenance on it.]]></summary></entry><entry><title type="html">Security Camera Privacy Hack</title><link href="http://localhost:4000/camera-privacy-hack/" rel="alternate" type="text/html" title="Security Camera Privacy Hack" /><published>2022-05-07T00:00:00-04:00</published><updated>2022-05-07T00:00:00-04:00</updated><id>http://localhost:4000/camera-privacy-hack</id><content type="html" xml:base="http://localhost:4000/camera-privacy-hack/"><![CDATA[<h2 id="enhancing-privacy-of-cheap-security-cameras">Enhancing privacy of cheap security cameras</h2>
<h1 id="get-picture-of-whole-camera-to-put-here-as-well">get picture of whole camera to put here as well</h1>

<p>I’ve always been a little paranoid of having having IoT devices live streaming views of my living space however I have a long trip coming up so a couple security cameras would be nice to keep an eye on my place. I considered a couple ways of modifying the cameras to provide more privacy:</p>
<ul>
  <li>A Python script that forges HTTP requests and orders the camera to turn around;</li>
  <li>A physical shutter external to the camera that blocks the lens; and</li>
  <li>An internal relay that cuts power to the camera module.
Unfortunately these were not ideal. The first idea was unreliable because turning the camera through a script still allows the camera to turn itself back on its own and may not be reliable should a software update be pushed that depreciates my integration of the camera’s API. The second was not an elegant solution and would be difficult to integrate on a PTZ camera that moves around. Finally, the third did not work because the camera would not come back online after the camera module got disconnected from its motherboard, no matter what I tried. In the end I settled on modifying the camera’s internal IR-CUT filter by covering the IR-CUT part with a sticker and integrating a microcontroller to toggle the state of the filter assembly. This was an elegant and invisible solution that should not noticeably affect image quality since the camera is being used indoors so there should be very little ambient IR light.</li>
</ul>

<p>The privacy mode of these cameras is toggled using a Python service running on a Linux server I have. The script regularly monitors what devices are connected to the local WiFI network, and once a known device is connected, the Python service blinds any security cameras within the apartment.</p>

<h1 id="hardware">Hardware</h1>

<p>While understandably not the most secure way to go about this, I used a few NodeMCU 1.0 modules I had laying around for this project. A more ideal solution would be to either use separate transceivers to air-gap the privacy microcontrollers from the internet or to use a WiFi/bluetooth capable microcontroller that can sniff and determine what devices are around it. Regardless, the hardware here is relatively simple, the camera has:</p>
<ul>
  <li>A ESP-12E module;</li>
  <li>A WS2812B LED; and</li>
  <li>A MX1508 H-bridge IC.
The MX1508 was needed since the ESP operates at 3.3V however the IR-CUT filter mechanism requires a higher voltage to actuate. The LED provides a hardcoded correlation between the state of the IR-CUT filter and a visual indication of whether or not the camera is able to see anything.</li>
</ul>

<h1 id="code">Code</h1>]]></content><author><name>Alex Ludicrous</name></author><summary type="html"><![CDATA[Enhancing privacy of cheap security cameras get picture of whole camera to put here as well]]></summary></entry><entry><title type="html">Smart Holographic Sight</title><link href="http://localhost:4000/smart-sight/" rel="alternate" type="text/html" title="Smart Holographic Sight" /><published>2022-02-25T00:00:00-05:00</published><updated>2022-02-25T00:00:00-05:00</updated><id>http://localhost:4000/smart-sight</id><content type="html" xml:base="http://localhost:4000/smart-sight/"><![CDATA[<h2 id="intelligent-weapon-optics">Intelligent weapon optics</h2>

<p>My overarching goal with a lot of the things I build is to develop a small ecosystem of tactically useful devices that can exchange information and provide the user with an advantage over their adversary. These devices include anything from motorized ascenders to augmented reality devices and UAVs. The SmartSight may work in conjunction with a motorized ascender such that the user can maintain the optic at eye level while also being able to control their ascender. This would provide the ability to keep a weapon tracked on a target while moving up or down the side of a building, for example. The SmartSight idea came about as I saw an old project by a <a href="https://andymeng.dev/">friend</a> of mine and decided to elaborate on it.</p>

<h1 id="basic-premise">Basic Premise</h1>

<p>The SmartSight contains a small display which reflects through a mirrored lens that allows the user to see both the display and the real world, just like a traditional holographic sight. I’m not too sure how much information I will present on the display; so far I intend to display a shot counter and a reticle which can adjust based on weapon cant. Furthermore, I will add indicators that describe the motorized ascender’s state and possibly a rangefinder at the very least. I only intend to use this on airsoft rifles so the rangefinder doesn’t need to be excessively good.</p>

<h1 id="update-jun-2022">UPDATE Jun 2022</h1>
<p>I have been working on this on and off for a while now without updating this page.
<img src="/assets/img/smart-sight/frontV2.PNG" alt="FrontV2" style="float: right; width:50%; height:50%; margin-left: 10px;" />
 I received the new 1.3” displays about a month ago and have generated a new CAD model which accomodates the larger display. The new display covers the majority of the space available on the lens and a shroud was included in this design to ensure that the optic remains viable even when exposed to sunlight. The previous design would likely have suffered in bright environments given how weak the displays are. Below is an updated exploded view of the new design:
<img src="/assets/img/smart-sight/explodedV2.PNG" alt="Exploded View V2" style="display: block; margin-left: auto; margin-right: auto; margin-top: 10px" /></p>

<p>A couple iterations of this design have been printed and all that is left at the moment is to wire up the final version and develop software. Since this design uses an Arduino Nano with its USB port exposed at the back, iterating software should be a piece of cake which can’t be said for the <a href="/lora-sensor-suite/">LoRa Sensor Project</a>.</p>

<h1 id="update-mar-2022">UPDATE Mar 2022</h1>

<p>The last version used a 0.96” 80x160 <a href="https://www.aliexpress.com/item/1005003514645335.html">ST7735S display</a> which has great pixel density but does not manage to cover the whole lens that it’s being reflected through. To rectify the issue, I recently purchased a 1.3” 240x240 <a href="https://www.aliexpress.com/item/4001282467099.html">ST7789 display</a> that is large enough to mostly cover the exposed area of the lens.</p>

<h1 id="update-feb-2022">UPDATE Feb 2022</h1>

<p><img src="/assets/img/smart-sight/front.PNG" alt="Front" style="float: right; width:50%; height:50%; margin-left: 10px;" />
Got around to creating a CAD model of the sight; this model is technically the third iteration but it represents the first reasonably functional version. It has space for an Arduino Nano, LoRa SX1278 transceiver, display, and a LiPo though no antenna mounting hole has been added. Having created this model with a transceiver onboard, I considered the possibility of including a remote kill feature for disabling weapons and as such I will probably need to wire the sight into the gun’s electronics. This means that future designs don’t strictly need to include space for a LiPo but I’m unsure of whether or not I will remove it just yet.</p>

<p><img src="/assets/img/smart-sight/back.PNG" alt="Back" style="float: left; width:50%; height:50%; margin-right: 10px;" />
Unfortunately, this design was built to fit some standardized Picatinny rail dimensions I found <a href="https://upload.wikimedia.org/wikipedia/commons/thumb/9/95/Picatinny.svg/1200px-Picatinny.svg.png">online</a> and these did fit one of the rifles I own but not the functional one. I was picky in finding my dimensions since the design was built all in metric units which may have caused some inaccuracies so the next design will be built using real measurements from the functional rifle. The intent with this design was to stick the antenna out the side of the sight but this is a poor decision considering the wear and tear that the weapon will likely be subjected to so I try to will integrate the antenna within the sight for the next iteration.</p>

<p>Here is an exploded view of this model:
<img src="/assets/img/smart-sight/exploded_noWriting.PNG" alt="Exploded View" style="display: block; margin-left: auto; margin-right: auto; margin-top: 10px" /></p>]]></content><author><name>Alex Ludicrous</name></author><summary type="html"><![CDATA[Intelligent weapon optics]]></summary></entry><entry><title type="html">LTE Mavic Pro</title><link href="http://localhost:4000/lte-mavic-pro/" rel="alternate" type="text/html" title="LTE Mavic Pro" /><published>2021-12-03T00:00:00-05:00</published><updated>2021-12-03T00:00:00-05:00</updated><id>http://localhost:4000/lte-mavic-pro</id><content type="html" xml:base="http://localhost:4000/lte-mavic-pro/"><![CDATA[<p>Cellular-based drone control has been a longstanding goal with the purpose of creating UAVs requiring minimal user input to function. I have found the need for constant input to significantly reduce the useability of drones for recon during my adventures because neither myself nor the people with me can dedicate significant attention to piloting them. This project aims to achieve basic autonomous control through an Android application that allows the user to place the drone at specific coordinates or land it. The first rendition was built to be submitted as an electronics project for a university course and is solely capable of navigation; takeoff and landing must be manually with a separate remote controller. This is because a F1 flight controller was used which is only capable of managing stability.</p>

<h1 id="basic-idea">Basic Idea</h1>

<p>The drone will be centered around a Raspberry Pi Zero and a LTE modem for internet access. A Raspberry Pi CM4 could fit and would be beneficial but I am not currently capable of developing carrier boards and a full size Raspberry Pi will not fit. The Pi’s serial port is dedicated to communicating with the flight controller through iBus since iBus operates at 115200 baud and bit bashing on the Pi becomes unreliable past 19200 baud. The GPS data will be received using a GPIO pin and bit bashing and another bit bashing serial connection will be used to communicate with an Arduino. The Arduino serves as an IO expander for the Pi to manage the LEDs on the drone as well as an ultrasonic sensor and sense voltage and current throughout the drone. Using an Arduino as such is advantageous since it has an ADC whereas the Pi does not. Additionally, offloading time-sensitive operations such as reading the ultrasonic sensor and running the drone’s LED patterns decreases the complexity of the Pi’s code.</p>

<h2 id="data-link">Data Link</h2>

<p>My current LTE modem filters all ports no matter what settings I chose within its menu. For this reason, I’ve elected to use a P2P UDP protocol which is able to punch through firewalls. A second Raspberry Pi will serve as an intermediary P2P server to connect the cell phone and drone given that neither has a static IP. The P2P code was largely copied from https://github.com/grakshith/p2p-chat-python.git and modified to better fit my protocol. Both the drone and cell phone should identify themselves during their initial UDP broadcast in order to identify what function they serve; this future proofs the server’s code since I can selectively connect devices based on functionality as opposed to the time at which they contact the server. Once two compatible hosts have broadcast their address/port to the P2P server, they will each receive the address/port of the other client and the server logs the connection before discarding all saved host data.</p>

<h2 id="flight-algorithm">Flight Algorithm</h2>

<p>The version submitted for my course uses a rather primal flight algorithm in which the Pi has a barometer and compass connected to it through I2C. Using GPS, compass, and altitude data the Pi is able to compute a vector from its current coordinates to the target coordinates using the haversine libary for Python and a bearing function I stole from StackExchange. It then points the drone in the target direction and goes forward; the drone’s speed varies based on distance to target and it progressively slows down as the distance decreases. The current version offloaded all navigation to the flight controller running iNav thereby reserving the Pi’s looptime for more useful functions such as WiFi, cellular, and UHF sniffing. OpenCV can also be used on the Pi to provide some level of active tracking and increase the effective autonomy of this platform. For this, I may need to choose a UAV platform with surround cameras such as the Mavic 2 or Skydio 2 and upgrade to an nVidia Jetson computer since having the drone actively follow subjects would require some level of obstacle avoidance.</p>

<h1 id="update-feb-2022">UPDATE Feb 2022</h1>

<p>Obtained a SucceX-D Mini F7 Twin G stack and redesigned the 3D printed bracket which holds all the electronics inside the Mavic. 
<img src="/assets/img/hacked-mavic/board-mount-V3.PNG" alt="Bracket V2" style="float: right" />
The new design no longer requires tape and glue but rather relies on three pre-existing screwholes used by the original DJI flight control board. It took a few revisions to finalize the fit of the board such that the components comfortably fit within the restricted space originally occupied by DJI’s proprietary electronics. This is the fifth revision of the bracket and it includes mount points for a 4-in-1 ESC board, flight controller, the Raspberry Pi, and a Flysky receiver. I’m sticking with the Flysky receiver over a Crossfire system since it is able to take advantage of the 2.4 GHz antennas already integrated in the Mavic leading to a more ‘stock’ look. The 4-in-1 ESC board is on the bottom such that it can be in contact with the bottom heatsink of the Mavic and hopefully take advantage of it. Realistically, this ESC board is rated for 45A per motor which is likely over double what the motors should be drawing. Finally, I have decided to remove the Arduino since I should be able to accomplish its tasks with threaded processes on the RPi. In doing so, I am now once again able to install the OEM gimbal on the drone and, since the DJI Mavic’s camera seems to use MIPI, I should be able to interface it with the RPi (I haven’t yet tested the camera’s protocol but its connector looks identical to that of the Caddx Polar camera I own).</p>

<p>Unfortunately I still do not have a compact cellular modem and I am not sure where I will be able to fit it. I also need to create a custom target to flash the F7 board with iNav since I don’t believe Betaflight is capable of executing waypoint missions through telemetry but I will see if that’s a possibility. I also need to figure out if the flight controller is able to arm and takeoff without any contribution from the receiver since I only intend to keep it for debugging/testing purposes and it is not intended to be used during regular operation.</p>

<h1 id="update-dec-2021">UPDATE Dec 2021</h1>

<p>Initial bracket designs relied on double sided adhesive and a small bracket to effectively hold down all the internals. 
<img src="/assets/img/hacked-mavic/board-mount-V1.PNG" alt="Bracket V1" style="float: right" />
This design makes maintenance virtually impossible without considerably disassembling the drone so current versions use existing screwholes to ensure a more secure fit. The varying boards within the Mavic are installed as follows:</p>
<ul>
  <li>The flight controller is installed sideways on the front of the bracket immediately following the pre-existing fan</li>
  <li>A 20x20mm 20A ESC board is installed immediately following the flight controller on the underside of the bracket. This allows for thermal pads to be placed between the ESCs and the Mavic’s pre-existing heatsink thereby providing some cooling.</li>
  <li>Following the ESC, the LTE modem and an Arduino Nano are installed on the bottom of the board.</li>
  <li>The top of the bracket is exclusively reserved for the Raspberry Pi Zero. Ideally, the Pi would be on the bottom so that the heatsink could cool it but unfortunately the ultrasonic sensors make this difficult so I had to place it on top. Fortunately, the Pi Zero does not need any cooling so I will keep it like this for future designs.</li>
  <li>Finally, a FlySky i6X receiver is shoved within the wiring towards the end of the drone body for debugging purposes.</li>
</ul>

<p><img src="/assets/img/hacked-mavic/build-V1.jpg" alt="Mavic Build V1" /></p>

<h1 id="code">Code</h1>

<h2 id="raspberry-pi">Raspberry Pi</h2>

<p>The Raspberry Pi runs off of a Python program split into four key files:</p>
<ul>
  <li><strong>main.py</strong> –&gt; this file is what runs upon startup. It calls upon the other three and synchronizes data between files (takes updated target coordinates from network.py and sends them to flight.py)</li>
  <li><strong>network.py</strong> –&gt; this file handles all P2P communication and is responsible for maintaining a link with the cell phone. It receives target coordinates and saves them in a local variable which is then queried by main.py</li>
  <li><strong>flight.py</strong> –&gt; handled flight algorithm in implementation for my course however <strong>TODO</strong> current version dispatches target coords to the flight controller and monitors telemetry data so it can be passed on to the Android application</li>
  <li><strong>misc.py</strong> –&gt; contains random functions used by all files such as logging</li>
</ul>

<h2 id="arduino">Arduino</h2>

<p>Pins A0 and A1 are used for detecting voltage from the battery and the 5V rail. Pins 2 and 13 are used as digital outputs for controlling the LEDs on the left and right front arms of the Mavic, respectively. Pin 8 is used for the LEDs throughout the drone which are single WS2812b pixels while pins 5 and 6 are used to monitoring the ultrasonic sensor. The LED patterns were done by keeping track of loop time: every time an LED pattern begins the value of millis() is saved in cycleStartTime, and for every time the code runs the current output is compared to cycleStartTime. Each cycle has an arbitrary time step, for example a cycle may have 8 time steps all of which last 800ms. These time steps are encoded in if statements that compare millis() to cycleStartTime and figure out which time step the cycle should be running. Once all 8 time steps have finished, cycleStartTime is updated to represent the current time and the cycle restarts.</p>

<h2 id="android-studio">Android Studio</h2>

<p>Not sure where exactly to go with the application. Probably gonna open to a full screen map but also have another activity for the drone camera feed/more complex controls. The user will be able to have either activity open full screen or split the screen so both can be viewed at the same time.</p>]]></content><author><name>Alex Ludicrous</name></author><summary type="html"><![CDATA[Cellular-based drone control has been a longstanding goal with the purpose of creating UAVs requiring minimal user input to function. I have found the need for constant input to significantly reduce the useability of drones for recon during my adventures because neither myself nor the people with me can dedicate significant attention to piloting them. This project aims to achieve basic autonomous control through an Android application that allows the user to place the drone at specific coordinates or land it. The first rendition was built to be submitted as an electronics project for a university course and is solely capable of navigation; takeoff and landing must be manually with a separate remote controller. This is because a F1 flight controller was used which is only capable of managing stability.]]></summary></entry><entry><title type="html">Jaguar (Medium-sized VTOL UAV Platform)</title><link href="http://localhost:4000/jaguar/" rel="alternate" type="text/html" title="Jaguar (Medium-sized VTOL UAV Platform)" /><published>2021-12-01T00:00:00-05:00</published><updated>2021-12-01T00:00:00-05:00</updated><id>http://localhost:4000/jaguar</id><content type="html" xml:base="http://localhost:4000/jaguar/"><![CDATA[<h2 id="simple-but-limited-uav-platform-for-urban-operations">Simple but limited UAV platform for urban operations</h2>

<p>I kept seeing ~2.5m wide VTOL UAVs on AliExpress that I would love to own but they are all rather overpriced so I decided to make my own. Using the tech I played with while developing the LTE-based Mavic Pro I intend to have this drone operated by a cellular application and AI to minimize how much interaction is required from the user.</p>

<p>I purchased motors and ESCs in accordance with <a href="https://www.aliexpress.com/item/1005002831031206.html?spm=a2g0o.productlist.0.0.38ef1d39JjUhDN&amp;algo_pvid=7475fc42-48b8-4b91-ad05-eff71d8d9826&amp;algo_exp_id=7475fc42-48b8-4b91-ad05-eff71d8d9826-8">this</a> VTOL from AliExpress because it will be similarly sized to my final design.</p>

<h1 id="design-overview">Design Overview</h1>

<p>This design relies heavily on 3D printed components and foamboard/spars which can be sourced at Dollarama. The general premise is to create a form of outline using 3D printed ribs and cover it in delaminated foamboard. The spars inside the fuselage are fiberglass whereas all other spars in the aircraft are steel broomsticks from Dollarama. The current design is solely a prototype and, as such, the extra weight should not matter.</p>

<h1 id="update-mar-2022">UPDATE Mar 2022</h1>

<p>Project abandoned for financial reasons.</p>

<h1 id="update-feb-2022">UPDATE Feb 2022</h1>

<p>Removable wing extensions have been finished.</p>

<p><strong>WING PICS</strong></p>

<p><img src="/assets/img/jaguar/CAD-V1.PNG" alt="Tail closeup" style="float: right; width:50%; height:50%" />
The CAD design has also been updated to include more specific design considerations for the tail: there are now servo and LED holes. The VTOL motors and mounts have been omitted in the design below. I also doubled the rib density in the wing based on my experience when building the removable portions; one rib every 8 inches allowed for an inconsistent profile at the leading edge once the foamboard was delaminated on one side.</p>

<p><img src="/assets/img/jaguar/CAD-V2.PNG" alt="Updated CAD" /></p>

<h1 id="update-dec-2021">UPDATE Dec 2021</h1>

<p>Went on a last minute trip before the COVID-19 Omicron wave and, for some reason, I find that my design productivity is very high while travelling so I was able to finish the CAD design for this UAV. The internals of the plane are not yet finalized because I have not yet decided on the specifications of the battery and I can’t fully imagine what components will be included in the UAV just yet. The current CAD progress focused on obtaining a general shape for the aircraft and fully designing the wings as well as the rear half of the fuselage containing the camera gimbal, electronics, and thrust motor. The tail is currently designed but without any considerations about the electronics which will be housed within.</p>

<p><img src="/assets/img/jaguar/CAD-V1.PNG" alt="Original CAD" /></p>

<p>I’ve also been printing wing ribs on and off for a few weeks now in hopes that I can begin construction soon. It’s difficult to decide where I should begin with a project as daunting as this one.</p>]]></content><author><name>Alex Ludicrous</name></author><summary type="html"><![CDATA[Simple but limited UAV platform for urban operations]]></summary></entry><entry><title type="html">Two G-class Stage Rocket w/ Basic Telemetry</title><link href="http://localhost:4000/two-stage-rocket/" rel="alternate" type="text/html" title="Two G-class Stage Rocket w/ Basic Telemetry" /><published>2021-11-08T00:00:00-05:00</published><updated>2021-11-08T00:00:00-05:00</updated><id>http://localhost:4000/two-stage-rocket</id><content type="html" xml:base="http://localhost:4000/two-stage-rocket/"><![CDATA[<h2 id="experimenting-with-rocketry-electronics">Experimenting with rocketry electronics</h2>

<p>While I doubt I will ever get a high power rocketry license, I do thoroughly enjoy developing and flying model rockets. None of my past rockets have incorporated any amount of electronics so the purpose of this project is to get a feel for rocketry electronics without any risk by developing only non-terribly-flight-critical components. For this project, I purchased the two biggest rocket engines I can legally get my hands on without any license: AeroTech G80-7T motors.</p>

<h1 id="design">Design</h1>
<h2 id="motor-mounts">Motor mounts</h2>

<p>I watched a <a href="https://www.youtube.com/watch?v=4fhoCt9vXA8">video</a> by ProjectAir on YouTube about a rocket he built using similarly powerful motors and I based my rocket motor mounts on his design. The motor mounts consist of a small tube for the motor and a larger tube that fits snuggly into the rocket body. These two are connected by 8 perpendicular supports between the two cylindrical extrusions. The holes on the bottom of this motor mount also work to hold the first stage onto the main stage by using 8 pegs protruding from the first stage which fit snuggly into the 8 holes of the motor mount above.</p>

<h2 id="avionics">Avionics</h2>

<p>I intend to have live data logging and telemetry at the very least. This rocket will include a GPS, barometer, and accelerometer as well as an ignition system for the main stage engine. I would also like to include some system that can delay the deployment of the main chute since it will significantly increase the rocket’s drift during recovery however I’m unsure of how reliably I can integrate such a feature. All the electronics will be housed near/in the nose cone and the rocket will separate close to the main stage motor for recovery such that the body tube/nose cone section containing the electronics remains intact.</p>

<h1 id="update-oct-2022">UPDATE Oct 2022</h1>

<p><img src="/assets/img/habibi-express/recovery_layout_update.jpg" alt="Recovery layout update" style="float: right; width:10%; height:20%; margin-left: 10px;" /> 
Progress is being made on flight controller firmware, the I2C issue has been fixed and the IMU data is now being read as well. Turns out the Adafruit BMP280 library was looking for the wrong address and I had to force it to read data from the true address. Engine mounts and fins have been attached to the rocket, currently focused on recovery charge and how to protect the rocket’s internals from the motor’s ejection charge as well as the true ejection charge. The motor mounts have plenty of space around them to allow the motor’s ejection charge gases to escape however I need to add a component following the motor to shield the parachute from the motor’s charge and contain the true ejection charge as well. The planned layout is pictured to the right where the green block represents the blast shield, red represents the true ejection charge, yellow represents the drogue chute, and cyan represents the final chute. The rocket splits between the cyan and yellow blocks when the ejection charge detonates.</p>

<p>The avionics bay has been expanded to include relays for the second stage and ejection charge igniters as well as an SD card reader for data logging, servo to retain the primary parachute, and two DVRs (scrapped the camera inside the body tube). The second stage will be ignited based on the following criteria:</p>
<ul>
  <li>Rocket attitude is within 30 degrees of launch attitude (makes sure the rocket is vertical)</li>
  <li>Rocket altitude is greater than 250 meters (should be 500 meters or so based on simulation)</li>
  <li>Rocket acceleration drops noticeably (simulation suggests peak of 13 Gs however the software will just look for a drop of ~5Gs)</li>
  <li>Launch was detected less than 10 seconds ago (makes sure the conditions cannot be met unless the rocket just took off)</li>
</ul>

<p>Once these conditions are met, the rocket will begin a 3-second timer before igniting the second stage, otherwise the flight controller will do nothing. Apogee will be detected when vertical acceleration drops below -5m/s^2 after which the ejection charge will be ignited. The final chute will be deployed 250 meters above ground level based on barometric data. Launch window has been slightly pushed back however it should be achievable by end of November :)</p>

<h1 id="update-sep-2022">UPDATE Sep 2022</h1>

<p><img src="/assets/img/habibi-express/fin_laser_cutting.jpg" alt="Laser cutting fins" style="float: right; width:30%; height:50%; margin-left: 10px;" />
Finally got around to laser cutting the fins and I have worked slightly on the firmware for the flight controller. Unfortunately I’m having issues with the barometer since it communicates using 3.3V so the Arduino Mega is not able to interpret the I2C data coming from it. The current solution is to replace the barometer with a proven chip that I can find online as working with the Arduino Mega. I will also attempt to read the I2C data using another 5V Arduino to verify that this is indeed the issue. Finally, I have decided to add a few <a href="https://www.aliexpress.com/item/1005002457700952.html">video recorders</a> and a few analog cameras to capture a few angles of the flight. I’m hoping to add a downward facing camera, a side facing camera, and one looking down the body tube towards the main stage engine to capture the ejection from inside the rocket. I intend model camera mounts and redo the avionics bay by the end of October such that the rocket can be flown early November at the latest.</p>

<h1 id="update-jun-2022">UPDATE Jun 2022</h1>

<p><img src="/assets/img/habibi-express/avionicsFront.jpg" alt="Assembled avionics bay" style="float: right; width:30%; height:50%; margin-left: 10px;" />
The avionics bay has been assembled though it is missing a couple key elements. Firstly, there is no voltage regulator to step down the LiPo’s voltage for the Arduino and related electronics; furthermore, I need to integrate a relay so the Arduino can ignite the second stage motor once the initial one burns out. Finally, the antenna installed on the design right now can not be used and is solely there to ensure that I don’t accidentally burn the LoRa transceiver by powering it on without an antenna. Everything on the module at the moment is completely wired and ready to go. I have noted the I2C addresses of the MPU6050 and BMP280 and the wire with the white connector sticking out the top of the avionics bay goes to the GPS sensor in the nose cone of the aircraft.</p>

<p>The software for this design won’t be too involved as the arduino only needs to ignite the second stage 3 seconds after the MPU6050 detects a decrease in vertical acceleration all while broadcasting GPS, altitude, and attitude data at regular intervals. The main concern now is developing viable fins for the rocket body. I am hoping to have them laser-cut at the university but I have yet to inquire about using the equipment.</p>

<h1 id="update-mar-2022">UPDATE Mar 2022</h1>

<p><img src="/assets/img/habibi-express/avionics-CAD-V2-back.PNG" alt="Avionics bay V2 back" style="float: right; width:30%; height:50%; margin-left: 10px;" />
The avionics bay is mostly finalized and I will attempt to print this soon; I’ve done without the 18650 battery and kept the 3s LiPo which is now housed in a casing at the top of the avionics bay. The LoRa module is now positioned such that an antenna can be directly attached to the module and have space in the rocket fuselage. The only thing lacking from the model to the right is a relay holder to ignite the second stage. I still need to remodel the nose cone since the current GPS holder may not have clearance so it must be shifted upwards after which I will begin 3D printing these components and assembling the rocket!</p>

<h1 id="update-feb-2022">UPDATE Feb 2022</h1>

<p><img src="/assets/img/habibi-express/rocket-CAD.PNG" alt="Rocket model" style="float: right; width:50%; height:50%; margin-left: 10px;" />
CAD model is now mostly finished, lots of small things still need to be figured out however most of the grunt work is done. I don’t have a concrete plan for how to wire the main stage motor’s igniter in a way that won’t risk tangling the parachute during recovery. Furthermore, I purchased two G80-7T motors however the rocket will need at least 10 seconds after the main stage burns out to reach its apogee so I most likely need to source a G80-13T motor to avoid using any complex recovery mechanisms. Unfortunately, <a href="https://www.greathobbies.com/">Great Hobbies</a> does not carry G80 motors anymore so I can only source these for unreasonably high prices from <a href="https://www.allrockets.ca/G80-13">AllRockets</a>.</p>

<p><img src="/assets/img/habibi-express/avionics-CAD.PNG" alt="Avionics model" style="float: right; width:30%; height:50%; margin-left: 10px;" />
Main focus now is the avionics bay. The model pictured here has space for an Arduino Mega 2560 (embed), a BMP280, an MPU6050, a LoRa SX1278 transceiver, and two batteries. The nose cone contains a GPS antenna bracket for positioning as well. This is the second iteration of the avionics bay and it contains space for both an 18650 LiIon cell (in green) and a small 3S 700mAh LiPo next to the LiIon cell. I’m concerned that the ~3V from the 18650 will not be enough to ignite the main stage of the rocket even with a boost converter which is why I included the LiPo. I originally considered using the 18650 in light of its higher energy density however it only has roughly 1.5 times the energy stored by the LiPo so it will likely be discarded in the next iteration.</p>

<h1 id="update-dec-2021">UPDATE Dec 2021</h1>
<p>Rocket design was finalized in <a href="https://openrocket.info/">OpenRocket</a> and basic simulation was done; maximum altitude estimated at roughly 1.1km with a max speed of Mach 0.52. I made some faster designs and others with higher apogees but this model seems the most predictable based on how much tech I want to fly with the rocket and how lightly I can manufacture things.</p>

<p><img src="/assets/img/habibi-express/open-rocket-sim.PNG" alt="OpenRocket Model" />
<img src="/assets/img/habibi-express/open-rocket-sim-graph.PNG" alt="OpenRocket Simulation" /></p>]]></content><author><name>Alex Ludicrous</name></author><summary type="html"><![CDATA[Experimenting with rocketry electronics]]></summary></entry><entry><title type="html">Annota Application</title><link href="http://localhost:4000/annota-mobile-application/" rel="alternate" type="text/html" title="Annota Application" /><published>2021-07-20T00:00:00-04:00</published><updated>2021-07-20T00:00:00-04:00</updated><id>http://localhost:4000/annota-mobile-application</id><content type="html" xml:base="http://localhost:4000/annota-mobile-application/"><![CDATA[<p>Annota is my first ever attempt at developing software for Android devices. As part of a second year course, we were challenged to develop an application that could digitize a user’s notes in order to categorize and index them. This application is far from exemplar for a variety of reasons however I had a tremendous level of success considering I knew very little about Java and Android development prior to this project. This was a group project so the work was done in conjunction with three other students though I got away with doing the coding work while the others focused on testing the application and taking care of written deliverables.</p>

<h1 id="clients-needs">Client’s Needs</h1>

<p>The client for this product suffers from Multiple Sclerosis (MS), an auto-immune disase impacting the central nervous, which causes her to suffer from short-term memory loss and fatigue. Since there is no known cure for MS as of this writing, available treatments focus on mitigating the impact of symptoms in patients. For our client, this entails developing an application which can digitize and index important information and provide them with time-based and potentially location-based reminders. Based on a couple interviews, the following needs were identified for the project:</p>

<table>
  <thead>
    <tr>
      <th>Customer Need</th>
      <th>Design Criteria</th>
      <th>Importance</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>A product for everybody</td>
      <td>Must be accessible and usable by everyone.</td>
      <td>1</td>
    </tr>
    <tr>
      <td>Ideally a virtual ‘cork board’</td>
      <td>Must be able to capture and organize text and images with possible support for other medias such as video</td>
      <td>2</td>
    </tr>
    <tr>
      <td>Needs notifications</td>
      <td>Should have reminder function</td>
      <td>3</td>
    </tr>
    <tr>
      <td>Red and green need to be avoided</td>
      <td>Accessibilty-focused UI</td>
      <td>4</td>
    </tr>
    <tr>
      <td>Automate organization</td>
      <td>Enable easy transfer of handwritten text to digital form</td>
      <td>5</td>
    </tr>
    <tr>
      <td>English as primary language</td>
      <td>Multiple language option with English as primary</td>
      <td>6</td>
    </tr>
    <tr>
      <td>Compatible with many devices</td>
      <td>Should support multiple platforms</td>
      <td>7</td>
    </tr>
    <tr>
      <td>Copy annotations from textbook</td>
      <td>Read, annotate, and categorize selective parts of written content</td>
      <td>8</td>
    </tr>
    <tr>
      <td>Zoom in and out of documents</td>
      <td>Integrate an image viewer interface</td>
      <td>9</td>
    </tr>
    <tr>
      <td>Make it aesthetic</td>
      <td>Visual appeal and stimulate user</td>
      <td>10</td>
    </tr>
  </tbody>
</table>]]></content><author><name>Alex Ludicrous</name></author><summary type="html"><![CDATA[Annota is my first ever attempt at developing software for Android devices. As part of a second year course, we were challenged to develop an application that could digitize a user’s notes in order to categorize and index them. This application is far from exemplar for a variety of reasons however I had a tremendous level of success considering I knew very little about Java and Android development prior to this project. This was a group project so the work was done in conjunction with three other students though I got away with doing the coding work while the others focused on testing the application and taking care of written deliverables.]]></summary></entry><entry><title type="html">IP Camera Hacking Toolkit</title><link href="http://localhost:4000/camera-toolkit/" rel="alternate" type="text/html" title="IP Camera Hacking Toolkit" /><published>2021-05-11T00:00:00-04:00</published><updated>2021-05-11T00:00:00-04:00</updated><id>http://localhost:4000/camera-toolkit</id><content type="html" xml:base="http://localhost:4000/camera-toolkit/"><![CDATA[<h2 id="exploit-collectionautomation-for-networked-cameras">Exploit collection/automation for networked cameras</h2>

<p>This is a project I haphazardly began upon discovering <strong>FIND CVE #</strong> which allows an attacker to bypass authentication on Hikvision cameras using a crafted URL. The exploit is rather simplistic but made me consider how useful camera exploits are when infiltrating facilities with unknown camera locations. Aside from connectivity issues I’ve faced with IPv6 networks, it should be theoretically possible to tap into any ethernet cable within a camera network and gain access to every single camera. I have not yet built a device capable of this but I intend to do so in the near future, here is the theoretical approach I have considered.</p>

<p>Axis, Avigilon, and Hikvision cameras are most common in construction site and commercial security so these are a priority.</p>

<h1 id="theoretical-device">Theoretical device</h1>

<p>The device would have two sets of 8 punch down connectors for each wire within an ethernet cable. The attacker would have to strip roughly 15-20 cm of a target cable and separate the wires enough to punch each wire down in both sets of connectors. After all the wires have been connected, the attacker would cut them between the punchdown connectors at which point the device will activate and act as a network switch and instantly reconnect the affected camera while providing the attacker with a physical connection into the network. The device would leech POE power off of the ethernet cable though having a standalone power supply may be required because the POE device powering the camera could technically trigger an alarm and notify someone of a discrepancy in POE power draw.</p>

<h1 id="update-june-2022">UPDATE June 2022</h1>

<p>Just purchased three items to hopefully build a device that can parasitically leech off of a POE camera wire. I bought a POE splitter which accepts one ~30W input and splits it into two ~15W POE outputs; I’m not entirely sure about these specifications but it should be capable of powering a single camera even with the device patched in to the existing POE line. I also purchased a board which converts POE power into a 12V 1A output and managed to find some punchdown connectors that should work with 22-23AWG wire. 
<img src="/assets/img/camera-toolkit/t-taps.PNG" alt="T-taps" style="float: right; width:30%; margin-right: 25px;" />
Fortunately, the punchdown connectors I found are single ‘T-taps’ as pictured to the right. These T-taps will make it significantly easier to patch in to an existing installation without needing to strip a large length of wire. I was initially worried about how difficult it may be to align and punch down 8 wires given past experience when installing <a href="https://github.com/rfidtool/ESP-RFID-Tool">ESP-RFID-Tools</a> which only require me to punch down 4 wires. I am eager to proceed with this project once I receive the parts, at the very least I will develop a tool capable of jamming camera networks using a <a href="https://www.researchgate.net/publication/266022049_ICMPv6_Router_Advertisement_Flooding">IPv6 Router Advertisment Flood Attack</a>. I have had issues in the past getting my computer to communicate with devices on NVR networks since these are designed more for communication between the NVR and the camera as opposed to communication between the cameras themselves. For some reason, my computer fails to obtain a valid IP configuration since it does not seem to gather that it is connected to an IPv6 network as opposed to an IPv4 network. I will be using a smaller SBC such as the <a href="https://www.aliexpress.com/item/1005002918902225.html">Orange Pi Zero</a> when building this concept which will ideally perform better.</p>

<p>A possible concern is not knowing whether the installation is using T-568A or T-568B wiring. Not sure how serious it would be to guess but I will do more research into POE wiring and all once I receive the parts and am closer to the design stage. These parts were purchased without a concrete design because the device itself costs about $25 excluding the SBC so I figured why not. I’ll have a use for these things regardless of whether this works.</p>

<h1 id="current-issues">Current issues</h1>

<p>IPv6 is the most significant issue I’m facing at the moment. Both my laptop and cell phone refuse to obtain a valid IP address when on a wired IPv6 network even though they should both be fully compatible. This may be due to MAC address filtering but I’m not sure.</p>

<h1 id="hikvision">Hikvision</h1>

<p>Working exploit for individual cameras but no exploit against NVRs. Camera enumaration/fingerprinting possible.</p>

<h1 id="unv">UNV</h1>

<p>Found a NVR password disclosure exploit but not tested. My building uses UNV cameras on an IPv4 network so I am able to experiment with things but I haven’t done much work thus far.</p>

<h1 id="axis">Axis</h1>

<p>I know remote code execution is possible but have yet to experment with any Axis cameras.</p>

<h1 id="avigilon">Avigilon</h1>

<p>Probably the most important target to me given their deep learning AI that makes them more detrimental than regular cameras.</p>

<h1 id="sony-ipela">Sony IPELA</h1>

<p>Idk if I’ll bother with Sony, they are mostly used in retail so I have little interest in them.</p>]]></content><author><name>Alex Ludicrous</name></author><summary type="html"><![CDATA[Exploit collection/automation for networked cameras]]></summary></entry></feed>